diff --git Makefile.target Makefile.target
index ae02495951..57b6dd4c0e 100644
--- Makefile.target
+++ Makefile.target
@@ -12,7 +12,7 @@ endif
 
 $(call set-vpath, $(SRC_PATH):$(BUILD_DIR))
 ifdef CONFIG_LINUX
-QEMU_CFLAGS += -I../linux-headers
+QEMU_CFLAGS += -I../linux-headers -msse2 -msse -march=native -maes
 endif
 QEMU_CFLAGS += -iquote .. -iquote $(SRC_PATH)/target/$(TARGET_BASE_ARCH) -DNEED_CPU_H
 
@@ -157,6 +157,7 @@ obj-y += memory_mapping.o
 obj-y += dump.o
 obj-$(TARGET_X86_64) += win_dump.o
 obj-y += migration/ram.o
+obj-$(CONFIG_PERISCOPE) += migration/periscope.o migration/periscope-syzkaller.o migration/periscope-profiler.o migration/periscope-afl.o migration/periscope-exec.o migration/periscope-kcov.o migration/periscope_dma.o migration/periscope-timers.o migration/periscope-delta-snap-hash.o
 LIBS := $(libs_softmmu) $(LIBS)
 
 # Hardware support
diff --git accel/kvm/kvm-all.c accel/kvm/kvm-all.c
index 241db496c3..b73f7bfcd0 100644
--- accel/kvm/kvm-all.c
+++ accel/kvm/kvm-all.c
@@ -31,6 +31,8 @@
 #include "exec/gdbstub.h"
 #include "sysemu/kvm_int.h"
 #include "sysemu/cpus.h"
+#include "migration/periscope.h"
+#include "migration/periscope_dma.h"
 #include "qemu/bswap.h"
 #include "exec/memory.h"
 #include "exec/ram_addr.h"
@@ -40,9 +42,12 @@
 #include "hw/irq.h"
 #include "sysemu/sev.h"
 #include "sysemu/balloon.h"
+#include "migration/periscope-timers.h"
 
 #include "hw/boards.h"
 
+#include "qemu/cutils.h"
+
 /* This check must be after config-host.h is included */
 #ifdef CONFIG_EVENTFD
 #include <sys/eventfd.h>
@@ -258,6 +263,58 @@ int kvm_physical_memory_addr_from_host(KVMState *s, void *ram,
     return 0;
 }
 
+int kvm_update_user_memory_region(void* old, void* new, size_t len)
+{
+    KVMState *s = kvm_state;
+    KVMMemoryListener *kml = &s->memory_listener;
+    void *rnew = NULL;
+    int ret = 0;
+
+    //static qemu_timeval tv_restore_begin, tv_restore_end;
+    //qemu_gettimeofday(&tv_restore_begin);
+
+    for (int i = 0; i < s->nr_slots; i++) {
+        KVMSlot *slot = &kml->slots[i];
+        if(i>6) break;
+        if ((old <= slot->ram && old + len > slot->ram)) {
+            struct kvm_userspace_memory_region mem;
+            rnew = new + (slot->ram - old);
+
+            mem.guest_phys_addr = slot->start_addr;
+            mem.userspace_addr = (unsigned long)slot->ram;
+            mem.flags = slot->flags;
+
+            mem.slot = slot->slot | ((kml->as_id) << 16);
+
+            /* Set the slot size to 0 before setting the slot to the desired
+             * value. This is needed based on KVM commit 75d61fbc. */
+            //mem.memory_size = 0;
+
+            //kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
+
+            mem.memory_size = slot->memory_size;
+
+
+            mem.userspace_addr = (unsigned long)rnew;
+            //ret = kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
+            ret = kvm_vm_ioctl(s, KVM_UPDATE_USER_MEMORY_REGION, &mem);
+            slot->old_flags = mem.flags;
+            slot->ram = rnew;
+            trace_kvm_set_user_memory(mem.slot, mem.flags, mem.guest_phys_addr,
+                  mem.memory_size, mem.userspace_addr, ret);
+
+        }
+    }
+
+    //qemu_timeval elapsed;
+    //timersub(&tv_restore_end, &tv_restore_begin, &elapsed);
+    //printf("periscope: reset mem time %lu ms\n",
+    //      elapsed.tv_sec * 1000L + elapsed.tv_usec / 1000L);
+
+    return ret;
+}
+
+
 static int kvm_set_user_memory_region(KVMMemoryListener *kml, KVMSlot *slot, bool new)
 {
     KVMState *s = kvm_state;
@@ -466,6 +523,8 @@ static int kvm_get_dirty_pages_log_range(MemoryRegionSection *section,
                        memory_region_get_ram_addr(section->mr);
     ram_addr_t pages = int128_get64(section->size) / getpagesize();
 
+    trace_kvm_get_dirty_pages_log_range(start, pages);
+
     cpu_physical_memory_set_dirty_lebitmap(bitmap, start, pages);
     return 0;
 }
@@ -846,6 +905,8 @@ static void kvm_log_sync(MemoryListener *listener,
     KVMMemoryListener *kml = container_of(listener, KVMMemoryListener, listener);
     int r;
 
+    trace_kvm_log_sync();
+
     r = kvm_physical_sync_dirty_bitmap(kml, section);
     if (r < 0) {
         abort();
@@ -1768,17 +1829,50 @@ void kvm_set_sigmask_len(KVMState *s, unsigned int sigmask_len)
     s->sigmask_len = sigmask_len;
 }
 
-static void kvm_handle_io(uint16_t port, MemTxAttrs attrs, void *data, int direction,
+static void kvm_cpu_kick_self(void);
+
+static void kvm_handle_io(CPUState* cpu,
+                          uint16_t port, MemTxAttrs attrs, void *data, int direction,
                           int size, uint32_t count)
 {
     int i;
     uint8_t *ptr = data;
 
     for (i = 0; i < count; i++) {
+        FlatView *fv = address_space_to_flatview(&address_space_io);
+        hwaddr l;
+        hwaddr addr1;
+        MemoryRegion *mr;
+        l = size;
+        mr = flatview_translate(fv, port, &addr1, &l, false, attrs);
+
+        if (periscope_mmio_check(mr, size, direction == KVM_EXIT_IO_OUT) < 0) {
+            kvm_cpu_kick_self();
+            kvm_vcpu_ioctl(cpu, KVM_RUN, 0);
+
+            if (periscope_maybe_checkpoint_request() == 0) {
+                kvm_cpu_synchronize_state(cpu);
+
+                vm_stop(RUN_STATE_SAVE_VM);
+            }
+
+            periscope_restore_request();
+            vm_stop(RUN_STATE_RESTORE_VM);
+            return;
+        }
+
         address_space_rw(&address_space_io, port, attrs,
                          ptr, size,
                          direction == KVM_EXIT_IO_OUT);
+
         ptr += size;
+
+        if (direction != KVM_EXIT_IO_OUT && mr && mr->name &&
+            strstart(mr->name, "periscope-", NULL)) {
+            if (periscope_maybe_checkpoint_request() == 0) {
+                vm_stop(RUN_STATE_SAVE_VM);
+            }
+        }
     }
 }
 
@@ -1942,6 +2036,25 @@ static void kvm_eat_signals(CPUState *cpu)
     } while (sigismember(&chkset, SIG_IPI));
 }
 
+int kvm_enable_dma_trace(uint64_t gpa)
+{
+    KVMState *s = kvm_state;
+    int ret;
+    //printf("%s: Enter\n", __FUNCTION__);
+    ret = kvm_vm_ioctl(s, KVM_ENABLE_DMA_TRACE, gpa);
+    return ret;
+}
+
+int kvm_disable_dma_trace(uint64_t gpa)
+{
+    KVMState *s = kvm_state;
+    int ret;
+    //printf("%s: Enter\n", __FUNCTION__);
+    ret = kvm_vm_ioctl(s, KVM_DISABLE_DMA_TRACE, gpa);
+    return ret;
+}
+
+
 int kvm_cpu_exec(CPUState *cpu)
 {
     struct kvm_run *run = cpu->kvm_run;
@@ -2021,15 +2134,84 @@ int kvm_cpu_exec(CPUState *cpu)
         case KVM_EXIT_IO:
             DPRINTF("handle_io\n");
             /* Called outside BQL */
-            kvm_handle_io(run->io.port, attrs,
+            kvm_handle_io(cpu, run->io.port, attrs,
                           (uint8_t *)run + run->io.data_offset,
                           run->io.direction,
                           run->io.size,
                           run->io.count);
             ret = 0;
+
+            if (periscope_checkpoint_requested() || periscope_restore_requested())
+                ret = EXCP_INTERRUPT;
+
             break;
         case KVM_EXIT_MMIO:
             DPRINTF("handle_mmio\n");
+
+            FlatView *fv = address_space_to_flatview(&address_space_memory);
+            hwaddr l;
+            hwaddr addr1;
+            MemoryRegion *mr;
+            l = run->mmio.len;
+            mr = flatview_translate(fv, run->mmio.phys_addr, &addr1, &l, false, attrs);
+
+            if (periscope_mmio_check(mr, run->mmio.len, run->mmio.is_write) < 0) {
+                kvm_cpu_kick_self();
+                run_ret = kvm_vcpu_ioctl(cpu, KVM_RUN, 0);
+
+                if (periscope_maybe_checkpoint_request() == 0) {
+                    kvm_cpu_synchronize_state(cpu);
+
+                    vm_stop(RUN_STATE_SAVE_VM);
+                }
+
+                periscope_restore_request();
+                vm_stop(RUN_STATE_RESTORE_VM);
+
+                ret = EXCP_INTERRUPT;
+                break;
+            }
+
+            if(mr && mr->name && strcmp(mr->name, "pc.ram") == 0) {
+               periscope_dmar *dmar = periscope_dma_get(run->mmio.phys_addr, 1);
+               if(dmar->mr != NULL) {
+                  if(run->mmio.is_write) {
+                     periscope_dma_write_access(dmar, run->mmio.phys_addr, run->mmio.data, run->mmio.len);
+                     // mirror data to actual guest ram
+                     dma_memory_write(&address_space_memory, run->mmio.phys_addr, run->mmio.data, run->mmio.len);
+                     //printf("written value @ %llx -> %lx\n", run->mmio.phys_addr, *(uint64_t*)run->mmio.data);
+                  } else { // read
+                     for(int i=0; i<run->mmio.len; ++i) { // for each accessed byte (to handle partial overwrites)
+                        int r = periscope_dma_read_access(dmar, run->mmio.phys_addr + i, ((uint8_t*)run->mmio.data) + i);
+                        if(r == 1) { // not fuzzed -> data in guest ram will be left unchanged
+                           //printf("not fuzzing dma @ %llx\n", run->mmio.phys_addr + i);
+                        } else if (r == 0) { // fuzzed
+                           printf("fuzzing dma @ %llx\n", run->mmio.phys_addr);
+
+                           // TODO
+                           // for now set some arbitraty address offset, which falls into the mmio region
+                           // we could also directly invoke the fuzzer
+                           address_space_rw(&address_space_memory,
+                                 dmar->mr->addr + 123, attrs,
+                                 ((uint8_t*)run->mmio.data) + i,
+                                 1,
+                                 run->mmio.is_write);
+
+                           //printf("fuzzed value %lx\n", *((uint64_t*)run->mmio.data)+i);
+                           // mirror data to actual guest ram
+                           dma_memory_write(&address_space_memory, run->mmio.phys_addr + i, ((uint8_t*)run->mmio.data)+i, 1);
+                        } else {
+                           printf("ERROR could not get dma value\n");
+
+                        }
+                     }
+                  }
+                  periscop_dma_maybe_remove(dmar, run->mmio.phys_addr);
+               }
+               ret = 0;
+               break;
+            }
+
             /* Called outside BQL */
             address_space_rw(&address_space_memory,
                              run->mmio.phys_addr, attrs,
@@ -2037,9 +2219,142 @@ int kvm_cpu_exec(CPUState *cpu)
                              run->mmio.len,
                              run->mmio.is_write);
             ret = 0;
+
+            if (!run->mmio.is_write && mr && mr->name &&
+                strstart(mr->name, "periscope-", NULL)) {
+                if (periscope_maybe_checkpoint_request() == 0) {
+                    vm_stop(RUN_STATE_SAVE_VM);
+
+                    ret = EXCP_INTERRUPT;
+                }
+            }
+
+            break;
+
+#ifndef KVM_HC_PERISCOPE
+#define KVM_EXIT_PERISCOPE_GET_PROG 100
+#define KVM_EXIT_PERISCOPE_END 101
+#define KVM_EXIT_PERISCOPE_DEBUG 110
+#endif
+
+        case KVM_EXIT_PERISCOPE_GET_PROG:
+            periscope_notify_boot();
+            run->hypercall.ret = periscope_get_agent_id();
+            ret = 0;
+            break;
+        case KVM_EXIT_PERISCOPE_END:
+            if (should_restore_at_agent_exit(run->hypercall.args[0])) {
+                kvm_cpu_kick_self();
+                run_ret = kvm_vcpu_ioctl(cpu, KVM_RUN, 0);
+
+                // no need for checkpoint here
+                // request a restore right away
+                periscope_restore_request();
+                vm_stop(RUN_STATE_RESTORE_VM);
+
+                ret = EXCP_INTERRUPT;
+                break;
+            }
+            if (should_shutdown_at_agent_exit(run->hypercall.args[0])) {
+                qemu_system_shutdown_request(SHUTDOWN_CAUSE_GUEST_SHUTDOWN);
+                ret = EXCP_INTERRUPT;
+            }
+            ret = 0;
+            break;
+        case KVM_EXIT_PERISCOPE_DEBUG:
+            kvm_cpu_synchronize_state(cpu);
+            ret = 0;
+
+            switch(run->hypercall.args[0]) {
+            case SYZKALLER_HC_ROOT_CHKPT:
+                printf("periscope: root checkpoint requested\n");
+                if (periscope_snapshot_inited()) {
+                    run->hypercall.ret = -1;
+                    ret = 0;
+                    break;
+                }
+                if (periscope_maybe_checkpoint_request() == 0) {
+                    ret = EXCP_INTERRUPT;
+#define FORCE_SKIP_HC
+#undef FORCE_SKIP_HC
+#ifdef FORCE_SKIP_HC
+                    // forcefully skip this hypercall before chkpt
+                    kvm_cpu_synchronize_state(cpu);
+                    X86CPU *x86_cpu = X86_CPU(cpu);
+                    x86_cpu->env.eip += 3; // vm(m)call is 3 bytes
+                    kvm_arch_put_registers(cpu, KVM_PUT_RUNTIME_STATE);
+                    cpu->vcpu_dirty = true;
+
+                    kvm_cpu_kick_self();
+                    run_ret = kvm_vcpu_ioctl(cpu, KVM_RUN, 0);
+#endif
+                }
+                else {
+                    printf("periscope: failed to request root checkpoint\n");
+                }
+                periscope_restore_request();
+                ret = EXCP_INTERRUPT;
+                break;
+            case SYZKALLER_HC_RECV_EXEC:
+                syzkaller_receive_execute(cpu, run->hypercall.args[1]);
+                break;
+            case SYZKALLER_HC_REPLY_EXEC:
+                syzkaller_reply_execute(run->hypercall.args[1]);
+                if (!periscope_snapshot_inited()) {
+                    ret = 0;
+                    break;
+                }
+                periscope_restore_request();
+                ret = EXCP_INTERRUPT;
+                break;
+            case SYZKALLER_HC_RECV_HANDSHAKE:
+                syzkaller_receive_handshake(cpu, run->hypercall.args[1]);
+                ret = 0;
+                break;
+            case SYZKALLER_HC_REPLY_HANDSHAKE:
+                syzkaller_reply_handshake();
+                ret = 0;
+                break;
+            case SYZKALLER_HC_MAYBE_CHKPT:
+                run->hypercall.ret = syzkaller_maybe_checkpoint(run->hypercall.args[1], run->hypercall.args[2]);
+                if (run->hypercall.ret == 0) {
+#ifdef FORCE_SKIP_HC
+                    // forcefully skip this hypercall before chkpt
+                    kvm_cpu_synchronize_state(cpu);
+                    X86CPU *x86_cpu = X86_CPU(cpu);
+                    x86_cpu->env.eip += 3; // vm(m)call is 3 bytes
+                    kvm_arch_put_registers(cpu, KVM_PUT_RUNTIME_STATE);
+                    cpu->vcpu_dirty = true;
+
+                    kvm_cpu_kick_self();
+                    run_ret = kvm_vcpu_ioctl(cpu, KVM_RUN, 0);
+#endif
+                    ret = EXCP_INTERRUPT;
+                    break;
+                }
+                ret = 0;
+                break;
+            case SYZKALLER_HC_FORKSRV_CTX:
+                syzkaller_submit_forkserver_context(run->hypercall.args[1]);
+                ret = 0;
+                break;
+            case PERISCOPE_DEBUG_HC_BENCHMARK:
+                periscope_benchmark_hypercall(run->hypercall.args[1]);
+                break;
+            case PERISCOPE_DEBUG_HC_NEXT:
+                periscope_fetch_next_input();
+                ret = 0;
+                break;
+            default:
+                periscope_debug_hypercall(run->hypercall.args[0], run->hypercall.args[1], run->hypercall.args[2]);
+                ret = 0;
+                break;
+            }
             break;
         case KVM_EXIT_IRQ_WINDOW_OPEN:
             DPRINTF("irq_window_open\n");
+            if (periscope_irq_check() == 0) {
+            }
             ret = EXCP_INTERRUPT;
             break;
         case KVM_EXIT_SHUTDOWN:
@@ -2048,6 +2363,7 @@ int kvm_cpu_exec(CPUState *cpu)
             ret = EXCP_INTERRUPT;
             break;
         case KVM_EXIT_UNKNOWN:
+            printf("periscope: kvm exit unknown\n");
             fprintf(stderr, "KVM: unknown exit, hardware reason %" PRIx64 "\n",
                     (uint64_t)run->hw.hardware_exit_reason);
             ret = -1;
@@ -2085,6 +2401,15 @@ int kvm_cpu_exec(CPUState *cpu)
         }
     } while (ret == 0);
 
+    if (periscope_shutdown_requested()) {
+        printf("periscope: shutdown request noticed. restoring VM...");
+
+        // TODO: error reporting?
+        periscope_restore_request();
+
+        vm_stop(RUN_STATE_RESTORE_VM);
+    }
+
     cpu_exec_end(cpu);
     qemu_mutex_lock_iothread();
 
@@ -2144,7 +2469,17 @@ int kvm_vcpu_ioctl(CPUState *cpu, int type, ...)
     va_end(ap);
 
     trace_kvm_vcpu_ioctl(cpu->cpu_index, type, arg);
+
+#ifdef PERISCOPE_TIMERS
+    peri_timer *pt = NULL;
+    if(type == KVM_RUN)
+       pt = start_interval("periscope_kvm_run.timer");
+#endif
     ret = ioctl(cpu->kvm_fd, type, arg);
+#ifdef PERISCOPE_TIMERS
+    if(pt)
+       stop_interval(pt);
+#endif
     if (ret == -1) {
         ret = -errno;
     }
diff --git accel/kvm/trace-events accel/kvm/trace-events
index 33c5b1b3af..155d02554b 100644
--- accel/kvm/trace-events
+++ accel/kvm/trace-events
@@ -1,5 +1,8 @@
 # See docs/devel/tracing.txt for syntax documentation.
 
+kvm_get_dirty_pages_log_range(uint64_t start, uint64_t pages) "start 0x%" PRIx64 " pages 0x%" PRIx64
+kvm_log_sync(void) ""
+
 # kvm-all.c
 kvm_ioctl(int type, void *arg) "type 0x%x, arg %p"
 kvm_vm_ioctl(int type, void *arg) "type 0x%x, arg %p"
diff --git configure configure
index 1c563a7027..aea4f17f3e 100755
--- configure
+++ configure
@@ -434,6 +434,7 @@ cpuid_h="no"
 avx2_opt=""
 zlib="yes"
 capstone=""
+agamotto=""
 lzo=""
 snappy=""
 bzip2=""
@@ -1504,6 +1505,8 @@ for opt do
   ;;
   --enable-capstone=system) capstone="system"
   ;;
+  --with-agamotto=*) agamotto="$optarg"
+  ;;
   --with-git=*) git="$optarg"
   ;;
   --enable-git-update) git_update=yes
@@ -1816,6 +1819,7 @@ disabled with --disable-FEATURE, default is enabled if available:
   sheepdog        sheepdog block driver support
   crypto-afalg    Linux AF_ALG crypto backend driver
   capstone        capstone disassembler support
+  agamotto        agamotto checkpoint support
   debug-mutex     mutex debugging support
   libpmem         libpmem support
 
@@ -4987,6 +4991,14 @@ EOF
   fi
 fi
 
+##########################################
+# agamotto
+
+if test -e "$agamotto"; then
+  QEMU_CFLAGS="$QEMU_CFLAGS -I$agamotto"
+  LIBS="-L$agamotto -lagamotto_nomain $LIBS"
+fi
+
 ##########################################
 # capstone
 
@@ -7200,6 +7212,9 @@ fi
 if test "$capstone" != "no" ; then
   echo "CONFIG_CAPSTONE=y" >> $config_host_mak
 fi
+if test -e "$agamotto"; then
+  echo "CONFIG_PERISCOPE=y" >> $config_host_mak
+fi
 if test "$debug_mutex" = "yes" ; then
   echo "CONFIG_DEBUG_MUTEX=y" >> $config_host_mak
 fi
diff --git exec.c exec.c
index 6ab62f4eee..3c4874c0b5 100644
--- exec.c
+++ exec.c
@@ -1381,6 +1381,55 @@ bool cpu_physical_memory_test_and_clear_dirty(ram_addr_t start,
     return dirty;
 }
 
+DirtyBitmapSnapshot *cpu_physical_memory_snapshot_and_get_dirty
+     (ram_addr_t start, ram_addr_t length, unsigned client)
+{
+    DirtyMemoryBlocks *blocks;
+    unsigned long align = 1UL << (TARGET_PAGE_BITS + BITS_PER_LEVEL);
+    ram_addr_t first = QEMU_ALIGN_DOWN(start, align);
+    ram_addr_t last  = QEMU_ALIGN_UP(start + length, align);
+    DirtyBitmapSnapshot *snap;
+    unsigned long page, end, dest;
+
+    snap = g_malloc0(sizeof(*snap) +
+                     ((last - first) >> (TARGET_PAGE_BITS + 3)));
+    snap->start = first;
+    snap->end   = last;
+
+    page = first >> TARGET_PAGE_BITS;
+    end  = last  >> TARGET_PAGE_BITS;
+    dest = 0;
+
+    rcu_read_lock();
+
+    blocks = atomic_rcu_read(&ram_list.dirty_memory[client]);
+
+    while (page < end) {
+        unsigned long idx = page / DIRTY_MEMORY_BLOCK_SIZE;
+        unsigned long offset = page % DIRTY_MEMORY_BLOCK_SIZE;
+        unsigned long num = MIN(end - page, DIRTY_MEMORY_BLOCK_SIZE - offset);
+
+        assert(QEMU_IS_ALIGNED(offset, (1 << BITS_PER_LEVEL)));
+        assert(QEMU_IS_ALIGNED(num,    (1 << BITS_PER_LEVEL)));
+        offset >>= BITS_PER_LEVEL;
+
+        bitmap_copy_atomic(snap->dirty + dest,
+                                     blocks->blocks[idx] + offset,
+                                     num);
+        page += num;
+        dest += num >> BITS_PER_LEVEL;
+    }
+
+    rcu_read_unlock();
+
+    if (tcg_enabled()) {
+        tlb_reset_dirty_range_all(start, length);
+    }
+
+    return snap;
+}
+
+
 DirtyBitmapSnapshot *cpu_physical_memory_snapshot_and_clear_dirty
      (ram_addr_t start, ram_addr_t length, unsigned client)
 {
@@ -2625,6 +2674,9 @@ RAMBlock *qemu_ram_block_from_host(void *ptr, bool round_offset,
         if (host - block->host < block->max_length) {
             goto found;
         }
+        if (host - block->host_restore < block->max_length) {
+            goto found;
+        }
     }
 
     rcu_read_unlock();
diff --git hmp-commands-info.hx hmp-commands-info.hx
index c59444c461..03578b398c 100644
--- hmp-commands-info.hx
+++ hmp-commands-info.hx
@@ -431,6 +431,20 @@ STEXI
 @item info snapshots
 @findex info snapshots
 Show the currently saved VM snapshots.
+ETEXI
+
+    {
+        .name       = "snapshots-minimal",
+        .args_type  = "",
+        .params     = "",
+        .help       = "show the currently saved minimal VM snapshots",
+        .cmd        = hmp_info_snapshots_minimal,
+    },
+
+STEXI
+@item info snapshots-minimal
+@findex info snapshots-minimal
+Show the currently saved minimal VM snapshots.
 ETEXI
 
     {
diff --git hmp-commands.hx hmp-commands.hx
index 9b4035965c..593ca3ea04 100644
--- hmp-commands.hx
+++ hmp-commands.hx
@@ -365,6 +365,23 @@ a snapshot with the same tag, it is replaced. More info at
 
 Since 4.0, savevm stopped allowing the snapshot id to be set, accepting
 only @var{tag} as parameter.
+ETEXI
+
+    {
+        .name       = "savevm-minimal",
+        .args_type  = "name:s?",
+        .params     = "[tag|id]",
+        .help       = "save a VM snapshot. If no tag or id are provided, a new snapshot is created",
+        .cmd        = hmp_savevm_minimal,
+    },
+
+STEXI
+@item savevm-minimal [@var{tag}|@var{id}]
+@findex savevm-minimal
+Create a snapshot of the whole virtual machine. If @var{tag} is
+provided, it is used as human readable identifier. If there is already
+a snapshot with the same tag or ID, it is replaced. More info at
+@ref{vm_snapshots}.
 ETEXI
 
     {
@@ -383,6 +400,22 @@ Set the whole virtual machine to the snapshot identified by the tag
 @var{tag}.
 
 Since 4.0, loadvm stopped accepting snapshot id as parameter.
+ETEXI
+
+    {
+        .name       = "loadvm-minimal",
+        .args_type  = "name:s",
+        .params     = "tag|id",
+        .help       = "restore a VM snapshot from its tag or id",
+        .cmd        = hmp_loadvm_minimal,
+        .command_completion = loadvm_minimal_completion,
+    },
+
+STEXI
+@item loadvm-minimal @var{tag}|@var{id}
+@findex loadvm-minimal
+Set the whole virtual machine to the snapshot identified by the tag
+@var{tag} or the unique snapshot ID @var{id}.
 ETEXI
 
     {
@@ -1911,6 +1944,39 @@ ETEXI
 STEXI
 @item qom-set @var{path} @var{property} @var{value}
 Set QOM property @var{property} of object at location @var{path} to value @var{value}
+ETEXI
+{
+		.name       = "kcov-ioctl",
+		.args_type  = "cmd:i,arg:i",
+		.params     = "cmd,arg",
+		.help       = "kcov-ioctl cmd arg",
+		.cmd        = hmp_kcov_ioctl,
+},
+STEXI
+@item kcov-ioctl  @var{cmd} @var{arg}
+Exec kcov-ioctl @var{cmd} @var{arg}.
+ETEXI
+{
+		.name       = "kcov-get-area-offset",
+		.args_type  = "",
+		.params     = "",
+		.help       = "kcov-get-area-offset",
+		.cmd        = hmp_kcov_get_area_offset,
+},
+STEXI
+@item kcov-get-area-offset
+Exec kcov-get-area-offset
+ETEXI
+{
+		.name       = "kcov-print-coverage",
+		.args_type  = "",
+		.params     = "",
+		.help       = "kcov-print-coverage",
+		.cmd        = hmp_kcov_print_coverage,
+},
+STEXI
+@item kcov-print-coverage
+Exec kcov-print-coverage
 ETEXI
 
     {
@@ -1926,3 +1992,4 @@ ETEXI
 STEXI
 @end table
 ETEXI
+
diff --git hmp.c hmp.c
index 8eec768088..89aba7e115 100644
--- hmp.c
+++ hmp.c
@@ -38,6 +38,7 @@
 #include "qapi/qapi-commands-run-state.h"
 #include "qapi/qapi-commands-tpm.h"
 #include "qapi/qapi-commands-ui.h"
+#include "qapi/qapi-commands-kcov.h"
 #include "qapi/qmp/qdict.h"
 #include "qapi/qmp/qerror.h"
 #include "qapi/string-input-visitor.h"
@@ -1466,6 +1467,23 @@ void hmp_loadvm(Monitor *mon, const QDict *qdict)
     hmp_handle_error(mon, &err);
 }
 
+void hmp_loadvm_minimal(Monitor *mon, const QDict *qdict)
+{
+    printf("TODO: hmp_loadvm_minimal\n");
+
+#if 0
+    int saved_vm_running  = runstate_is_running();
+    const char *name = qdict_get_str(qdict, "name");
+    Error *err = NULL;
+    vm_stop(RUN_STATE_RESTORE_VM);
+
+    if (load_snapshot(name, &err) == 0 && saved_vm_running) {
+        vm_start();
+    }
+    hmp_handle_error(mon, &err);
+#endif
+}
+
 void hmp_savevm(Monitor *mon, const QDict *qdict)
 {
     Error *err = NULL;
@@ -1474,6 +1492,17 @@ void hmp_savevm(Monitor *mon, const QDict *qdict)
     hmp_handle_error(mon, &err);
 }
 
+void hmp_savevm_minimal(Monitor *mon, const QDict *qdict)
+{
+    printf("TODO: hmp_savevm_minimal\n");
+#if 0
+    Error *err = NULL;
+
+    save_snapshot(qdict_get_try_str(qdict, "name"), &err);
+    hmp_handle_error(mon, &err);
+#endif
+}
+
 void hmp_delvm(Monitor *mon, const QDict *qdict)
 {
     BlockDriverState *bs;
@@ -1630,6 +1659,11 @@ void hmp_info_snapshots(Monitor *mon, const QDict *qdict)
 
 }
 
+void hmp_info_snapshots_minimal(Monitor *mon, const QDict *qdict)
+{
+    printf("TODO: hmp_info_snapshots_minimal\n");
+}
+
 void hmp_announce_self(Monitor *mon, const QDict *qdict)
 {
     qmp_announce_self(migrate_announce_params(), NULL);
@@ -3154,3 +3188,20 @@ void hmp_info_memory_size_summary(Monitor *mon, const QDict *qdict)
     }
     hmp_handle_error(mon, &err);
 }
+
+void hmp_kcov_get_area_offset(Monitor *mon, const QDict *qdict)
+{
+	qmp_kcov_get_area_offset(NULL);
+}
+
+void hmp_kcov_ioctl(Monitor *mon, const QDict *qdict)
+{
+	int64_t cmd = qdict_get_int(qdict, "cmd");
+	int64_t arg = qdict_get_int(qdict, "arg");
+	qmp_kcov_ioctl(cmd, arg, NULL);
+}
+
+void hmp_kcov_print_coverage(Monitor *mon, const QDict *qdict)
+{
+   qmp_kcov_print_coverage(NULL);
+}
diff --git hmp.h hmp.h
index 43617f2646..ac6ba96d79 100644
--- hmp.h
+++ hmp.h
@@ -66,9 +66,12 @@ void hmp_snapshot_delete_blkdev_internal(Monitor *mon, const QDict *qdict);
 void hmp_drive_mirror(Monitor *mon, const QDict *qdict);
 void hmp_drive_backup(Monitor *mon, const QDict *qdict);
 void hmp_loadvm(Monitor *mon, const QDict *qdict);
+void hmp_loadvm_minimal(Monitor *mon, const QDict *qdict);
 void hmp_savevm(Monitor *mon, const QDict *qdict);
+void hmp_savevm_minimal(Monitor *mon, const QDict *qdict);
 void hmp_delvm(Monitor *mon, const QDict *qdict);
 void hmp_info_snapshots(Monitor *mon, const QDict *qdict);
+void hmp_info_snapshots_minimal(Monitor *mon, const QDict *qdict);
 void hmp_migrate_cancel(Monitor *mon, const QDict *qdict);
 void hmp_migrate_continue(Monitor *mon, const QDict *qdict);
 void hmp_migrate_incoming(Monitor *mon, const QDict *qdict);
@@ -140,6 +143,7 @@ void migrate_set_parameter_completion(ReadLineState *rs, int nb_args,
                                       const char *str);
 void delvm_completion(ReadLineState *rs, int nb_args, const char *str);
 void loadvm_completion(ReadLineState *rs, int nb_args, const char *str);
+void loadvm_minimal_completion(ReadLineState *rs, int nb_args, const char *str);
 void hmp_rocker(Monitor *mon, const QDict *qdict);
 void hmp_rocker_ports(Monitor *mon, const QDict *qdict);
 void hmp_rocker_of_dpa_flows(Monitor *mon, const QDict *qdict);
@@ -151,4 +155,7 @@ void hmp_info_vm_generation_id(Monitor *mon, const QDict *qdict);
 void hmp_info_memory_size_summary(Monitor *mon, const QDict *qdict);
 void hmp_info_sev(Monitor *mon, const QDict *qdict);
 
+void hmp_kcov_ioctl(Monitor *mon, const QDict *qdict);
+void hmp_kcov_get_area_offset(Monitor *mon, const QDict *qdict);
+void hmp_kcov_print_coverage(Monitor *mon, const QDict *qdict);
 #endif
diff --git hw/Makefile.objs hw/Makefile.objs
index 82aa7fab8e..7ce452da1c 100644
--- hw/Makefile.objs
+++ hw/Makefile.objs
@@ -19,6 +19,7 @@ devices-dirs-$(CONFIG_IPMI) += ipmi/
 devices-dirs-$(CONFIG_SOFTMMU) += isa/
 devices-dirs-$(CONFIG_SOFTMMU) += misc/
 devices-dirs-$(CONFIG_SOFTMMU) += net/
+devices-dirs-$(CONFIG_SOFTMMU) += periscope/
 devices-dirs-$(CONFIG_SOFTMMU) += rdma/
 devices-dirs-$(CONFIG_SOFTMMU) += nvram/
 devices-dirs-$(CONFIG_SOFTMMU) += pci/
diff --git hw/i386/intel_iommu.c hw/i386/intel_iommu.c
index 2558f48fe6..aa7a695f19 100644
--- hw/i386/intel_iommu.c
+++ hw/i386/intel_iommu.c
@@ -301,6 +301,23 @@ out:
     return entry;
 }
 
+static inline uint16_t vtd_make_source_id(uint8_t bus_num, uint8_t devfn)
+{
+    return ((bus_num & 0xffUL) << 8) | (devfn & 0xffUL);
+}
+
+int vtd_lookup_gfn(IntelIOMMUState *s, uint8_t bus_num, uint8_t devfn,
+                   hwaddr addr, uint64_t *gfn)
+{
+    uint16_t source_id = vtd_make_source_id(bus_num, devfn);
+    VTDIOTLBEntry *entry = vtd_lookup_iotlb(s, source_id, addr);
+    if (!entry) {
+        return -1;
+    }
+    *gfn = entry->gfn;
+    return 0;
+}
+
 /* Must be with IOMMU lock held */
 static void vtd_update_iotlb(IntelIOMMUState *s, uint16_t source_id,
                              uint16_t domain_id, hwaddr addr, uint64_t slpte,
@@ -1358,6 +1375,77 @@ static int vtd_dev_to_context_entry(IntelIOMMUState *s, uint8_t bus_num,
     return 0;
 }
 
+int vtd_dev_to_domain_id(IntelIOMMUState *s, uint8_t bus_num,
+                         uint8_t devfn, uint16_t *domain_id)
+{
+    VTDContextEntry ce;
+    int ret = vtd_dev_to_context_entry(s, bus_num, devfn, &ce);
+    if (ret == 0) {
+        *domain_id = VTD_CONTEXT_ENTRY_DID(ce.hi);
+    }
+    return ret;
+}
+
+
+int vtd_iova_to_gpa_writable(IntelIOMMUState *s, uint8_t bus_num,
+                    uint8_t devfn, uint64_t iova, uint64_t *gpa) {
+    VTDContextEntry ce;
+    int ret = vtd_dev_to_context_entry(s, bus_num, devfn, &ce);
+    if (ret < 0) {
+        return ret;
+    }
+
+    bool is_write = true;
+    uint64_t slpte;
+    uint32_t slpte_level;
+    bool reads, writes;
+
+    uint8_t aw_bits = VTD_HOST_ADDRESS_WIDTH;
+
+    ret = vtd_iova_to_slpte(s, &ce, iova, is_write,
+                            &slpte, &slpte_level,
+                            &reads, &writes, aw_bits);
+    if (ret < 0) {
+        return ret;
+    }
+
+    uint64_t page_mask = vtd_slpt_level_page_mask(slpte_level);
+
+    *gpa = vtd_get_slpte_addr(slpte, aw_bits) & page_mask;
+
+    return 0;
+}
+
+
+int vtd_iova_to_gpa(IntelIOMMUState *s, uint8_t bus_num,
+                    uint8_t devfn, uint64_t iova, uint64_t *gpa) {
+    VTDContextEntry ce;
+    int ret = vtd_dev_to_context_entry(s, bus_num, devfn, &ce);
+    if (ret < 0) {
+        return ret;
+    }
+
+    bool is_write = false;
+    uint64_t slpte;
+    uint32_t slpte_level;
+    bool reads, writes;
+
+    uint8_t aw_bits = VTD_HOST_ADDRESS_WIDTH;
+
+    ret = vtd_iova_to_slpte(s, &ce, iova, is_write,
+                            &slpte, &slpte_level,
+                            &reads, &writes, aw_bits);
+    if (ret < 0) {
+        return ret;
+    }
+
+    uint64_t page_mask = vtd_slpt_level_page_mask(slpte_level);
+
+    *gpa = vtd_get_slpte_addr(slpte, aw_bits) & page_mask;
+
+    return 0;
+}
+
 static int vtd_sync_shadow_page_hook(IOMMUTLBEntry *entry,
                                      void *private)
 {
@@ -1525,11 +1613,6 @@ static void vtd_switch_address_space_all(IntelIOMMUState *s)
     }
 }
 
-static inline uint16_t vtd_make_source_id(uint8_t bus_num, uint8_t devfn)
-{
-    return ((bus_num & 0xffUL) << 8) | (devfn & 0xffUL);
-}
-
 static const bool vtd_qualified_faults[] = {
     [VTD_FR_RESERVED] = false,
     [VTD_FR_ROOT_ENTRY_P] = false,
diff --git hw/i386/kvmvapic.c hw/i386/kvmvapic.c
index 70f6f26a94..1d659ab911 100644
--- hw/i386/kvmvapic.c
+++ hw/i386/kvmvapic.c
@@ -583,6 +583,8 @@ static int vapic_map_rom_writable(VAPICROMState *s)
     as = sysbus_address_space(&s->busdev);
 
     if (s->rom_mapped_writable) {
+        // XXX this only works for resets done by periscope!
+        return 0;
         memory_region_del_subregion(as, &s->rom);
         object_unparent(OBJECT(&s->rom));
     }
diff --git hw/i386/pc.c hw/i386/pc.c
index f2c15bf1f2..54428ac3e4 100644
--- hw/i386/pc.c
+++ hw/i386/pc.c
@@ -77,6 +77,7 @@
 #include "hw/i386/intel_iommu.h"
 #include "hw/net/ne2000-isa.h"
 #include "standard-headers/asm-x86/bootparam.h"
+#include "migration/periscope_perf_switches.h"
 
 /* debug PC/ISA interrupts */
 //#define DEBUG_IRQ
@@ -2624,7 +2625,7 @@ static void pc_machine_reset(void)
     CPUState *cs;
     X86CPU *cpu;
 
-    qemu_devices_reset();
+    if(!quick_reset_devs) qemu_devices_reset();
 
     /* Reset APIC after devices have been reset to cancel
      * any changes that qemu_devices_reset() might have done.
@@ -2633,7 +2634,7 @@ static void pc_machine_reset(void)
         cpu = X86_CPU(cs);
 
         if (cpu->apic_state) {
-            device_reset(cpu->apic_state);
+            if(!quick_reset_devs) device_reset(cpu->apic_state);
         }
     }
 }
diff --git hw/misc/ivshmem.c hw/misc/ivshmem.c
index c7b6bbc974..ef3d621c9b 100644
--- hw/misc/ivshmem.c
+++ hw/misc/ivshmem.c
@@ -109,6 +109,8 @@ typedef struct IVShmemState {
     uint64_t msg_buf;           /* buffer for receiving server messages */
     int msg_buffered_bytes;     /* #bytes in @msg_buf */
 
+    OnOffAuto chkpt;
+
     /* migration stuff */
     OnOffAuto master;
     Error *migration_blocker;
@@ -939,7 +941,11 @@ static void ivshmem_common_realize(PCIDevice *dev, Error **errp)
         }
     }
 
-    vmstate_register_ram(s->ivshmem_bar2, DEVICE(s));
+
+    if (s->chkpt == ON_OFF_AUTO_ON) {
+        vmstate_register_ram(s->ivshmem_bar2, DEVICE(s));
+    }
+
     pci_register_bar(PCI_DEVICE(s), 2,
                      PCI_BASE_ADDRESS_SPACE_MEMORY |
                      PCI_BASE_ADDRESS_MEM_PREFETCH |
@@ -971,7 +977,9 @@ static void ivshmem_exit(PCIDevice *dev)
             close(fd);
         }
 
-        vmstate_unregister_ram(s->ivshmem_bar2, DEVICE(dev));
+        if (s->chkpt == ON_OFF_AUTO_ON) {
+            vmstate_unregister_ram(s->ivshmem_bar2, DEVICE(dev));
+        }
     }
 
     if (s->hostmem) {
@@ -1059,6 +1067,7 @@ static const VMStateDescription ivshmem_plain_vmsd = {
 
 static Property ivshmem_plain_properties[] = {
     DEFINE_PROP_ON_OFF_AUTO("master", IVShmemState, master, ON_OFF_AUTO_OFF),
+    DEFINE_PROP_ON_OFF_AUTO("chkpt", IVShmemState, chkpt, ON_OFF_AUTO_OFF),
     DEFINE_PROP_LINK("memdev", IVShmemState, hostmem, TYPE_MEMORY_BACKEND,
                      HostMemoryBackend *),
     DEFINE_PROP_END_OF_LIST(),
diff --git hw/pci/pci.c hw/pci/pci.c
index 6d13ef877b..3d6e39a8ed 100644
--- hw/pci/pci.c
+++ hw/pci/pci.c
@@ -1671,6 +1671,35 @@ static void pci_for_each_device_under_bus(PCIBus *bus,
     }
 }
 
+PCIDevice *get_pcidev_by_name(const char* name)
+{
+    PCIDevice *d;
+    int devfn;
+
+    if(!name)
+       return NULL;
+
+    PCIHostState *host_bridge;
+    QLIST_FOREACH(host_bridge, &pci_host_bridges, next) {
+       for(devfn = 0; devfn < ARRAY_SIZE(host_bridge->bus->devices); devfn++) {
+          d = host_bridge->bus->devices[devfn];
+          if (d && d->name && strncmp(d->name, name, strlen(name)) == 0) {
+             return d;
+          }
+       }
+    }
+    return NULL;
+}
+//void pci_for_each_device_xxx(
+//                         void (*fn)(PCIBus *b, PCIDevice *d, void *opaque),
+//                         void *opaque)
+//{
+//   PCIHostState *host_bridge;
+//   QLIST_FOREACH(host_bridge, &pci_host_bridges, next) {
+//      pci_for_each_device_under_bus(host_bridge->bus, fn, opaque);
+//   }
+//}
+
 void pci_for_each_device(PCIBus *bus, int bus_num,
                          void (*fn)(PCIBus *b, PCIDevice *d, void *opaque),
                          void *opaque)
diff --git hw/periscope/Makefile.objs hw/periscope/Makefile.objs
new file mode 100644
index 0000000000..513c87d58b
--- /dev/null
+++ hw/periscope/Makefile.objs
@@ -0,0 +1,8 @@
+common-obj-$(CONFIG_PCI) += pci.o
+common-obj-$(CONFIG_VIRTIO) += virtio.o
+common-obj-$(CONFIG_PCI) += kcov_dev.o
+common-obj-$(CONFIG_PCI) += kvm_api_test.o
+common-obj-$(CONFIG_PCI) += pci-i2c.o
+common-obj-$(CONFIG_PCI) += i2c.o
+common-obj-$(CONFIG_SD) += sd.o
+common-obj-$(CONFIG_USB) += usb.o
diff --git hw/periscope/i2c.c hw/periscope/i2c.c
new file mode 100644
index 0000000000..8be2fdc8c8
--- /dev/null
+++ hw/periscope/i2c.c
@@ -0,0 +1,146 @@
+#include "qemu/osdep.h"
+#include "hw/i2c/i2c.h"
+#include "hw/i2c/smbus_slave.h"
+#include "qemu-common.h"
+#include "qemu/log.h"
+
+#include "hw/display/edid.h"
+
+struct I2CPeriScopeState {
+  /*< private >*/
+#if 1
+  SMBusDevice smb;
+#else
+  I2CSlave i2c;
+#endif
+  /*< public >*/
+  bool firstbyte;
+  uint8_t reg;
+  qemu_edid_info edid_info;
+  uint8_t edid_blob[128];
+};
+
+typedef struct I2CPeriScopeState I2CPeriScopeState;
+
+#define TYPE_I2CPERISCOPE "periscope-i2c"
+#define I2CPERISCOPE(obj)                                                      \
+  OBJECT_CHECK(I2CPeriScopeState, (obj), TYPE_I2CPERISCOPE)
+
+static void i2c_periscope_reset(DeviceState *ds) {
+  I2CPeriScopeState *s = I2CPERISCOPE(ds);
+
+  s->firstbyte = false;
+  s->reg = 0;
+}
+
+static int i2c_periscope_event(I2CSlave *i2c, enum i2c_event event) {
+  I2CPeriScopeState *s = I2CPERISCOPE(i2c);
+
+  printf("periscope: i2c_periscope_event\n");
+
+  if (event == I2C_START_SEND) {
+    s->firstbyte = true;
+  }
+
+  return 0;
+}
+
+static uint8_t i2c_periscope_rx(I2CSlave *i2c) {
+  I2CPeriScopeState *s = I2CPERISCOPE(i2c);
+
+  printf("periscope: i2c_periscope_rx\n");
+
+  int value;
+  value = s->edid_blob[s->reg % sizeof(s->edid_blob)];
+  s->reg++;
+  return value;
+}
+
+static int i2c_periscope_tx(I2CSlave *i2c, uint8_t data) {
+  I2CPeriScopeState *s = I2CPERISCOPE(i2c);
+
+  printf("periscope: i2c_periscope_tx\n");
+
+  if (s->firstbyte) {
+    s->reg = data;
+    s->firstbyte = false;
+    printf("periscope: [EDID] Written new pointer: %u\n", data);
+    return 0;
+  }
+
+  /* Ignore all writes */
+  s->reg++;
+  return 0;
+}
+
+static void quick_cmd(SMBusDevice *dev, uint8_t read) {
+  printf("periscope: quick_cmd\n");
+}
+
+static int write_data(SMBusDevice *dev, uint8_t *buf, uint8_t len) {
+  printf("periscope: write_data\n");
+  return 0;
+}
+
+static uint8_t receive_byte(SMBusDevice *dev) {
+  printf("periscope: receive_byte\n");
+  return 0;
+}
+
+static void i2c_periscope_init(Object *obj) {
+  I2CPeriScopeState *s = I2CPERISCOPE(obj);
+
+  qemu_edid_generate(s->edid_blob, sizeof(s->edid_blob), &s->edid_info);
+}
+
+static const VMStateDescription vmstate_i2c_periscope = {
+    .name = TYPE_I2CPERISCOPE,
+    .version_id = 1,
+    .fields = (VMStateField[]){VMSTATE_BOOL(firstbyte, I2CPeriScopeState),
+                               VMSTATE_UINT8(reg, I2CPeriScopeState),
+                               VMSTATE_END_OF_LIST()}};
+
+static Property i2c_periscope_properties[] = {
+    DEFINE_EDID_PROPERTIES(I2CPeriScopeState, edid_info),
+    DEFINE_PROP_END_OF_LIST(),
+};
+
+static void i2c_periscope_class_init(ObjectClass *oc, void *data) {
+  DeviceClass *dc = DEVICE_CLASS(oc);
+#if 1
+  SMBusDeviceClass *smbdc = SMBUS_DEVICE_CLASS(oc);
+//#else
+  I2CSlaveClass *isc = I2C_SLAVE_CLASS(oc);
+#endif
+
+  dc->reset = i2c_periscope_reset;
+  dc->vmsd = &vmstate_i2c_periscope;
+  dc->props = i2c_periscope_properties;
+#if 1
+  smbdc->quick_cmd = quick_cmd;
+  smbdc->write_data = write_data;
+  smbdc->receive_byte = receive_byte;
+//#else
+  isc->event = i2c_periscope_event;
+  isc->recv = i2c_periscope_rx;
+  isc->send = i2c_periscope_tx;
+#endif
+}
+
+static TypeInfo i2c_periscope_info = {
+    .name = TYPE_I2CPERISCOPE,
+#if 1
+    .parent = TYPE_SMBUS_DEVICE,
+#else
+    .parent = TYPE_I2C_SLAVE,
+#endif
+    .instance_size = sizeof(I2CPeriScopeState),
+    .instance_init = i2c_periscope_init,
+    .class_init = i2c_periscope_class_init
+};
+
+static void register_devices(void) {
+  type_register_static(&i2c_periscope_info);
+}
+
+type_init(register_devices);
diff --git hw/periscope/kcov_dev.c hw/periscope/kcov_dev.c
new file mode 100644
index 0000000000..3544fd8eda
--- /dev/null
+++ hw/periscope/kcov_dev.c
@@ -0,0 +1,329 @@
+#include "qemu/osdep.h"
+#include "exec/cpu-common.h"
+#include "migration/ram.h"
+#include "hw/pci/pci.h"
+#include "kcov_vdev.h"
+
+#define DEVICE_NAME "kcov_vdev"
+
+
+typedef struct {
+   /*< private >*/
+   PCIDevice parent_obj;
+   MemoryRegion mmio;
+   /*< public >*/
+   uint64_t area_offset;
+   bool trace_pc; // as opposed to trace_afl
+   bool trace_pc_flush; // flush cov buffer when full only if trace_pc && trace_pc_flush
+   bool trace_global; // enable collecting global coverage regardless of kernel control path contexts (e.g., softirq)
+} KCovState;
+
+typedef struct {
+   unsigned int cmd;
+   unsigned int arg;
+   unsigned int ret;
+} kcov_mmio_state;
+
+static kcov_mmio_state mstate;
+static uint64_t kcov_area_offset = 0;
+
+#define FF(_b) (0xff << ((_b) << 3))
+
+static uint32_t count_bytes(uint8_t *mem) {
+  uint32_t *ptr = (uint32_t *)mem;
+  uint32_t i = (KCOV_MAP_SIZE >> 2);
+  uint32_t ret = 0;
+
+  while (i--) {
+    uint32_t v = *(ptr++);
+
+    if (!v) continue;
+    if (v & FF(0)) ret++;
+    if (v & FF(1)) ret++;
+    if (v & FF(2)) ret++;
+    if (v & FF(3)) ret++;
+  }
+
+  return ret;
+}
+
+void kcov_print_coverage(void)
+{
+   if(!kcov_area_offset) {
+      printf("%s: no kcov area offset set (use kcov-get-area-offset qmp)\n", __FUNCTION__);
+      return;
+   }
+
+   RAMBlock *block = qemu_ram_block_by_name("pc.ram");
+   if(!block) {
+      printf("%s: could not find ramblock\n", __FUNCTION__);
+      return;
+   }
+
+   uint64_t* host = host_from_ram_block_offset(block, kcov_area_offset);
+   if(host) {
+      printf("%s: %lx (count=%u)\n", __FUNCTION__, host[0], count_bytes((uint8_t *)host));
+   } else {
+      printf("%s: could not get host ptr\n", __FUNCTION__);
+   }
+}
+
+uint8_t *kcov_get_area(void)
+{
+   if(kcov_area_offset == 0) {
+      printf("%s: no kcov area offset set (use kcov-get-area-offset qmp)\n", __FUNCTION__);
+      return NULL;
+   }
+
+   RAMBlock *block = qemu_ram_block_by_name("pc.ram");
+   if(!block) {
+      printf("%s: could not find ramblock\n", __FUNCTION__);
+      return NULL;
+   }
+
+   uint64_t* host = host_from_ram_block_offset(block, kcov_area_offset);
+   return (uint8_t *)host;
+}
+
+// get physical offset of kcov coverage bitmap from guest
+int kcov_get_area_offset(void *opaque)
+{
+   PCIDevice *pdev = opaque;
+   mstate.cmd = KCOV_GET_AREA_OFFSET;
+   mstate.arg = 0;
+   pci_set_irq(pdev, 1);
+   return 0;
+}
+
+void kcov_flush_area(bool no_print) {
+    uint64_t *area = (uint64_t *)kcov_get_area();
+    static uint64_t prev_pc = 0L;
+    uint64_t max_pcs = KCOV_MAP_SIZE / sizeof(uint64_t) - 1;
+    uint64_t num_pcs = area[0];
+
+    if (no_print) {
+        printf("periscope: flushing kcov area\n");
+        area[0] = 0;
+        return;
+    }
+
+    if (num_pcs > max_pcs) {
+        printf("periscope: kcov area overflown? max=%lu, num=%lu\n",
+               max_pcs, num_pcs);
+        num_pcs = max_pcs;
+    }
+
+    if (num_pcs == 0) return;
+
+    uint64_t num_skipped = 1;
+    while (num_skipped < 1 + num_pcs) {
+        if (area[num_skipped] != prev_pc) {
+            break;
+        }
+        num_skipped++;
+    }
+
+    if (num_skipped == 1 + num_pcs) return;
+
+    printf("periscope: pcs=[");
+
+    bool printed = false;
+    for (uint64_t i = num_skipped; i < 1 + num_pcs; i++) {
+        if (prev_pc == area[i]) continue;
+        if (printed) {
+            printf(",");
+        }
+        printf("0x%lx", area[i]);
+        prev_pc = area[i];
+        printed = true;
+    }
+    printf("]\n");
+
+    area[0] = 0;
+}
+
+// send kcov ioctl to guest kcov driver
+int kcov_ioctl(void *opaque, unsigned int cmd, unsigned int arg)
+{
+   PCIDevice *pdev = opaque;
+   mstate.cmd = cmd;
+   mstate.arg = arg;
+   printf("%s: state %p\n", __FUNCTION__, pdev);
+   pci_set_irq(pdev, 1);
+   return 0;
+}
+
+static uint64_t mmio_read(void *opaque, hwaddr addr, unsigned size)
+{
+   KCovState *s = opaque;
+   //printf(DEVICE_NAME " mmio_read addr = %llx size = %x\n", (unsigned long long)addr, size);
+   switch (addr) {
+      case KCOV_CMD_OFFSET:
+         return mstate.cmd;
+      case KCOV_ARG_OFFSET:
+         return mstate.arg;
+      case KCOV_CCMODE_OFFSET:
+         if (s->trace_pc) {
+            if (s->trace_pc_flush)
+               return KCOV_TRACE_PC | ((unsigned int)1<<16);
+            return KCOV_TRACE_PC;
+         }
+         return KCOV_TRACE_AFL;
+      case KCOV_GMODE_OFFSET:
+         if (s->trace_global)
+            return 1;
+         return 0;
+   }
+   return 0x1234567812345678;
+}
+
+static void mmio_write(void *opaque, hwaddr addr, uint64_t val,
+      unsigned size)
+{
+   KCovState *state = opaque;
+
+#if 0
+   printf(DEVICE_NAME " mmio_write addr = %llx val = %llx size = %x\n",
+         (unsigned long long)addr, (unsigned long long)val, size);
+#endif
+   switch (addr) {
+      case KCOV_SET_IRQ:
+         pci_set_irq(&state->parent_obj, 1);
+         break;
+      case KCOV_RESET_IRQ:
+         pci_set_irq(&state->parent_obj, 0);
+         break;
+      case KCOV_RET_OFFSET:
+         state->area_offset = val;
+         kcov_area_offset = val;
+         printf(DEVICE_NAME " kcov area offset %lx\n", kcov_area_offset);
+         mstate.ret = 0;
+         break;
+      case KCOV_COV_ENABLE:
+         if (state->trace_pc) {
+            printf(DEVICE_NAME " kcov buffer enable %lx\n", val);
+            kcov_area_offset = val;
+         }
+         break;
+      case KCOV_COV_DISABLE:
+         if (state->trace_pc) {
+            printf(DEVICE_NAME " kcov buffer disable %lx\n", val);
+            kcov_area_offset = 0;
+         }
+         break;
+      case KCOV_COV_REMOTE_ENABLE:
+         if (state->trace_pc) {
+            printf(DEVICE_NAME " kcov buffer remote enable %lx\n", val);
+            kcov_area_offset = val;
+         }
+         break;
+      case KCOV_COV_REMOTE_DISABLE:
+         if (state->trace_pc) {
+            printf(DEVICE_NAME " kcov buffer remote disable %lx\n", val);
+            kcov_area_offset = 0;
+         }
+         break;
+      case KCOV_COV_COLLECT:
+         if (state->trace_pc) {
+            printf(DEVICE_NAME " kcov buffer collect %lx\n", val);
+            // TODO
+         }
+         break;
+      case KCOV_COV_FULL:
+         if (state->trace_pc) {
+            printf(DEVICE_NAME " kcov buffer full %lx\n", val);
+            kcov_flush_area(false);
+         }
+         break;
+//      case KCOV_RET_OFFSET + 4:
+//         kcov_area_offset = (kcov_area_offset & ~(0xffffffffUL)) | val;
+//         printf(DEVICE_NAME " kcov area offset %lx\n", kcov_area_offset);
+//         mstate.ret = 0;
+//         break;
+   }
+}
+
+static const MemoryRegionOps mmio_ops = {
+   .read = mmio_read,
+   .write = mmio_write,
+   .endianness = DEVICE_NATIVE_ENDIAN,
+};
+
+static void realize(PCIDevice *pdev, Error **errp)
+{
+   KCovState *state = DO_UPCAST(KCovState, parent_obj, pdev);
+
+   pci_config_set_interrupt_pin(pdev->config, 1);
+   memory_region_init_io(&state->mmio, OBJECT(state), &mmio_ops, state,
+         DEVICE_NAME, 1024);
+   pci_register_bar(pdev, 0, PCI_BASE_ADDRESS_SPACE_MEMORY, &state->mmio);
+}
+
+static int kcov_pre_save(void *opaque)
+{
+   return 0;
+}
+
+static int kcov_post_load(void *opaque, int version_id)
+{
+   KCovState *state = opaque;
+   kcov_area_offset = state->area_offset;
+   return 0;
+}
+
+static const VMStateDescription vmstate_kcov = {
+    .name = DEVICE_NAME,
+    .version_id = 1,
+    .minimum_version_id = 1,
+    .pre_save = kcov_pre_save,
+    .post_load = kcov_post_load,
+    .fields = (VMStateField[]) {
+        VMSTATE_PCI_DEVICE(parent_obj, KCovState),
+        VMSTATE_UINT64(area_offset, KCovState),
+        VMSTATE_BOOL(trace_pc, KCovState),
+        VMSTATE_BOOL(trace_pc_flush, KCovState),
+        VMSTATE_BOOL(trace_global, KCovState),
+        VMSTATE_END_OF_LIST()
+    }
+};
+
+static Property kcov_properties[] = {
+    DEFINE_PROP_BOOL("trace-pc", KCovState, trace_pc, false),
+    DEFINE_PROP_BOOL("trace-pc-flush", KCovState, trace_pc_flush, true),
+    DEFINE_PROP_BOOL("trace-global", KCovState, trace_global, true),
+    DEFINE_PROP_END_OF_LIST(),
+};
+
+static void class_init(ObjectClass *class, void *data)
+{
+   DeviceClass *dc = DEVICE_CLASS(class);
+   PCIDeviceClass *k = PCI_DEVICE_CLASS(class);
+
+   k->realize = realize;
+   k->vendor_id = PCI_VENDOR_ID_QEMU;
+   k->device_id = 0x11e9;
+   k->revision = 0x0;
+   k->class_id = PCI_CLASS_OTHERS;
+   dc->vmsd = &vmstate_kcov;
+   dc->props = kcov_properties;
+}
+
+static const TypeInfo type_info = {
+   .name          = DEVICE_NAME,
+   .parent        = TYPE_PCI_DEVICE,
+   .class_init    = class_init,
+   .instance_size = sizeof(KCovState),
+   .class_size = sizeof(PCIDeviceClass),
+   .interfaces =
+      (InterfaceInfo[]){
+         {INTERFACE_CONVENTIONAL_PCI_DEVICE}, {},
+      },
+
+};
+
+static void register_types(void)
+{
+   type_register_static(&type_info);
+}
+
+type_init(register_types)
diff --git hw/periscope/kcov_vdev.h hw/periscope/kcov_vdev.h
new file mode 100644
index 0000000000..22bb75b06a
--- /dev/null
+++ hw/periscope/kcov_vdev.h
@@ -0,0 +1,49 @@
+#ifndef KCOV_VDEV_H
+#define KCOV_VDEV_H
+
+#define KCOV_MAP_SIZE_POW2 16
+#define KCOV_MAP_SIZE (1 << KCOV_MAP_SIZE_POW2)
+
+uint8_t *kcov_get_area(void);
+void kcov_flush_area(bool);
+int kcov_get_area_offset(void *opaque);
+void kcov_print_coverage(void);
+int kcov_ioctl(void *opaque, unsigned int cmd, unsigned int arg);
+
+#define KCOV_SET_IRQ 0x0
+#define KCOV_RESET_IRQ 0x4
+#define KCOV_CMD_OFFSET 0x10
+#define KCOV_ARG_OFFSET 0x20
+#define KCOV_CMD_MMAP 0x30
+#define KCOV_RET_OFFSET 0x40
+#define KCOV_GET_AREA_OFFSET 0x50
+#define KCOV_CCMODE_OFFSET 0x60
+#define KCOV_COV_FULL 0x70
+#define KCOV_COV_ENABLE 0x80
+#define KCOV_COV_DISABLE 0x90
+#define KCOV_COV_REMOTE_ENABLE 0xa0
+#define KCOV_COV_REMOTE_DISABLE 0xb0
+#define KCOV_COV_COLLECT 0xc0
+#define KCOV_GMODE_OFFSET 0xf0
+
+#define KCOV_INIT_TRACE       _IOR('c', 1, unsigned long)
+#define KCOV_ENABLE        _IO('c', 100)
+#define KCOV_DISABLE       _IO('c', 101)
+
+enum {
+   KCOV_TRACE_PC = 0,
+   KCOV_TRACE_CMP = 1,
+	KCOV_TRACE_AFL = 2,
+};
+
+/*
+ * The format for the types of collected comparisons.
+ *
+ * Bit 0 shows whether one of the arguments is a compile-time constant.
+ * Bits 1 & 2 contain log2 of the argument size, up to 8 bytes.
+ */
+#define KCOV_CMP_CONST          (1 << 0)
+#define KCOV_CMP_SIZE(n)        ((n) << 1)
+#define KCOV_CMP_MASK           KCOV_CMP_SIZE(3)
+
+#endif
diff --git hw/periscope/kvm_api_test.c hw/periscope/kvm_api_test.c
new file mode 100644
index 0000000000..cc36648a90
--- /dev/null
+++ hw/periscope/kvm_api_test.c
@@ -0,0 +1,203 @@
+#include "qemu/osdep.h"
+#include "exec/cpu-common.h"
+#include "migration/ram.h"
+#include "migration/periscope_dma.h"
+#include "hw/pci/pci.h"
+#include "kvm_api_test.h"
+#include "qemu/iov.h"
+#include "hw/i386/x86-iommu.h"
+#include "hw/i386/intel_iommu.h"
+
+#define DEVICE_NAME "kvm_api_test"
+
+
+typedef struct {
+   /*< private >*/
+   PCIDevice parent_obj;
+   MemoryRegion mmio;
+} KvmApiTestState;
+
+typedef struct {
+   uint64_t map_addr;
+   uint64_t map_size;
+   uint64_t unmap_addr;
+} KvmApiDmaState;
+
+static KvmApiDmaState dma_state;
+
+typedef struct IommuTrace {
+    IOMMUMemoryRegion *iommu;
+    uint64_t gpa;
+    IOMMUNotifier n;
+} IommuTrace;
+
+
+static void pci_unmap_notify_func(IOMMUNotifier *n, IOMMUTLBEntry *iotlb) {
+   IommuTrace *iot = container_of(n, IommuTrace, n);
+   if(iot) {
+      printf("iova: %lx, tr. addr %lx, gpa: %lx\n", iotlb->iova, iotlb->translated_addr, iot->gpa);
+      if(periscope_dma_unmap(iot->gpa, 1) == 0) {
+         MemoryRegion *mr = &iot->iommu->parent_obj;
+         memory_region_unregister_iommu_notifier(mr, n);
+         g_free(iot);
+      }
+   }
+}
+
+static void translate_trace_iova(KvmApiTestState* state, uint64_t val, unsigned size) {
+    if(size != 4) return;
+    PCIDevice *pci_dev = &state->parent_obj;
+    PCIBus *bus = pci_get_bus(pci_dev);
+    IntelIOMMUState *iommu = INTEL_IOMMU_DEVICE(x86_iommu_get_default());
+    if (bus && iommu) {
+        uint16_t domain_id;
+        int ret = vtd_dev_to_domain_id(iommu, pci_bus_num(bus), pci_dev->devfn, &domain_id);
+        if (ret == 0) {
+           uint64_t gpa;
+           //ret = vtd_iova_to_gpa(iommu, pci_bus_num(bus), pci_dev->devfn, val, &gpa);
+           ret = vtd_iova_to_gpa_writable(iommu, pci_bus_num(bus), pci_dev->devfn, val, &gpa);
+           if (ret == 0) {
+              // TODO: when this message gets printed, then we need to implement DMA fuzzing
+              printf("periscope: mmio_write domain=%u iova=0x%lx gpa=0x%lx\n",
+                    domain_id, val, gpa);
+
+              // start dma tracing
+              // todo detect multi page dma mappings
+              int size = getpagesize();
+              // todo: which mmio region should get the dma exits?
+              if(periscope_dma_add(gpa, size, &state->mmio) == 0) {
+                 VTDAddressSpace *vas = vtd_find_add_as(iommu, bus, pci_dev->devfn);
+                 if(vas) {
+                    MemoryRegion *mr = &vas->iommu.parent_obj;
+                    if(mr) {
+                       IommuTrace* iot = g_malloc(sizeof(IommuTrace));
+                       iot->iommu = &vas->iommu;
+                       iot->gpa = gpa;
+                       iommu_notifier_init(&iot->n, pci_unmap_notify_func,
+                             IOMMU_NOTIFIER_UNMAP, (val >> 12) << 12, ((val + 0x1000) >> 12) << 12, 0);
+                       memory_region_register_iommu_notifier(mr, &iot->n);
+                    }
+                 }
+              }
+           }
+        }
+    }
+}
+
+
+static uint64_t retval = 0x42;
+static uint64_t mmio_read(void *opaque, hwaddr addr, unsigned size)
+{
+   //KvmApiTestState *s = opaque;
+   //printf(DEVICE_NAME " mmio_read addr = %llx size = %x\n", (unsigned long long)addr, size);
+   switch (addr) {
+      default:
+         printf("%s: addr %lx, size %x\n", __FUNCTION__, addr, size);
+         break;
+   }
+   return retval++;
+}
+
+static void mmio_write(void *opaque, hwaddr addr, uint64_t val,
+      unsigned size)
+{
+   KvmApiTestState *state = opaque;
+   //PCIDevice *pdev = opaque;
+
+   //printf(DEVICE_NAME " mmio_write addr = %llx val = %llx size = %x\n",
+   //      (unsigned long long)addr, (unsigned long long)val, size);
+   switch (addr) {
+      case DMA_MAP_ADDR:
+         dma_state.map_addr = val;
+         break;
+      case DMA_MAP_SIZE:
+         dma_state.map_size = val;
+         break;
+      case DMA_UNMAP_ADDR:
+         dma_state.unmap_addr = val;
+         break;
+      case DMA_MAP:
+         translate_trace_iova(state, dma_state.map_addr, 4);
+         break;
+      case DMA_UNMAP:
+         printf("UNMAP\n");
+         //periscope_dma_remove(dma_state.unmap_addr, 0);
+         //translate_iova(state, dma_state.unmap_addr);
+         break;
+      default:
+         printf("%s: addr %lx, val %lx\n", __FUNCTION__, addr, val);
+         break;
+   }
+}
+
+static const MemoryRegionOps mmio_ops = {
+   .read = mmio_read,
+   .write = mmio_write,
+   .endianness = DEVICE_NATIVE_ENDIAN,
+};
+
+static void realize(PCIDevice *pdev, Error **errp)
+{
+   KvmApiTestState *state = DO_UPCAST(KvmApiTestState, parent_obj, pdev);
+
+   pci_config_set_interrupt_pin(pdev->config, 1);
+   memory_region_init_io(&state->mmio, OBJECT(state), &mmio_ops, state,
+         DEVICE_NAME, 0x1000);
+   pci_register_bar(pdev, 0, PCI_BASE_ADDRESS_SPACE_MEMORY, &state->mmio);
+}
+
+static int kvm_api_test_pre_save(void *opaque)
+{
+   return 0;
+}
+
+static int kvm_api_test_post_load(void *opaque, int version_id)
+{
+   //KvmApiTestState *state = opaque;
+   return 0;
+}
+
+static const VMStateDescription vmstate_kvm_api_test = {
+    .name = DEVICE_NAME,
+    .version_id = 1,
+    .minimum_version_id = 1,
+    .pre_save = kvm_api_test_pre_save,
+    .post_load = kvm_api_test_post_load,
+    .fields = (VMStateField[]) {
+        VMSTATE_PCI_DEVICE(parent_obj, KvmApiTestState),
+        VMSTATE_END_OF_LIST()
+    }
+};
+
+static void class_init(ObjectClass *class, void *data)
+{
+   DeviceClass *dc = DEVICE_CLASS(class);
+   PCIDeviceClass *k = PCI_DEVICE_CLASS(class);
+
+   k->realize = realize;
+   k->vendor_id = PCI_VENDOR_ID_QEMU;
+   k->device_id = 0x11ea;
+   k->revision = 0x0;
+   k->class_id = PCI_CLASS_OTHERS;
+   dc->vmsd = &vmstate_kvm_api_test;
+}
+
+static const TypeInfo type_info = {
+   .name          = DEVICE_NAME,
+   .parent        = TYPE_PCI_DEVICE,
+   .class_init    = class_init,
+   .instance_size = sizeof(KvmApiTestState),
+   .class_size = sizeof(PCIDeviceClass),
+   .interfaces =
+      (InterfaceInfo[]){
+         {INTERFACE_CONVENTIONAL_PCI_DEVICE}, {},
+      },
+
+};
+
+static void register_types(void)
+{
+   type_register_static(&type_info);
+}
+
+type_init(register_types)
diff --git hw/periscope/kvm_api_test.h hw/periscope/kvm_api_test.h
new file mode 100644
index 0000000000..53aabdd85d
--- /dev/null
+++ hw/periscope/kvm_api_test.h
@@ -0,0 +1,10 @@
+#ifndef KVM_API_TEST_H
+#define KVM_API_TEST_H
+
+#define DMA_MAP_ADDR 0x100
+#define DMA_MAP_SIZE 0x200
+#define DMA_UNMAP_ADDR 0x300
+#define DMA_MAP 0x400
+#define DMA_UNMAP 0x500
+
+#endif
diff --git hw/periscope/pci-i2c.c hw/periscope/pci-i2c.c
new file mode 100644
index 0000000000..e21f8174ff
--- /dev/null
+++ hw/periscope/pci-i2c.c
@@ -0,0 +1,112 @@
+#include "qemu/osdep.h"
+#include "exec/cpu-common.h"
+#include "hw/pci/pci.h"
+#include "migration/ram.h"
+
+#define DEVICE_NAME "periscope-pci-i2c"
+
+typedef struct {
+  /*< private >*/
+  PCIDevice parent_obj;
+  MemoryRegion mmio;
+  /*< public >*/
+} I2CState;
+
+typedef struct {
+  unsigned int cmd;
+  unsigned int arg;
+  unsigned int ret;
+} mmio_state;
+
+static uint64_t mmio_read(void *opaque, hwaddr addr, unsigned size) {
+  I2CState *s = opaque;
+  (void)s;
+
+  printf(DEVICE_NAME " mmio_read addr = %llx size = %x\n",
+         (unsigned long long)addr, size);
+  switch (addr) {
+  default:
+    break;
+  }
+  return 0x1234567812345678;
+}
+
+static void mmio_write(void *opaque, hwaddr addr, uint64_t val, unsigned size) {
+  I2CState *s = opaque;
+  (void)s;
+
+  printf(DEVICE_NAME " mmio_write addr = %llx val = %llx size = %x\n",
+         (unsigned long long)addr, (unsigned long long)val, size);
+  switch (addr) {
+  default:
+    break;
+  }
+}
+
+static const MemoryRegionOps mmio_ops = {
+    .read = mmio_read,
+    .write = mmio_write,
+    .endianness = DEVICE_NATIVE_ENDIAN,
+};
+
+static void realize(PCIDevice *pdev, Error **errp) {
+  I2CState *state = DO_UPCAST(I2CState, parent_obj, pdev);
+
+  pci_config_set_interrupt_pin(pdev->config, 1);
+  memory_region_init_io(&state->mmio, OBJECT(state), &mmio_ops, state,
+                        DEVICE_NAME, 1024);
+  pci_register_bar(pdev, 0, PCI_BASE_ADDRESS_SPACE_MEMORY, &state->mmio);
+}
+
+static int pre_save(void *opaque) { return 0; }
+
+static int post_load(void *opaque, int version_id) {
+  I2CState *s = opaque;
+  (void)s;
+
+  return 0;
+}
+
+static const VMStateDescription vmstate = {
+    .name = DEVICE_NAME,
+    .version_id = 1,
+    .minimum_version_id = 1,
+    .pre_save = pre_save,
+    .post_load = post_load,
+    .fields = (VMStateField[]){VMSTATE_PCI_DEVICE(parent_obj, I2CState),
+                               VMSTATE_END_OF_LIST()}};
+
+static Property properties[] = {
+    DEFINE_PROP_END_OF_LIST(),
+};
+
+static void class_init(ObjectClass *class, void *data) {
+  DeviceClass *dc = DEVICE_CLASS(class);
+  PCIDeviceClass *k = PCI_DEVICE_CLASS(class);
+
+  k->realize = realize;
+  k->vendor_id = PCI_VENDOR_ID_QEMU;
+  k->device_id = 0x11eb;
+  k->revision = 0x0;
+  k->class_id = PCI_CLASS_OTHERS;
+  dc->vmsd = &vmstate;
+  dc->props = properties;
+}
+
+static const TypeInfo type_info = {
+    .name = DEVICE_NAME,
+    .parent = TYPE_PCI_DEVICE,
+    .class_init = class_init,
+    .instance_size = sizeof(I2CState),
+    .class_size = sizeof(PCIDeviceClass),
+    .interfaces =
+        (InterfaceInfo[]){
+            {INTERFACE_CONVENTIONAL_PCI_DEVICE},
+            {},
+        },
+
+};
+
+static void register_types(void) { type_register_static(&type_info); }
+
+type_init(register_types)
diff --git hw/periscope/pci.c hw/periscope/pci.c
new file mode 100644
index 0000000000..f9486caed4
--- /dev/null
+++ hw/periscope/pci.c
@@ -0,0 +1,737 @@
+#include "qemu/osdep.h"
+#include "hw/hw.h"
+#include "hw/pci/pci.h"
+#include "sysemu/dma.h"
+#include "sysemu/sysemu.h"
+#include "qemu/cutils.h"
+#include "qemu/iov.h"
+#include "qemu/range.h"
+#include "migration/snapshot.h"
+#include "block/snapshot.h"
+#include "migration/periscope.h"
+#include "hw/periscope/pci.h"
+#include "hw/i386/x86-iommu.h"
+#include "hw/i386/intel_iommu.h"
+#include "migration/periscope_dma.h"
+#include <stdio.h>
+#include <sys/mman.h>
+
+/* PCI Device IDs */
+#define QCA6174_DEVICE_ID 0x003e // ath10k
+#define QCA9565_DEVICE_ID 0x0036 // ath9k
+#define QCA9377_DEVICE_ID 0x0042 // ath10k
+#define QCA9980_DEVICE_ID 0x0040 // ath10k
+#define QCA9990_DEVICE_ID 0x0040 // ath10k
+
+// ath10k/hw.h
+#define FW_IND_INITIALIZED 2
+
+// ath10k/hw.c
+#define QCA988x_FW_INDICATOR_ADDRESS 0x9030
+#define QCA6174_FW_INDICATOR_ADDRESS 0x3a028
+#define QCA99x0_FW_INDICATOR_ADDRESS 0x40050
+#define QCA99x0_RTC_STATE_VAL_ON 5
+
+#define QCA99x0_RTC_SOC_BASE_ADDRESS 0x00080000
+#define QCA99x0_SOC_CORE_BASE_ADDRESS 0x00082000
+#define QCA99x0_SOC_CHIP_ID_ADDRESS 0x000000ec
+#define QCA99x0_SOC_CHIP_ID (0x1 << 8)
+
+#define QCA_DEBUG 1
+
+#ifdef QCA_DEBUG
+enum {
+    DEBUG_GENERAL,
+    DEBUG_IO,
+    DEBUG_MMIO,
+    DEBUG_INTERRUPT,
+    DEBUG_RX,
+    DEBUG_TX,
+    DEBUG_MDIC,
+    DEBUG_EEPROM,
+    DEBUG_UNKNOWN,
+    DEBUG_TXSUM,
+    DEBUG_TXERR,
+    DEBUG_RXERR,
+    DEBUG_RXFILTER,
+    DEBUG_PHY,
+    DEBUG_NOTYET,
+};
+#define DBGBIT(x) (1 << DEBUG_##x)
+static int debugflags = DBGBIT(TXERR) | DBGBIT(GENERAL);
+
+#define DBGOUT(what, fmt, ...)                                                 \
+    do {                                                                       \
+        if (debugflags & DBGBIT(what))                                         \
+            fprintf(stderr, "periscope-pci: " fmt, ##__VA_ARGS__);                \
+    } while (0)
+#else
+#define DBGOUT(what, fmt, ...)                                                 \
+    do {                                                                       \
+    } while (0)
+#endif
+
+typedef struct io_memory_region_desc {
+    uint8_t type;
+    int size;
+} io_memory_region_desc;
+
+struct IommuTrace;
+typedef struct IommuTrace {
+    IOMMUMemoryRegion *iommu;
+    uint64_t gpa;
+    IOMMUNotifier n;
+    QLIST_ENTRY(IommuTrace) list;
+} IommuTrace;
+
+static QLIST_HEAD( ,IommuTrace) iommu_trace_notifiers =
+    QLIST_HEAD_INITIALIZER(iommu_trace_notifiers);
+
+static int num_io_descs = 0;
+static io_memory_region_desc io_desc[MAX_IO_MEMORY_REGIONS];
+
+typedef struct PeriScopeBaseClass {
+    PCIDeviceClass parent_class;
+} PeriScopeBaseClass;
+
+#define TYPE_PERISCOPE "periscope"
+
+#define PERISCOPE(obj) OBJECT_CHECK(QCAState, (obj), TYPE_PERISCOPE)
+
+#define PERISCOPE_DEVICE_CLASS(klass)                                         \
+    OBJECT_CLASS_CHECK(PeriScopeBaseClass, (klass), TYPE_PERISCOPE)
+#define PERISCOPE_DEVICE_GET_CLASS(obj)                                       \
+    OBJECT_GET_CLASS(PeriScopeBaseClass, (obj), TYPE_PERISCOPE)
+
+static uint32_t vendor_id = 0;
+static uint32_t device_id = 0;
+static uint32_t revision_id = 0;
+static uint32_t class_id = 0;
+static uint32_t subsystem_vendor_id = 0;
+static uint32_t subsystem_id = 0;
+static bool configured = false;
+
+void periscope_configure_dev(const char *optarg) {
+    char str[256];
+    const char *p;
+
+    strncpy(str, optarg, sizeof(str));
+    printf("periscope: initializing device config %s...\n", str);
+
+    // default device
+    vendor_id = PCI_VENDOR_ID_ATHEROS;
+    device_id = QCA6174_DEVICE_ID;
+    revision_id = 0x1;
+    class_id = PCI_CLASS_WIRELESS_OTHER;
+
+    const char *tok = strtok(str, ",");
+
+    if (tok && strstart(tok, "vendor=", &p)) {
+        long id;
+        if (qemu_strtol(p, NULL, 16, &id) == 0) {
+            vendor_id = id;
+            // printf("periscope: vendor %lu\n", id);
+        }
+        tok = strtok(NULL, ",");
+    }
+
+    if (tok && vendor_id > 0) {
+        if (strstart(tok, "device=", &p)) {
+            long id;
+            if (qemu_strtol(p, NULL, 16, &id) == 0) {
+                device_id = id;
+                // printf("periscope: device %lu\n", id);
+            }
+        }
+        tok = strtok(NULL, ",");
+    }
+
+    if (tok && strstart(tok, "revision=", &p)) {
+        long id;
+        if (qemu_strtol(p, NULL, 16, &id) == 0) {
+            revision_id = id;
+            // printf("periscope: revision %lu\n", id);
+        }
+        tok = strtok(NULL, ",");
+    }
+
+    if (tok && strstart(tok, "class=", &p)) {
+        long id;
+        if (qemu_strtol(p, NULL, 16, &id) == 0) {
+            class_id = id;
+            // printf("periscope: class %lu\n", id);
+        }
+        tok = strtok(NULL, ",");
+    }
+
+    // TODO: subsystem_vendor_id and subsystem_id
+
+    if (tok && strstart(tok, "subsystem_vendor_id=", &p)) {
+        long id;
+        if (qemu_strtol(p, NULL, 16, &id) == 0) {
+            subsystem_vendor_id = id;
+            // printf("periscope: subsystem_vendor %lu\n", id);
+        }
+        tok = strtok(NULL, ",");
+    }
+
+    if (tok && strstart(tok, "subsystem_id=", &p)) {
+        long id;
+        if (qemu_strtol(p, NULL, 16, &id) == 0) {
+            subsystem_id = id;
+            // printf("periscope: subsystem %lu\n", id);
+        }
+        tok = strtok(NULL, ",");
+    }
+
+    while (tok && num_io_descs < MAX_IO_MEMORY_REGIONS) {
+        printf("periscope: io region %s\n", tok);
+
+        if (strstart(tok, "mmio=", &p)) {
+            io_desc[num_io_descs].type = PCI_BASE_ADDRESS_SPACE_MEMORY;
+            long id;
+            if (qemu_strtol(p, NULL, 16, &id) == 0) {
+                io_desc[num_io_descs].size = id;
+                num_io_descs++;
+            }
+        }
+        else if (strstart(tok, "io=", &p)) {
+            io_desc[num_io_descs].type = PCI_BASE_ADDRESS_SPACE_IO;
+            long id;
+            if (qemu_strtol(p, NULL, 16, &id) == 0) {
+                io_desc[num_io_descs].size = id;
+                num_io_descs++;
+            }
+        }
+        tok = strtok(NULL, ",");
+    }
+
+    printf("periscope: initializing 0x%x:0x%x (rev:0x%x, class:0x%x) 0x%x:0x%x...\n",
+            vendor_id, device_id, revision_id, class_id,
+            subsystem_vendor_id, subsystem_id);
+
+    configured = true;
+}
+
+static void remove_all_iommu_trace_notifiers(void)
+{
+   IommuTrace *iot;
+   QLIST_FOREACH(iot, &iommu_trace_notifiers, list) {
+      MemoryRegion *mr = &iot->iommu->parent_obj;
+      memory_region_unregister_iommu_notifier(mr, &iot->n);
+      QLIST_REMOVE(iot, list);
+      g_free(iot);
+   }
+}
+
+static void pci_unmap_notify_func(IOMMUNotifier *n, IOMMUTLBEntry *iotlb) {
+   IommuTrace *iot = container_of(n, IommuTrace, n);
+   if(iot) {
+      //printf("iova: %lx, tr. addr %lx, gpa: %lx\n", iotlb->iova, iotlb->translated_addr, iot->gpa);
+      //if(periscope_dma_remove(iot->gpa, 1) == 0) {
+      if(periscope_dma_unmap(iot->gpa, 1) == 0) {
+         MemoryRegion *mr = &iot->iommu->parent_obj;
+         memory_region_unregister_iommu_notifier(mr, n);
+         QLIST_REMOVE(iot, list);
+         g_free(iot);
+      }
+   }
+}
+
+static void translate_trace_iova(QCAState* state, uint64_t val, unsigned size) {
+    if(size != 4) return;
+    PCIDevice *pci_dev = &state->parent_obj;
+    PCIBus *bus = pci_get_bus(pci_dev);
+    IntelIOMMUState *iommu = INTEL_IOMMU_DEVICE(x86_iommu_get_default());
+    if (bus && iommu) {
+        uint16_t domain_id;
+        int ret = vtd_dev_to_domain_id(iommu, pci_bus_num(bus), pci_dev->devfn, &domain_id);
+        if (ret == 0) {
+           uint64_t gpa;
+           //ret = vtd_iova_to_gpa(iommu, pci_bus_num(bus), pci_dev->devfn, val, &gpa);
+           // only translate writable mappings
+           ret = vtd_iova_to_gpa_writable(iommu, pci_bus_num(bus), pci_dev->devfn, val, &gpa);
+           if (ret == 0) {
+              // TODO: when this message gets printed, then we need to implement DMA fuzzing
+              //printf("periscope: mmio_write domain=%u iova=0x%lx gpa=0x%lx\n",
+              //      domain_id, val, gpa);
+
+              // start dma tracing
+              // todo detect multi page dma mappings
+              int size = getpagesize();
+              // todo: which mmio region should get the dma exits?
+              if(periscope_dma_add(gpa, size, &state->io[1]) == 0) {
+                 VTDAddressSpace *vas = vtd_find_add_as(iommu, bus, pci_dev->devfn);
+                 if(vas) {
+                    MemoryRegion *mr = &vas->iommu.parent_obj;
+                    if(mr) {
+                       IommuTrace* iot = g_malloc(sizeof(IommuTrace));
+                       iot->iommu = &vas->iommu;
+                       iot->gpa = gpa;
+                       iommu_notifier_init(&iot->n, pci_unmap_notify_func,
+                             IOMMU_NOTIFIER_UNMAP, (val >> 12) << 12, ((val + 0x1000) >> 12) << 12, 0);
+                       memory_region_register_iommu_notifier(mr, &iot->n);
+                       QLIST_INSERT_HEAD(&iommu_trace_notifiers, iot, list);
+                    }
+                 }
+              }
+           }
+        }
+    }
+}
+
+
+static void pci_mmio_write(void *opaque, hwaddr addr, uint64_t val,
+                           unsigned size)
+{
+    QCAState *s = opaque;
+    PCIDevice *pci_dev = opaque;
+    unsigned int index = (addr & 0x1ffff) >> 2;
+
+    pci_irq_deassert(&s->parent_obj);
+
+#ifdef TRACE_PERISCOPE_MMIO_WRITE
+    printf("periscope: mmio write 0x%lx 0x%lx 0x%x\n", addr, val, size);
+#endif
+    translate_trace_iova(s, val, size);
+
+    switch (index) {
+    case 0:
+        if (val) {
+            pci_irq_assert(pci_dev);
+        } else {
+            pci_irq_deassert(pci_dev);
+        }
+        s->reg[0] = val;
+        break;
+    case 1:
+        break;
+    default:
+        DBGOUT(UNKNOWN, "MMIO unknown write addr=0x%08x,val=0x%08" PRIx64 "\n",
+               index << 2, val);
+        break;
+    }
+
+    if (index < 10) {
+    } else {
+        DBGOUT(UNKNOWN, "MMIO unknown write addr=0x%08x,val=0x%08" PRIx64 "\n",
+               index << 2, val);
+    }
+}
+
+static uint64_t pci_mmio_read(void *opaque, hwaddr addr, unsigned size)
+{
+    QCAState *s = opaque;
+    PCIDevice *pci_dev = &s->parent_obj;
+
+    pci_irq_deassert(pci_dev);
+    //unsigned int index = (addr & 0x1ffff) >> 2;
+
+    uint64_t out;
+
+    periscope_mmio_read(opaque, size, &out);
+
+    periscope_maybe_raise_irq(&s->parent_obj);
+
+#ifdef TRACE_PERISCOPE_MMIO_READ
+    printf("periscope: mmio read 0x%lx 0x%x 0x%lx\n", addr, size, out);
+#endif
+
+    return out;
+
+#ifdef CREATE_SHARED_MEMORY
+    uint64_t offset = s->shmem[0];
+
+    if(offset > 0x1000) {
+        //printf("offset oor %ld\n", offset);
+        return 0;
+    }
+
+    //switch (index) {
+    //case 0:
+    //    return QCA99x0_RTC_STATE_VAL_ON;
+    //}
+
+    //if (addr == QCA99x0_RTC_SOC_BASE_ADDRESS + QCA99x0_SOC_CHIP_ID_ADDRESS) {
+    //    printf("QCA99x0 soc_chip_id_address\n");
+    //    return QCA99x0_SOC_CHIP_ID;
+    //}
+
+    //if (addr == QCA6174_FW_INDICATOR_ADDRESS) {
+    //    printf("QCA6174 fw_indicator_address\n");
+    //    return FW_IND_INITIALIZED;
+    //}
+    //if (addr == QCA99x0_FW_INDICATOR_ADDRESS) {
+    //    printf("QCA99x0 fw_indicator_address\n");
+    //    return FW_IND_INITIALIZED;
+    //}
+
+    (void)s;
+    //return 0;
+    s->shmem[0] = s->shmem[0] + 1;
+    return s->shmem[offset];
+#endif
+}
+
+static const MemoryRegionOps periscope_mmio_ops = {
+    .read = pci_mmio_read,
+    .write = pci_mmio_write,
+    .endianness = DEVICE_LITTLE_ENDIAN,
+    .valid.min_access_size = 1,
+    .valid.max_access_size = 4,
+    .impl =
+        {
+            .min_access_size = 1,
+            .max_access_size = 4,
+        },
+};
+
+#if 0
+static uint64_t periscope_io_read(void *opaque, hwaddr addr, unsigned size)
+{
+    QCAState *s = opaque;
+
+    //printf("qca io read %ld %d\n", addr, size);
+
+    uint64_t ret;
+    periscope_mmio_read(size, &ret);
+
+    (void)s;
+    return ret;
+}
+
+static void periscope_io_write(void *opaque, hwaddr addr, uint64_t val, unsigned size)
+{
+    QCAState *s = opaque;
+
+    //printf("qca io write %ld %ld %d\n", addr, val, size);
+
+    (void)s;
+}
+#endif
+
+static const MemoryRegionOps periscope_io_ops = {
+    .read = pci_mmio_read,
+    .write = pci_mmio_write,
+    .endianness = DEVICE_LITTLE_ENDIAN,
+};
+
+static int periscope_pre_save(void *opaque)
+{
+    QCAState *s = opaque;
+
+    //printf("periscope: pre_save\n");
+
+    // TODO
+    (void)s;
+
+    return 0;
+}
+
+static int periscope_post_load(void *opaque, int version_id)
+{
+    QCAState *s = opaque;
+
+    //printf("periscope: post_load\n");
+
+    // TODO
+    (void)s;
+
+#if 0
+    pcie_cap_slot_post_load(opaque, version_id);
+#endif
+
+    return 0;
+}
+
+static const VMStateDescription vmstate_periscope = {
+    .name = "periscope",
+    .version_id = 2,
+    .minimum_version_id = 1,
+    .pre_save = periscope_pre_save,
+    .post_load = periscope_post_load,
+    .fields = (VMStateField[]) {
+        VMSTATE_PCI_DEVICE(parent_obj, QCAState),
+        VMSTATE_END_OF_LIST()
+    }
+};
+
+static void pci_periscope_uninit(PCIDevice *dev)
+{
+    QCAState *d = PERISCOPE(dev);
+
+    g_free(d->irq);
+    d->irq = NULL;
+}
+
+#ifdef CREATE_SHARED_MEMORY
+static int create_shared_memory(QCAState *d)
+{
+   int fd = shm_open("/qca_shm.file", O_CREAT | O_RDWR, S_IRUSR | S_IWUSR);
+   if(fd < 0) {
+      printf("OPEN FAILED %d\n", fd);
+      return -1;
+   }
+   if (ftruncate(fd, 0x1000) == -1) {
+      perror("ftruncate");
+      return -1;
+   }
+   d->shmem = (uint64_t*)mmap(NULL, 0x1000, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
+   if(d->shmem == MAP_FAILED) {
+      printf("MMAP FAILED\n");
+      return -1;
+   }
+   d->shmem[0] = 1;
+   return 0;
+}
+#endif
+
+static void pci_periscope_realize(PCIDevice *pci_dev, Error **errp)
+{
+    // DeviceState *dev = DEVICE(pci_dev);
+    QCAState *d = PERISCOPE(pci_dev);
+    uint8_t *pci_conf;
+
+    pci_conf = pci_dev->config;
+
+    pci_set_word(pci_dev->config + PCI_SUBSYSTEM_VENDOR_ID,
+                 subsystem_vendor_id);
+    pci_set_word(pci_dev->config + PCI_SUBSYSTEM_ID,
+                 subsystem_id);
+
+    pci_set_word(pci_conf + PCI_STATUS, PCI_STATUS_DEVSEL_MEDIUM |
+                                        PCI_STATUS_FAST_BACK);
+
+    /* TODO: RST# value should be 0, PCI spec 6.2.4 */
+    pci_conf[PCI_CACHE_LINE_SIZE] = 0x10;
+
+    // The Interrupt Pin register is a read-only register that identifies the
+    // legacy interrupt Message(s) the Function uses (see Section 6.1 for
+    // further details). Valid values are 01h, 02h, 03h, and 04h that map to
+    // legacy interrupt Messages for INTA, INTB, INTC, and INTD respectively.
+    pci_conf[PCI_INTERRUPT_PIN] = 1; /* interrupt pin A */
+
+    for (unsigned i=0; i<num_io_descs; i++) {
+        if (io_desc[i].size <= 0) continue;
+
+        char id_str[50];
+        sprintf(id_str, "periscope-io%d", i);
+
+        printf("periscope: configuring periscope-io%d (size=%d,type=%u)\n",
+               i, io_desc[i].size, io_desc[i].type);
+
+        const MemoryRegionOps *ops = &periscope_mmio_ops;
+        if (io_desc[i].type == PCI_BASE_ADDRESS_SPACE_IO)
+            ops = &periscope_io_ops;
+
+        memory_region_init_io(&d->io[i], OBJECT(d), ops, d,
+                              id_str, io_desc[i].size);
+
+        pci_register_bar(pci_dev, i, io_desc[i].type, &d->io[i]);
+    }
+
+    d->irq = pci_allocate_irq(pci_dev);
+
+    // TODO: not sure if or when we need the following
+    if (pci_is_express(pci_dev)) {
+        printf("periscope: initializing pcie configuration space\n");
+        int pos;
+
+        pos = pcie_endpoint_cap_init(pci_dev, 0);
+        assert(pos > 0);
+
+        pos = pci_add_capability(pci_dev, PCI_CAP_ID_PM, 0,
+                                 PCI_PM_SIZEOF, errp);
+        if (pos < 0) {
+            return;
+        }
+
+        pci_dev->exp.pm_cap = pos;
+
+        /*
+         * Indicates that this function complies with revision 1.2 of the
+         * PCI Power Management Interface Specification.
+         */
+        pci_set_word(pci_dev->config + pos + PCI_PM_PMC, 0x3);
+    }
+
+#ifdef CREATE_SHARED_MEMORY
+    if(create_shared_memory(d) != 0)
+      d->shmem = NULL;
+#endif
+
+#if 0
+    qemu_macaddr_default_if_unset(&d->conf.macaddr);
+    macaddr = d->conf.macaddr.a;
+
+    qcax_core_prepare_eeprom(d->eeprom_data,
+                               qca_eeprom_template,
+                               sizeof(qca_eeprom_template),
+                               PCI_DEVICE_GET_CLASS(pci_dev)->device_id,
+                               macaddr);
+
+    d->nic = qemu_new_nic(&net_periscope_info, &d->conf,
+                          object_get_typename(OBJECT(d)), dev->id, d);
+
+    qemu_format_nic_info_str(qemu_get_queue(d->nic), macaddr);
+
+    d->autoneg_timer = timer_new_ms(QEMU_CLOCK_VIRTUAL, qca_autoneg_timer, d);
+    d->mit_timer = timer_new_ns(QEMU_CLOCK_VIRTUAL, qca_mit_timer, d);
+#endif
+}
+
+static void qdev_periscope_reset(DeviceState *dev)
+{
+    QCAState *d = PERISCOPE(dev);
+
+    remove_all_iommu_trace_notifiers();
+    // neccessary?
+    // right now it seems like the system reset takes care of pt but list should be emptied
+    periscope_dma_remove_all();
+    vm_stop(RUN_STATE_RESTORE_VM);
+
+    (void)d;
+}
+
+#define PCI_READ_WRITE_CONFIG
+#undef PCI_READ_WRITE_CONFIG
+
+#ifdef PCI_READ_WRITE_CONFIG
+static uint32_t periscope_pci_read_config(PCIDevice *d, uint32_t addr,
+                                          int len)
+{
+    QCAState *s = PERISCOPE(d);
+
+    return pci_default_read_config(d, addr, val, len);
+}
+
+static void periscope_pci_write_config(PCIDevice *d, uint32_t addr,
+                                       uint32_t val, int len)
+{
+    QCAState *s = PERISCOPE(d);
+
+    pci_default_write_config(d, addr, val, len);
+}
+#endif
+
+static Property periscope_properties[] = {
+    DEFINE_PROP_END_OF_LIST(),
+};
+
+#if 0
+typedef struct QCAInfo {
+    const char *name;
+    uint16_t device_id;
+    uint8_t revision;
+} QCAInfo;
+#endif
+
+static void periscope_class_init(ObjectClass *klass, void *data)
+{
+    DeviceClass *dc = DEVICE_CLASS(klass);
+    PCIDeviceClass *k = PCI_DEVICE_CLASS(klass);
+
+    if (!configured) {
+        printf("periscope: device not configured?\n");
+    }
+
+    printf("periscope: initializing device class...\n");
+
+#if 0
+    QCABaseClass *e = QCA_DEVICE_CLASS(klass);
+    const QCAInfo *info = data;
+#endif
+
+    k->realize = pci_periscope_realize;
+    k->exit = pci_periscope_uninit;
+
+    k->romfile = 0;
+
+    /* Device identifiers */
+    k->vendor_id = vendor_id;
+    k->device_id = device_id;
+    k->subsystem_vendor_id = subsystem_vendor_id;
+    k->subsystem_id = subsystem_id;
+    k->revision = revision_id;
+    k->class_id = class_id;
+
+    DeviceCategory cat = DEVICE_CATEGORY_MISC;
+    switch (class_id) {
+    case PCI_CLASS_NETWORK_ETHERNET:
+    case PCI_CLASS_WIRELESS_OTHER:
+        cat = DEVICE_CATEGORY_NETWORK;
+        break;
+    }
+    set_bit(cat, dc->categories);
+
+    // dc->desc = "";
+
+#ifdef PCI_READ_WRITE_CONFIG
+    k->config_read = periscope_pci_read_config;
+    k->config_write = periscope_pci_write_config;
+#endif
+
+    /* qemu user things */
+    dc->vmsd = &vmstate_periscope;
+    dc->props = periscope_properties;
+    dc->reset = qdev_periscope_reset;
+}
+
+static void periscope_instance_init(Object *obj)
+{
+    PCI_DEVICE(obj)->cap_present |= QEMU_PCI_CAP_EXPRESS;
+
+#if 0
+    QCAState *n = PERISCOPE(obj);
+    device_add_bootindex_property(obj, &n->bootindex, "bootindex", "/ssllab@0",
+                                  DEVICE(n), NULL);
+#endif
+}
+
+static const TypeInfo pci_periscope_info = {
+    .name = TYPE_PERISCOPE,
+    .parent = TYPE_PCI_DEVICE,
+    .instance_size = sizeof(QCAState),
+    .instance_init = periscope_instance_init,
+    .class_size = sizeof(PeriScopeBaseClass),
+    .class_init = periscope_class_init,
+    .interfaces =
+        (InterfaceInfo[]){
+            {INTERFACE_PCIE_DEVICE},
+            {INTERFACE_CONVENTIONAL_PCI_DEVICE},
+            {},
+        },
+};
+
+#if 0
+static QCAInfo periscope_devices[] = {
+    {
+        .name = "periscope", .device_id = 0, .revision = 0x02,
+    },
+};
+#endif
+
+static void periscope_register_types(void)
+{
+#if 0
+    int i;
+#endif
+
+    type_register_static(&pci_periscope_info);
+
+#if 0
+    for (i = 0; i < ARRAY_SIZE(periscope_devices); i++) {
+        const QCAInfo *info = &periscope_devices[i];
+        TypeInfo type_info = {};
+        type_info.name = info->name;
+        type_info.parent = TYPE_PERISCOPE_BASE;
+        type_info.class_data = (void *)info;
+        type_info.class_init = periscope_class_init;
+        type_info.instance_init = periscope_instance_init;
+
+        type_register(&type_info);
+    }
+#endif
+}
+
+type_init(periscope_register_types)
diff --git hw/periscope/pci.h hw/periscope/pci.h
new file mode 100644
index 0000000000..f642fdf446
--- /dev/null
+++ hw/periscope/pci.h
@@ -0,0 +1,30 @@
+#ifndef PERISCOPE_PCI_H
+#define PERISCOPE_PCI_H
+
+#include "qemu/osdep.h"
+#include "hw/hw.h"
+#include "hw/pci/pci.h"
+
+#define CREATE_SHARED_MEMORY
+#undef CREATE_SHARED_MEMORY
+
+#define MAX_IO_MEMORY_REGIONS 10
+
+typedef struct QCAState_st {
+    /*< private >*/
+    PCIDevice parent_obj;
+    /*< public >*/
+
+    MemoryRegion modern_bar;
+    MemoryRegion io[MAX_IO_MEMORY_REGIONS];
+
+    uint32_t reg[0x80];
+
+    qemu_irq irq;
+
+#ifdef CREATE_SHARED_MEMORY
+    uint64_t* shmem;
+#endif
+} QCAState;
+
+#endif
\ No newline at end of file
diff --git hw/periscope/sd.c hw/periscope/sd.c
new file mode 100644
index 0000000000..e69de29bb2
diff --git hw/periscope/usb.c hw/periscope/usb.c
new file mode 100644
index 0000000000..a2b246415f
--- /dev/null
+++ hw/periscope/usb.c
@@ -0,0 +1,353 @@
+#include "qemu/osdep.h"
+#include "hw/hw.h"
+#include "ui/console.h"
+#include "hw/usb.h"
+#include "hw/usb/desc.h"
+
+/* Interface requests */
+#define WACOM_GET_REPORT	0x2101
+#define WACOM_SET_REPORT	0x2109
+
+/* HID interface requests */
+#define HID_GET_REPORT		0xa101
+#define HID_GET_IDLE		0xa102
+#define HID_GET_PROTOCOL	0xa103
+#define HID_SET_IDLE		0x210a
+#define HID_SET_PROTOCOL	0x210b
+
+typedef struct USBPeriScopeState {
+    USBDevice dev;
+    USBEndpoint *intr;
+    QEMUPutMouseEntry *eh_entry;
+    int dx, dy, dz, buttons_state;
+    int x, y;
+    int mouse_grabbed;
+    enum {
+        WACOM_MODE_HID = 1,
+        WACOM_MODE_WACOM = 2,
+    } mode;
+    uint8_t idle;
+    int changed;
+} USBPeriScopeState;
+
+#define TYPE_USB_PERISCOPE "usb-periscope"
+#define USB_PERISCOPE(obj) OBJECT_CHECK(USBPeriScopeState, (obj), TYPE_USB_PERISCOPE)
+
+enum {
+    STR_MANUFACTURER = 1,
+    STR_PRODUCT,
+    STR_SERIALNUMBER,
+};
+
+static const USBDescStrings desc_strings = {
+    [STR_MANUFACTURER]     = "QEMU",
+    [STR_PRODUCT]          = "PeriScope",
+    [STR_SERIALNUMBER]     = "1",
+};
+
+static const USBDescIface desc_iface_periscope = {
+    .bInterfaceNumber              = 0,
+    .bNumEndpoints                 = 2,
+    .bInterfaceClass               = USB_CLASS_VENDOR_SPEC,
+    .bInterfaceSubClass            = USB_CLASS_VENDOR_SPEC,
+    .bInterfaceProtocol            = 0x02,
+    .eps = (USBDescEndpoint[]) {
+        {
+            .bEndpointAddress      = USB_DIR_IN | 0x01,
+            .bmAttributes          = USB_ENDPOINT_XFER_BULK,
+            .wMaxPacketSize        = 0x200,
+            .bInterval             = 0x00,
+        },
+        {
+            .bEndpointAddress      = USB_DIR_OUT | 0x01,
+            .bmAttributes          = USB_ENDPOINT_XFER_BULK,
+            .wMaxPacketSize        = 0x200,
+            .bInterval             = 0x00,
+        },
+    },
+};
+
+static const USBDescDevice desc_device_periscope = {
+    .bcdUSB                        = 0x0200,
+    .bMaxPacketSize0               = 64,
+    .bNumConfigurations            = 1,
+    .bDeviceClass = USB_CLASS_VENDOR_SPEC,
+    .bDeviceSubClass = USB_CLASS_VENDOR_SPEC,
+    .bDeviceProtocol = USB_CLASS_VENDOR_SPEC,
+    .confs = (USBDescConfig[]) {
+        {
+            .bNumInterfaces        = 1,
+            .bConfigurationValue   = 1,
+            .bmAttributes          = USB_CFG_ATT_ONE,
+            .bMaxPower             = 40,
+            .nif = 1,
+            .ifs = &desc_iface_periscope,
+        },
+    },
+};
+
+static const USBDesc desc_periscope = {
+    .id = {
+        .idVendor          = 0x4cc,
+        .idProduct         = 0x2533,
+        .bcdDevice         = 0x0,
+        .iManufacturer     = STR_MANUFACTURER,
+        .iProduct          = STR_PRODUCT,
+        .iSerialNumber     = STR_SERIALNUMBER,
+    },
+    .full = &desc_device_periscope,
+    .str  = desc_strings,
+};
+
+static void usb_mouse_event(void *opaque,
+                            int dx1, int dy1, int dz1, int buttons_state)
+{
+    USBPeriScopeState *s = opaque;
+
+    s->dx += dx1;
+    s->dy += dy1;
+    s->dz += dz1;
+    s->buttons_state = buttons_state;
+    s->changed = 1;
+    usb_wakeup(s->intr, 0);
+}
+
+static void usb_periscope_event(void *opaque,
+                            int x, int y, int dz, int buttons_state)
+{
+    USBPeriScopeState *s = opaque;
+
+    /* scale to Penpartner resolution */
+    s->x = (x * 5040 / 0x7FFF);
+    s->y = (y * 3780 / 0x7FFF);
+    s->dz += dz;
+    s->buttons_state = buttons_state;
+    s->changed = 1;
+    usb_wakeup(s->intr, 0);
+}
+
+static inline int int_clamp(int val, int vmin, int vmax)
+{
+    if (val < vmin)
+        return vmin;
+    else if (val > vmax)
+        return vmax;
+    else
+        return val;
+}
+
+static int usb_mouse_poll(USBPeriScopeState *s, uint8_t *buf, int len)
+{
+    int dx, dy, dz, b, l;
+
+    if (!s->mouse_grabbed) {
+        s->eh_entry = qemu_add_mouse_event_handler(usb_mouse_event, s, 0,
+                        "QEMU PenPartner tablet");
+        qemu_activate_mouse_event_handler(s->eh_entry);
+        s->mouse_grabbed = 1;
+    }
+
+    dx = int_clamp(s->dx, -128, 127);
+    dy = int_clamp(s->dy, -128, 127);
+    dz = int_clamp(s->dz, -128, 127);
+
+    s->dx -= dx;
+    s->dy -= dy;
+    s->dz -= dz;
+
+    b = 0;
+    if (s->buttons_state & MOUSE_EVENT_LBUTTON)
+        b |= 0x01;
+    if (s->buttons_state & MOUSE_EVENT_RBUTTON)
+        b |= 0x02;
+    if (s->buttons_state & MOUSE_EVENT_MBUTTON)
+        b |= 0x04;
+
+    buf[0] = b;
+    buf[1] = dx;
+    buf[2] = dy;
+    l = 3;
+    if (len >= 4) {
+        buf[3] = dz;
+        l = 4;
+    }
+    return l;
+}
+
+static int usb_periscope_poll(USBPeriScopeState *s, uint8_t *buf, int len)
+{
+    int b;
+
+    if (!s->mouse_grabbed) {
+        s->eh_entry = qemu_add_mouse_event_handler(usb_periscope_event, s, 1,
+                        "QEMU PeriScope");
+        qemu_activate_mouse_event_handler(s->eh_entry);
+        s->mouse_grabbed = 1;
+    }
+
+    b = 0;
+    if (s->buttons_state & MOUSE_EVENT_LBUTTON)
+        b |= 0x01;
+    if (s->buttons_state & MOUSE_EVENT_RBUTTON)
+        b |= 0x40;
+    if (s->buttons_state & MOUSE_EVENT_MBUTTON)
+        b |= 0x20; /* eraser */
+
+    if (len < 7)
+        return 0;
+
+    buf[0] = s->mode;
+    buf[5] = 0x00 | (b & 0xf0);
+    buf[1] = s->x & 0xff;
+    buf[2] = s->x >> 8;
+    buf[3] = s->y & 0xff;
+    buf[4] = s->y >> 8;
+    if (b & 0x3f) {
+        buf[6] = 0;
+    } else {
+        buf[6] = (unsigned char) -127;
+    }
+
+    return 7;
+}
+
+static void usb_periscope_handle_reset(USBDevice *dev)
+{
+    USBPeriScopeState *s = (USBPeriScopeState *) dev;
+
+    s->dx = 0;
+    s->dy = 0;
+    s->dz = 0;
+    s->x = 0;
+    s->y = 0;
+    s->buttons_state = 0;
+    s->mode = WACOM_MODE_HID;
+}
+
+static void usb_periscope_handle_control(USBDevice *dev, USBPacket *p,
+               int request, int value, int index, int length, uint8_t *data)
+{
+    USBPeriScopeState *s = (USBPeriScopeState *) dev;
+    int ret;
+
+    ret = usb_desc_handle_control(dev, p, request, value, index, length, data);
+    if (ret >= 0) {
+        return;
+    }
+
+    switch (request) {
+    case WACOM_SET_REPORT:
+        if (s->mouse_grabbed) {
+            qemu_remove_mouse_event_handler(s->eh_entry);
+            s->mouse_grabbed = 0;
+        }
+        s->mode = data[0];
+        break;
+    case WACOM_GET_REPORT:
+        data[0] = 0;
+        data[1] = s->mode;
+        p->actual_length = 2;
+        break;
+    /* USB HID requests */
+    case HID_GET_REPORT:
+        if (s->mode == WACOM_MODE_HID)
+            p->actual_length = usb_mouse_poll(s, data, length);
+        else if (s->mode == WACOM_MODE_WACOM)
+            p->actual_length = usb_periscope_poll(s, data, length);
+        break;
+    case HID_GET_IDLE:
+        data[0] = s->idle;
+        p->actual_length = 1;
+        break;
+    case HID_SET_IDLE:
+        s->idle = (uint8_t) (value >> 8);
+        break;
+    default:
+        p->status = USB_RET_STALL;
+        break;
+    }
+}
+
+static void usb_periscope_handle_data(USBDevice *dev, USBPacket *p)
+{
+    USBPeriScopeState *s = (USBPeriScopeState *) dev;
+    uint8_t buf[p->iov.size];
+    int len = 0;
+
+    switch (p->pid) {
+    case USB_TOKEN_IN:
+        if (p->ep->nr == 1) {
+            if (!(s->changed || s->idle)) {
+                p->status = USB_RET_NAK;
+                return;
+            }
+            s->changed = 0;
+            if (s->mode == WACOM_MODE_HID)
+                len = usb_mouse_poll(s, buf, p->iov.size);
+            else if (s->mode == WACOM_MODE_WACOM)
+                len = usb_periscope_poll(s, buf, p->iov.size);
+            usb_packet_copy(p, buf, len);
+            break;
+        }
+        /* Fall through.  */
+    case USB_TOKEN_OUT:
+    default:
+        p->status = USB_RET_STALL;
+    }
+}
+
+static void usb_periscope_unrealize(USBDevice *dev, Error **errp)
+{
+    USBPeriScopeState *s = (USBPeriScopeState *) dev;
+
+    if (s->mouse_grabbed) {
+        qemu_remove_mouse_event_handler(s->eh_entry);
+        s->mouse_grabbed = 0;
+    }
+}
+
+static void usb_periscope_realize(USBDevice *dev, Error **errp)
+{
+    USBPeriScopeState *s = USB_PERISCOPE(dev);
+    usb_desc_create_serial(dev);
+    usb_desc_init(dev);
+    s->intr = usb_ep_get(dev, USB_TOKEN_IN, 1);
+    s->changed = 1;
+}
+
+static const VMStateDescription vmstate_usb_periscope = {
+    .name = "usb-periscope",
+    .unmigratable = 1,
+};
+
+static void usb_periscope_class_init(ObjectClass *klass, void *data)
+{
+    DeviceClass *dc = DEVICE_CLASS(klass);
+    USBDeviceClass *uc = USB_DEVICE_CLASS(klass);
+
+    uc->product_desc   = "QEMU PeriScope USB";
+    uc->usb_desc       = &desc_periscope;
+    uc->realize        = usb_periscope_realize;
+    uc->handle_reset   = usb_periscope_handle_reset;
+    uc->handle_control = usb_periscope_handle_control;
+    uc->handle_data    = usb_periscope_handle_data;
+    uc->unrealize      = usb_periscope_unrealize;
+    set_bit(DEVICE_CATEGORY_INPUT, dc->categories);
+    dc->desc = "QEMU PeriScope USB";
+    dc->vmsd = &vmstate_usb_periscope;
+}
+
+static const TypeInfo periscope_info = {
+    .name          = TYPE_USB_PERISCOPE,
+    .parent        = TYPE_USB_DEVICE,
+    .instance_size = sizeof(USBPeriScopeState),
+    .class_init    = usb_periscope_class_init,
+};
+
+static void usb_periscope_register_types(void)
+{
+    type_register_static(&periscope_info);
+    usb_legacy_register(TYPE_USB_PERISCOPE, "periscope", NULL);
+}
+
+type_init(usb_periscope_register_types)
diff --git hw/periscope/virtio.c hw/periscope/virtio.c
new file mode 100644
index 0000000000..98d15605a6
--- /dev/null
+++ hw/periscope/virtio.c
@@ -0,0 +1,209 @@
+/*
+ * virtio.c
+ *
+ * Authors:
+ *  dokyungs@uci.edu
+ */
+
+#include "qemu/osdep.h"
+#include "qemu/units.h"
+#include "qemu-common.h"
+#include "qemu/iov.h"
+#include "sysemu/dma.h"
+#include "hw/virtio/virtio.h"
+#include "hw/virtio/virtio-bus.h"
+#include "qemu/log.h"
+#include "qapi/error.h"
+
+#include "virtio.h"
+
+
+static void virtio_periscope_get_config(VirtIODevice *vdev, uint8_t *config)
+{
+    VirtIOPeriScope *p = VIRTIO_PERISCOPE(vdev);
+
+    (void)p;
+}
+
+static void virtio_periscope_set_config(VirtIODevice *vdev, const uint8_t *config)
+{
+    VirtIOPeriScope *p = VIRTIO_PERISCOPE(vdev);
+
+    (void)p;
+}
+
+static uint64_t virtio_periscope_get_features(VirtIODevice *vdev, uint64_t features,
+                                              Error **errp)
+{
+    VirtIOPeriScope *p = VIRTIO_PERISCOPE(vdev);
+
+    (void)p;
+
+    return features;
+}
+
+static void virtio_periscope_set_features(VirtIODevice *vdev, uint64_t features)
+{
+    VirtIOPeriScope *p = VIRTIO_PERISCOPE(vdev);
+
+    (void)p;
+}
+
+#if 0
+static int virtio_periscope_save(QEMUFile *f, void *opaque, size_t size,
+                                 const VMStateField *field, QJSON *vmdesc)
+{
+    VirtIOPeriScope *p = opaque;
+
+    (void)p;
+
+    return 0;
+}
+
+static int virtio_periscope_load(QEMUFile *f, void *opaque, size_t size,
+                                 const VMStateField *field)
+{
+    VirtIOPeriScope *p = opaque;
+
+    (void)p;
+
+    return 0;
+}
+#endif
+
+static int virtio_periscope_load(VirtIODevice *vdev, QEMUFile *f,
+                                 int version_id) {
+
+    return 0;
+}
+
+/* Guest wrote coverage */
+static void handle_kcov_output(VirtIODevice *vdev, VirtQueue *vq)
+{
+
+}
+
+static void virtio_periscope_device_realize(DeviceState *qdev, Error **errp)
+{
+    VirtIODevice *vdev = VIRTIO_DEVICE(qdev);
+    VirtIOPeriScope *p = VIRTIO_PERISCOPE(qdev);
+    // Error *local_err = NULL;
+
+    virtio_init(vdev, "virtio-periscope", VIRTIO_ID_PERISCOPE, 0);
+
+    /* Add a queue for kcov map transfers from guest to host */
+    p->kcov_ovq = virtio_add_queue(vdev, 128, handle_kcov_output);
+
+    (void)vdev;
+    (void)p;
+}
+
+static void virtio_periscope_device_unrealize(DeviceState *qdev, Error **errp)
+{
+    VirtIOPeriScope *p = VIRTIO_PERISCOPE(qdev);
+
+    (void)p;
+}
+
+static void virtio_periscope_instance_init(Object *obj)
+{
+}
+
+static void virtio_periscope_reset(VirtIODevice *vdev)
+{
+    VirtIOPeriScope *p = VIRTIO_PERISCOPE(vdev);
+
+    (void)p;
+}
+
+static Property virtio_periscope_properties[] = {
+    DEFINE_PROP_END_OF_LIST(),
+};
+
+static void virtio_periscope_class_init(ObjectClass *klass, void *data)
+{
+    DeviceClass *dc = DEVICE_CLASS(klass);
+    VirtioDeviceClass *vdc = VIRTIO_DEVICE_CLASS(klass);
+
+    vdc->realize = virtio_periscope_device_realize;
+    vdc->unrealize = virtio_periscope_device_unrealize;
+    vdc->get_config = virtio_periscope_get_config;
+    vdc->set_config = virtio_periscope_set_config;
+    vdc->get_features = virtio_periscope_get_features;
+    vdc->set_features = virtio_periscope_set_features;
+
+    vdc->reset = virtio_periscope_reset;
+    vdc->load = virtio_periscope_load;
+
+    set_bit(DEVICE_CATEGORY_DISPLAY, dc->categories);
+    dc->props = virtio_periscope_properties;
+    dc->hotpluggable = false;
+}
+
+static const TypeInfo virtio_periscope_info = {
+    .name = TYPE_VIRTIO_PERISCOPE,
+    .parent = TYPE_VIRTIO_DEVICE,
+    .instance_size = sizeof(VirtIOPeriScope),
+    .instance_init = virtio_periscope_instance_init,
+    .class_init = virtio_periscope_class_init,
+};
+
+static void virtio_register_types(void)
+{
+    type_register_static(&virtio_periscope_info);
+}
+
+type_init(virtio_register_types)
+
+
+#if 0
+
+#include "kcov.h"
+
+static void kcov_memory_listener_commit(MemoryListener *listener) {
+
+}
+
+static void kcov_device_realize(DeviceState *dev, Error **errp)
+{
+    KCovDevice *kcdev = KCOV_DEVICE(dev);
+    KCovDeviceClass *kcdc = KCOV_DEVICE_GET_CLASS(dev);
+    Error *err = NULL;
+
+    virtio_bus_device_plugged(kdev, &err);
+    if (err != NULL) {
+        error_propagate(errp, err);
+        kcdc->unrealize(dev, NULL);
+        return;
+    }
+
+    memory_listener_register(&kcdev->listener, kcdev->dma_as);
+}
+
+static void kcov_device_class_init(ObjectClass *klass, void *data) {
+    /* Set the default value here. */
+    VirtioDeviceClass *vdc = VIRTIO_DEVICE_CLASS(klass);
+    DeviceClass *dc = DEVICE_CLASS(klass);
+
+    dc->realize = virtio_device_realize;
+    dc->unrealize = virtio_device_unrealize;
+    dc->bus_type = TYPE_VIRTIO_BUS;
+};
+
+static const TypeInfo kcov_device_info = {
+    .name = TYPE_KCOV_DEVICE,
+    .parent = TYPE_DEVICE,
+    .instance_size = sizeof(KCovDevice),
+    .class_init = kcov_device_class_init,
+    .instance_finalize = kcov_device_instance_finalize,
+    .abstract = true,
+    .class_size = sizeof(KCovDeviceClass),
+};
+
+static void kcov_register_types(void)
+{
+    type_register_static(&kcov_device_info);
+}
+
+type_init(kcov_register_types)
+#endif
diff --git hw/periscope/virtio.h hw/periscope/virtio.h
new file mode 100644
index 0000000000..b55e9fda9d
--- /dev/null
+++ hw/periscope/virtio.h
@@ -0,0 +1,59 @@
+/*
+ * virtio.h
+ *
+ * Authors:
+ *  dokyungs@uci.edu
+ */
+
+#ifndef VIRTIO_PERISCOPE_H
+#define VIRTIO_PERISCOPE_H
+
+#include "qemu/queue.h"
+#include "hw/virtio/virtio.h"
+#include "qemu/log.h"
+
+#define TYPE_VIRTIO_PERISCOPE "virtio-periscope-device"
+#define VIRTIO_PERISCOPE(obj)                                        \
+        OBJECT_CHECK(VirtIOPeriScope, (obj), TYPE_VIRTIO_PERISCOPE)
+
+#define VIRTIO_ID_PERISCOPE 16
+
+#if 0
+typedef struct VirtIOPeriScopeConf {
+
+} VirtIOPeriScopeConf;
+#endif
+
+typedef struct VirtIOPeriScope {
+    VirtIODevice parent_obj;
+
+    VirtQueue *kcov_ovq;
+} VirtIOPeriScope;
+
+#if 0
+struct KCovDevice {
+    DeviceState parent_obj;
+    AddressSpace *dma_as;
+    MemoryListener listener;
+    VirtQueueElement *vqelem;
+};
+
+typedef KCovDevice KCovDevice;
+
+typedef struct KCovDeviceClass {
+    /*< private >*/
+    DeviceClass parent;
+    /*< public >*/
+
+} KCovDeviceClass;
+
+#define TYPE_KCOV_DEVICE "kcov-device"
+#define KCOV_DEVICE_GET_CLASS(obj) \
+        OBJECT_GET_CLASS(KCovDeviceClass, obj, TYPE_KCOV_DEVICE)
+#define KCOV_DEVICE_CLASS(klass) \
+        OBJECT_CLASS_CHECK(KCovDeviceClass, klass, TYPE_KCOV_DEVICE)
+#define KCOV_DEVICE(obj) \
+        OBJECT_CHECK(KCovDevice, (obj), TYPE_KCOV_DEVICE)
+#endif
+
+#endif
\ No newline at end of file
diff --git include/exec/memory.h include/exec/memory.h
index 1625913f84..e79ad40fcd 100644
--- include/exec/memory.h
+++ include/exec/memory.h
@@ -1316,6 +1316,12 @@ DirtyBitmapSnapshot *memory_region_snapshot_and_clear_dirty(MemoryRegion *mr,
                                                             hwaddr size,
                                                             unsigned client);
 
+// same as memory_region_snapshot_and_clear_dirty
+// but does not clear qemu internal bitmaps
+DirtyBitmapSnapshot *memory_region_snapshot_and_get_dirty(MemoryRegion *mr,
+                                                            hwaddr addr,
+                                                            hwaddr size,
+                                                            unsigned client);
 /**
  * memory_region_snapshot_get_dirty: Check whether a range of bytes is dirty
  *                                   in the specified dirty bitmap snapshot.
diff --git include/exec/ram_addr.h include/exec/ram_addr.h
index 9ecd911c3e..859ba431b7 100644
--- include/exec/ram_addr.h
+++ include/exec/ram_addr.h
@@ -22,11 +22,13 @@
 #ifndef CONFIG_USER_ONLY
 #include "hw/xen/xen.h"
 #include "exec/ramlist.h"
+#include "migration/periscope-delta-snap.h"
 
 struct RAMBlock {
     struct rcu_head rcu;
     struct MemoryRegion *mr;
     uint8_t *host;
+    uint8_t *host_restore;
     uint8_t *colo_cache; /* For colo, VM's ram cache */
     ram_addr_t offset;
     ram_addr_t used_length;
@@ -35,13 +37,17 @@ struct RAMBlock {
     uint32_t flags;
     /* Protected by iothread lock.  */
     char idstr[256];
-    /* RCU-enabled, writes protected by the ramlist lock */
+   /* RCU-enabled, writes protected by the ramlist lock */
     QLIST_ENTRY(RAMBlock) next;
     QLIST_HEAD(, RAMBlockNotifier) ramblock_notifiers;
     int fd;
     size_t page_size;
     /* dirty bitmap used during migration */
     unsigned long *bmap;
+    unsigned long *bmap_delta_restore; // tracks dirty pages, used to only restore dirty pages in ram_load
+    unsigned long *bmap_delta_snap; // also tracks dirty pages, used to only save dirty pages in ram_save_host_page
+    size_t skipped;
+    size_t restored;
     /* bitmap of pages that haven't been sent even once
      * only maintained and used in postcopy at the moment
      * where it's used to send the dirtymap at the start
@@ -214,7 +220,9 @@ static inline bool cpu_physical_memory_is_clean(ram_addr_t addr)
     bool code = cpu_physical_memory_get_dirty_flag(addr, DIRTY_MEMORY_CODE);
     bool migration =
         cpu_physical_memory_get_dirty_flag(addr, DIRTY_MEMORY_MIGRATION);
-    return !(vga && code && migration);
+    bool delta =
+        cpu_physical_memory_get_dirty_flag(addr, DIRTY_MEMORY_DELTA);
+    return !(vga && code && migration && delta);
 }
 
 static inline uint8_t cpu_physical_memory_range_includes_clean(ram_addr_t start,
@@ -235,6 +243,10 @@ static inline uint8_t cpu_physical_memory_range_includes_clean(ram_addr_t start,
         !cpu_physical_memory_all_dirty(start, length, DIRTY_MEMORY_MIGRATION)) {
         ret |= (1 << DIRTY_MEMORY_MIGRATION);
     }
+    if (mask & (1 << DIRTY_MEMORY_DELTA) &&
+        !cpu_physical_memory_all_dirty(start, length, DIRTY_MEMORY_DELTA)) {
+        ret |= (1 << DIRTY_MEMORY_DELTA);
+    }
     return ret;
 }
 
@@ -299,6 +311,12 @@ static inline void cpu_physical_memory_set_dirty_range(ram_addr_t start,
             bitmap_set_atomic(blocks[DIRTY_MEMORY_CODE]->blocks[idx],
                               offset, next - page);
         }
+        // TODO: for now we always update the delta bitmap until we find
+        // out where exactly we are loosing the pages
+        if (unlikely(mask & (1 << DIRTY_MEMORY_DELTA))) {
+            bitmap_set_atomic(blocks[DIRTY_MEMORY_DELTA]->blocks[idx],
+                              offset, next - page);
+        }
 
         page = next;
         idx++;
@@ -352,6 +370,7 @@ static inline void cpu_physical_memory_set_dirty_lebitmap(unsigned long *bitmap,
                 if (tcg_enabled()) {
                     atomic_or(&blocks[DIRTY_MEMORY_CODE][idx][offset], temp);
                 }
+                atomic_or(&blocks[DIRTY_MEMORY_DELTA][idx][offset], temp);
             }
 
             if (++offset >= BITS_TO_LONGS(DIRTY_MEMORY_BLOCK_SIZE)) {
@@ -391,6 +410,10 @@ bool cpu_physical_memory_test_and_clear_dirty(ram_addr_t start,
                                               ram_addr_t length,
                                               unsigned client);
 
+// same as cpu_physical_memory_snapshot_and_clear_dirty
+// but does not clear qemu internal bitmaps
+DirtyBitmapSnapshot *cpu_physical_memory_snapshot_and_get_dirty
+    (ram_addr_t start, ram_addr_t length, unsigned client);
 DirtyBitmapSnapshot *cpu_physical_memory_snapshot_and_clear_dirty
     (ram_addr_t start, ram_addr_t length, unsigned client);
 
@@ -404,6 +427,7 @@ static inline void cpu_physical_memory_clear_dirty_range(ram_addr_t start,
     cpu_physical_memory_test_and_clear_dirty(start, length, DIRTY_MEMORY_MIGRATION);
     cpu_physical_memory_test_and_clear_dirty(start, length, DIRTY_MEMORY_VGA);
     cpu_physical_memory_test_and_clear_dirty(start, length, DIRTY_MEMORY_CODE);
+    cpu_physical_memory_test_and_clear_dirty(start, length, DIRTY_MEMORY_DELTA);
 }
 
 
diff --git include/exec/ramlist.h include/exec/ramlist.h
index bc4faa1b00..2f0b057dd2 100644
--- include/exec/ramlist.h
+++ include/exec/ramlist.h
@@ -11,7 +11,8 @@ typedef struct RAMBlockNotifier RAMBlockNotifier;
 #define DIRTY_MEMORY_VGA       0
 #define DIRTY_MEMORY_CODE      1
 #define DIRTY_MEMORY_MIGRATION 2
-#define DIRTY_MEMORY_NUM       3        /* num of dirty bits */
+#define DIRTY_MEMORY_DELTA     3
+#define DIRTY_MEMORY_NUM       4        /* num of dirty bits */
 
 /* The dirty memory bitmap is split into fixed-size blocks to allow growth
  * under RCU.  The bitmap for a block can be accessed as follows:
diff --git include/hw/i386/intel_iommu.h include/hw/i386/intel_iommu.h
index 12f3d266e2..37b42af6fb 100644
--- include/hw/i386/intel_iommu.h
+++ include/hw/i386/intel_iommu.h
@@ -283,4 +283,15 @@ struct IntelIOMMUState {
  */
 VTDAddressSpace *vtd_find_add_as(IntelIOMMUState *s, PCIBus *bus, int devfn);
 
+int vtd_dev_to_domain_id(IntelIOMMUState *s, uint8_t bus_num,
+                         uint8_t devfn, uint16_t *domain_id);
+
+int vtd_lookup_gfn(IntelIOMMUState *s, uint8_t bus_num, uint8_t devfn,
+                   hwaddr addr, uint64_t *gfn);
+
+int vtd_iova_to_gpa_writable(IntelIOMMUState *s, uint8_t bus_num,
+                    uint8_t devfn, uint64_t iova, uint64_t *gpa);
+int vtd_iova_to_gpa(IntelIOMMUState *s, uint8_t bus_num,
+                    uint8_t devfn, uint64_t iova, uint64_t *gpa);
+
 #endif
diff --git include/hw/pci/pci.h include/hw/pci/pci.h
index 0abb06b357..89e4e922a2 100644
--- include/hw/pci/pci.h
+++ include/hw/pci/pci.h
@@ -447,6 +447,7 @@ static inline int pci_dev_bus_num(const PCIDevice *dev)
 }
 
 int pci_bus_numa_node(PCIBus *bus);
+PCIDevice *get_pcidev_by_name(const char* name);
 void pci_for_each_device(PCIBus *bus, int bus_num,
                          void (*fn)(PCIBus *bus, PCIDevice *d, void *opaque),
                          void *opaque);
diff --git include/hw/pci/pci_ids.h include/hw/pci/pci_ids.h
index 0abe27a53a..bc3ac554c0 100644
--- include/hw/pci/pci_ids.h
+++ include/hw/pci/pci_ids.h
@@ -174,6 +174,8 @@
 #define PCI_DEVICE_ID_AMD_LANCE          0x2000
 #define PCI_DEVICE_ID_AMD_SCSI           0x2020
 
+#define PCI_VENDOR_ID_ATHEROS            0x168c
+
 #define PCI_VENDOR_ID_TI                 0x104c
 
 #define PCI_VENDOR_ID_MOTOROLA           0x1057
diff --git include/io/channel-buffer.h include/io/channel-buffer.h
index 3f4b3f29e1..cd4acea8f1 100644
--- include/io/channel-buffer.h
+++ include/io/channel-buffer.h
@@ -57,4 +57,9 @@ struct QIOChannelBuffer {
 QIOChannelBuffer *
 qio_channel_buffer_new(size_t capacity);
 
+QIOChannelBuffer *
+qio_channel_buffer_new_with_existing_data(uint8_t *data, size_t size);
+
+uint8_t *qio_channel_buffer_close_without_free(QIOChannelBuffer *ioc);
+
 #endif /* QIO_CHANNEL_BUFFER_H */
diff --git include/migration/misc.h include/migration/misc.h
index 5cdbabd094..cec473ed1c 100644
--- include/migration/misc.h
+++ include/migration/misc.h
@@ -42,6 +42,9 @@ void precopy_enable_free_page_optimization(void);
 
 void ram_mig_init(void);
 void qemu_guest_free_page_hint(void *addr, size_t len);
+int ram_duplicate_mappings_cow(void);
+int ram_duplicate_mappings(void);
+int ram_reset_mappings_cow(void);
 
 /* migration/block.c */
 
diff --git include/migration/qemu-file-types.h include/migration/qemu-file-types.h
index bbe04d4484..4b0ab855bb 100644
--- include/migration/qemu-file-types.h
+++ include/migration/qemu-file-types.h
@@ -36,6 +36,7 @@ void qemu_put_be16(QEMUFile *f, unsigned int v);
 void qemu_put_be32(QEMUFile *f, unsigned int v);
 void qemu_put_be64(QEMUFile *f, uint64_t v);
 size_t qemu_get_buffer(QEMUFile *f, uint8_t *buf, size_t size);
+size_t skip_qemu_get_buffer(QEMUFile *f, uint8_t *buf, size_t size);
 
 int qemu_get_byte(QEMUFile *f);
 
diff --git include/migration/snapshot.h include/migration/snapshot.h
index c85b6ec75b..4ae43640cc 100644
--- include/migration/snapshot.h
+++ include/migration/snapshot.h
@@ -17,5 +17,6 @@
 
 int save_snapshot(const char *name, Error **errp);
 int load_snapshot(const char *name, Error **errp);
+int load_snapshot_via_rollback(const char *name, Error **errp);
 
 #endif
diff --git include/qemu/bitmap.h include/qemu/bitmap.h
index 5c313346b9..ba2d7544e1 100644
--- include/qemu/bitmap.h
+++ include/qemu/bitmap.h
@@ -249,6 +249,9 @@ void bitmap_set(unsigned long *map, long i, long len);
 void bitmap_set_atomic(unsigned long *map, long i, long len);
 void bitmap_clear(unsigned long *map, long start, long nr);
 bool bitmap_test_and_clear_atomic(unsigned long *map, long start, long nr);
+// same as bitmap_copy_and_clear_atomic but does not zero src
+void bitmap_copy_atomic(unsigned long *dst, unsigned long *src,
+                                  long nr);
 void bitmap_copy_and_clear_atomic(unsigned long *dst, unsigned long *src,
                                   long nr);
 unsigned long bitmap_find_next_zero_area(unsigned long *map,
diff --git include/standard-headers/linux/virtio_ids.h include/standard-headers/linux/virtio_ids.h
index 6d5c3b2d4f..7a85f64afe 100644
--- include/standard-headers/linux/virtio_ids.h
+++ include/standard-headers/linux/virtio_ids.h
@@ -43,5 +43,6 @@
 #define VIRTIO_ID_INPUT        18 /* virtio input */
 #define VIRTIO_ID_VSOCK        19 /* virtio vsock transport */
 #define VIRTIO_ID_CRYPTO       20 /* virtio crypto */
+#define VIRTIO_ID_PERISCOPE    40 /* virtio periscope */
 
 #endif /* _LINUX_VIRTIO_IDS_H */
diff --git include/sysemu/kvm.h include/sysemu/kvm.h
index a6d1cd190f..df0a6cc272 100644
--- include/sysemu/kvm.h
+++ include/sysemu/kvm.h
@@ -358,6 +358,7 @@ int kvm_arch_handle_exit(CPUState *cpu, struct kvm_run *run);
 int kvm_arch_process_async_events(CPUState *cpu);
 
 int kvm_arch_get_registers(CPUState *cpu);
+target_ulong kvm_arch_get_kvm_rip(CPUState *cpu);
 
 /* state subset only touched by the VCPU itself during runtime */
 #define KVM_PUT_RUNTIME_STATE   1
@@ -547,4 +548,8 @@ int kvm_set_one_reg(CPUState *cs, uint64_t id, void *source);
 int kvm_get_one_reg(CPUState *cs, uint64_t id, void *target);
 struct ppc_radix_page_info *kvm_get_radix_page_info(void);
 int kvm_get_max_memslots(void);
+
+int kvm_enable_dma_trace(uint64_t gpa);
+int kvm_disable_dma_trace(uint64_t gpa);
+int kvm_update_user_memory_region(void* old, void* new, size_t len);
 #endif
diff --git io/channel-buffer.c io/channel-buffer.c
index 43d795976d..9c5b10bf2c 100644
--- io/channel-buffer.c
+++ io/channel-buffer.c
@@ -40,6 +40,20 @@ qio_channel_buffer_new(size_t capacity)
 }
 
 
+QIOChannelBuffer *
+qio_channel_buffer_new_with_existing_data(uint8_t *data, size_t size)
+{
+    QIOChannelBuffer *ioc;
+
+    ioc = QIO_CHANNEL_BUFFER(object_new(TYPE_QIO_CHANNEL_BUFFER));
+
+    ioc->data = data;
+    ioc->capacity = ioc->usage = size;
+
+    return ioc;
+}
+
+
 static void qio_channel_buffer_finalize(Object *obj)
 {
     QIOChannelBuffer *ioc = QIO_CHANNEL_BUFFER(obj);
@@ -147,6 +161,16 @@ static int qio_channel_buffer_close(QIOChannel *ioc,
 }
 
 
+uint8_t *qio_channel_buffer_close_without_free(QIOChannelBuffer *bioc)
+{
+    uint8_t *data = bioc->data;
+    bioc->data = NULL;
+    bioc->capacity = bioc->usage = bioc->offset = 0;
+
+    return data;
+}
+
+
 typedef struct QIOChannelBufferSource QIOChannelBufferSource;
 struct QIOChannelBufferSource {
     GSource parent;
diff --git linux-headers/linux/kvm.h linux-headers/linux/kvm.h
index b53ee59748..77af73a8d2 100644
--- linux-headers/linux/kvm.h
+++ linux-headers/linux/kvm.h
@@ -1440,6 +1440,12 @@ struct kvm_enc_region {
 /* Available with KVM_CAP_HYPERV_CPUID */
 #define KVM_GET_SUPPORTED_HV_CPUID _IOWR(KVMIO, 0xc1, struct kvm_cpuid2)
 
+#define KVM_ENABLE_DMA_TRACE      _IO(KVMIO,   0xc2)
+#define KVM_DISABLE_DMA_TRACE     _IO(KVMIO,   0xc3)
+#define KVM_UPDATE_USER_MEMORY_REGION _IOW(KVMIO, 0xc4, \
+            struct kvm_userspace_memory_region)
+
+
 /* Secure Encrypted Virtualization command */
 enum sev_cmd_id {
 	/* Guest initialization commands */
diff --git memory.c memory.c
index 9fbca52e05..9463af7c3c 100644
--- memory.c
+++ memory.c
@@ -1822,6 +1822,11 @@ uint8_t memory_region_get_dirty_log_mask(MemoryRegion *mr)
     if (global_dirty_log && mr->ram_block) {
         mask |= (1 << DIRTY_MEMORY_MIGRATION);
     }
+#ifdef ENABLE_LW_CHKPT
+    mask |= (1 << DIRTY_MEMORY_DELTA);
+#else
+    printf("WARNING DIRTY_MEMORY_DELTA will be missing bytes\n");
+#endif
     return mask;
 }
 
@@ -2071,6 +2076,18 @@ static void memory_region_sync_dirty_bitmap(MemoryRegion *mr)
     }
 }
 
+DirtyBitmapSnapshot *memory_region_snapshot_and_get_dirty(MemoryRegion *mr,
+                                                            hwaddr addr,
+                                                            hwaddr size,
+                                                            unsigned client)
+{
+    assert(mr->ram_block);
+    memory_region_sync_dirty_bitmap(mr);
+    return cpu_physical_memory_snapshot_and_get_dirty(
+                memory_region_get_ram_addr(mr) + addr, size, client);
+}
+
+
 DirtyBitmapSnapshot *memory_region_snapshot_and_clear_dirty(MemoryRegion *mr,
                                                             hwaddr addr,
                                                             hwaddr size,
diff --git migration/c_hashmap/hashmap_custom.c migration/c_hashmap/hashmap_custom.c
new file mode 100644
index 0000000000..96d13b7487
--- /dev/null
+++ migration/c_hashmap/hashmap_custom.c
@@ -0,0 +1,461 @@
+/*
+ * Generic map implementation.
+ */
+#include "hashmap_custom.h"
+#include "migration/meow_hash_x64_aesni.h"
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <assert.h>
+#include <sys/mman.h>
+#include <sys/time.h>
+
+#define USE_LIST
+#define WARN_LIST
+#define WARN_LIST_TH 8
+//#undef USE_LIST
+//#define INITIAL_SIZE (67108864UL) //2**26
+#define MAX_CHAIN_LENGTH (8)
+
+/* We need to keep keys and values */
+typedef struct _hashmap_element{
+	short in_use;
+   struct _hashmap_element *next;
+   meow_u128 key;
+   unsigned int idx;
+   //page_meta data;
+	//any_t ptr;
+} hashmap_element;
+
+/* A hashmap has some maximum size and current size,
+ * as well as the data to hold. */
+typedef struct _hashmap_map{
+	unsigned long table_size;
+	unsigned long n_elements;
+} hashmap_map;
+
+typedef struct _hashmap_map_info{
+   hashmap_map *m;
+	hashmap_element *data;
+} hashmap_map_info;
+
+unsigned int hashmap_element_size(void) {
+   return sizeof(hashmap_element);
+}
+
+/*
+ * Return an empty hashmap, or NULL on failure.
+ */
+map_t hashmap_new(void *ptr, void *data_ptr, unsigned long size, int init) {
+   hashmap_map_info *mi = malloc(sizeof(hashmap_map_info));
+   assert(mi);
+   if(ptr) {
+      printf("Sharing hashmap %p\n", ptr);
+      mi->m = (hashmap_map*)ptr;
+   } else {
+      printf("Allocating hashmap\n");
+      mi->m = (hashmap_map*)malloc(sizeof(hashmap_map));
+   }
+   assert(mi->m);
+
+   unsigned long n_entries = size / sizeof(hashmap_element);
+   if(data_ptr) {
+      printf("Sharing hashmap data %p\n", data_ptr);
+      mi->data = (hashmap_element*)data_ptr;
+      if(init) {
+         printf("Init table size %ld\n", n_entries);
+         mi->m->table_size = n_entries;
+         memset(mi->data, 0, size);
+      }
+   } else {
+      printf("Allocating\n");
+      mi->data = (hashmap_element*) calloc(n_entries, sizeof(hashmap_element));
+      //madvise(mi->data, n_entries * sizeof(hashmap_element), MADV_WILLNEED);
+      mi->m->table_size = n_entries;
+   }
+   assert(mi->data);
+
+   printf("hashmap %p, data %p, size %ld, entries %ld\n", mi->m, mi->data, size, size / sizeof(hashmap_element));
+   if(init) {
+      mi->m->n_elements = 0;
+   }
+
+	return mi;
+}
+
+#if 0
+static hashmap_element *hashmap_hash_list(map_t in, meow_u128* key){
+	int curr;
+	//int i;
+
+	/* Cast the hashmap */
+	hashmap_map_info* mi = (hashmap_map_info *) in;
+
+	/* If full, return immediately */
+	//if(mi->m->n_elements >= (mi->m->table_size/2)) return MAP_FULL;
+
+	/* Find the best index */
+	curr = MeowU32From(*key, 0) %  mi->m->table_size;
+
+   //if(mi->data[curr].in_use == 0)
+   //   return &mi->data[curr];
+
+   hashmap_element *next = &mi->data[curr];
+   //if(next->in_use = 0 && next->next == NULL)
+   //   return next;
+   hashmap_element *prev = next;
+   while(next != NULL) {
+      if(next->in_use == 0) {
+         return next;
+      }
+      prev = next;
+      next = next->next;
+   }
+   next = malloc(sizeof(hashmap_element));
+   //madvise(next, sizeof(hashmap_element), MADV_WILLNEED);
+   next->next = NULL;
+   prev->next = next;
+   return next;
+}
+
+static int hashmap_hash(map_t in, meow_u128* key){
+	int curr;
+	int i;
+
+	/* Cast the hashmap */
+	hashmap_map_info* mi = (hashmap_map_info *) in;
+
+	/* If full, return immediately */
+	if(mi->m->n_elements >= (mi->m->table_size/2)) return MAP_FULL;
+
+	/* Find the best index */
+	curr = MeowU32From(*key, 0) %  mi->m->table_size;
+
+
+	/* Linear probing */
+	for(i = 0; i< MAX_CHAIN_LENGTH; i++){
+		if(mi->data[curr].in_use == 0)
+			return curr;
+
+		if(mi->data[curr].in_use == 1 &&
+            MeowHashesAreEqual(mi->data[curr].key, *key))
+			return curr;
+
+		curr = (curr + 1) % mi->m->table_size;
+	}
+
+	return MAP_FULL;
+
+}
+#endif
+
+
+//unsigned long hgptime_found = 0;
+//unsigned long hgptime_miss = 0;
+int hashmap_get_and_put_static(map_t in, meow_u128 *key, unsigned int *idx_get, unsigned int **idx_put){
+	unsigned int curr;
+	hashmap_map_info* mi;
+
+
+   //unsigned long long *h = (unsigned long long*)key;
+	/* Cast the hashmap */
+	mi = (hashmap_map_info *) in;
+
+	/* Find data location */
+	curr = MeowU32From(*key, 0) % mi->m->table_size;
+
+   hashmap_element *next = &mi->data[curr];
+
+#ifdef WARN_LIST
+   unsigned int clen = 0;
+#endif
+   hashmap_element *prev = next;
+   while(next != NULL) {
+      if (next->in_use == 1 && MeowHashesAreEqual(next->key, *key)){
+         *idx_get = next->idx;
+         return MAP_OK;
+      }
+      prev = next;
+      next = next->next;
+#ifdef WARN_LIST
+      clen++;
+#endif
+   }
+   if(clen == 1 && prev->in_use == 0) {
+      prev->key = *key;
+      prev->in_use = 1;
+      *idx_put = &prev->idx;
+      return MAP_MISSING;
+   }
+
+   next = malloc(sizeof(hashmap_element));
+   next->next = NULL;
+   *idx_put = &next->idx;
+   next->key = *key;
+   next->in_use = 1;
+   prev->next = next;
+
+#ifdef WARN_LIST
+   if(clen > WARN_LIST_TH) {
+      printf("Warning: chain len %d\n", clen);
+   }
+#endif
+	/* Not found */
+	return MAP_MISSING;
+}
+#if 0
+/*
+ * Add a pointer to the hashmap with some key
+ */
+unsigned long hputtime = 0;
+int hashmap_put(map_t in, meow_u128 *key, any_t value){
+	unsigned int index;
+	hashmap_map_info* mi;
+
+   struct timeval begin, end, elapsed;
+   gettimeofday(&begin, NULL);
+
+	/* Cast the hashmap */
+	mi = (hashmap_map_info *) in;
+#ifdef USE_LIST
+   hashmap_element *curr = hashmap_hash_list(mi, key);
+
+    curr->ptr = value;
+	//memcpy(&curr->data, value, sizeof(page_meta));
+	//memcpy(&curr->data.key, key, sizeof(meow_u128));
+	curr->in_use = 1;
+	mi->m->n_elements++;
+#else
+	/* If full, return immediately */
+	if(mi->m->n_elements >= mi->m->table_size) return MAP_FULL;
+	/* Find a place to put our value */
+   index = hashmap_hash(in, key);
+   if(index == MAP_FULL) {
+      return MAP_OMEM;
+   }
+
+	/* Set the data */
+	//mi->data[index].data = value;
+	memcpy(&mi->data[index].data, value, sizeof(page_meta));
+	//memcpy(&mi->data[index].data.key, key, sizeof(meow_u128));
+	mi->data[index].in_use = 1;
+	mi->m->n_elements++;
+#endif
+
+   gettimeofday(&end, NULL);
+   timersub(&end, &begin, &elapsed);
+   hputtime += elapsed.tv_sec * 1000L * 1000L + elapsed.tv_usec;
+	return MAP_OK;
+}
+int hashmap_get_and_put(map_t in, meow_u128 *key, any_t *arg_get, any_t arg_put){
+	unsigned int curr;
+	unsigned int i;
+	hashmap_map_info* mi;
+
+
+   unsigned long long *h = (unsigned long long*)key;
+	/* Cast the hashmap */
+	mi = (hashmap_map_info *) in;
+
+	/* Find data location */
+	curr = MeowU32From(*key, 0) % mi->m->table_size;
+
+   //struct timeval begin, end, elapsed;
+   //gettimeofday(&begin, NULL);
+   hashmap_element *next = &mi->data[curr];
+   if(next->in_use == 0) {
+      next->ptr = arg_put;
+      next->key = *key;
+      next->in_use = 1;
+      *arg_get = NULL;
+      //gettimeofday(&end, NULL);
+      //timersub(&end, &begin, &elapsed);
+      //hgptime_miss += elapsed.tv_sec * 1000L * 1000L + elapsed.tv_usec;
+      return MAP_MISSING;
+   }
+
+#ifdef WARN_LIST
+   unsigned int clen = 0;
+#endif
+   hashmap_element *prev = next;
+   while(next != NULL) {
+      if (next->in_use == 1 && MeowHashesAreEqual(next->key, *key)){
+         *arg_get = next->ptr;
+         //gettimeofday(&end, NULL);
+         //timersub(&end, &begin, &elapsed);
+         //hgptime_found += elapsed.tv_sec * 1000L * 1000L + elapsed.tv_usec;
+         return MAP_OK;
+      }
+      prev = next;
+      next = next->next;
+#ifdef WARN_LIST
+      clen++;
+#endif
+   }
+	*arg_get = NULL;
+   next = malloc(sizeof(hashmap_element));
+   //madvise(next, sizeof(hashmap_element), MADV_WILLNEED);
+   next->next = NULL;
+   next->ptr = arg_put;
+   next->key = *key;
+   next->in_use = 1;
+   prev->next = next;
+
+#ifdef WARN_LIST
+   if(clen > WARN_LIST_TH) {
+      printf("Warning: chain len %d\n", clen);
+   }
+#endif
+   //gettimeofday(&end, NULL);
+   //timersub(&end, &begin, &elapsed);
+   //hgptime_miss += elapsed.tv_sec * 1000L * 1000L + elapsed.tv_usec;
+	/* Not found */
+	return MAP_MISSING;
+}
+/*
+ * Get your pointer out of the hashmap with a key
+ */
+unsigned long hgettime_miss = 0;
+unsigned long hgettime_found = 0;
+int hashmap_get(map_t in, meow_u128 *key, any_t *arg){
+	unsigned int curr;
+	unsigned int i;
+	hashmap_map_info* mi;
+
+
+   unsigned long long *h = (unsigned long long*)key;
+	/* Cast the hashmap */
+	mi = (hashmap_map_info *) in;
+
+	/* Find data location */
+	curr = MeowU32From(*key, 0) % mi->m->table_size;
+
+
+   struct timeval begin, end, elapsed;
+   gettimeofday(&begin, NULL);
+#ifdef USE_LIST
+   hashmap_element *next = &mi->data[curr];
+   if(next->in_use == 0 && next->next == NULL) {
+      *arg = NULL;
+      return MAP_MISSING;
+   }
+
+   while(next != NULL) {
+      if (next->in_use == 1 && MeowHashesAreEqual(next->key, *key)){
+         *arg = next->ptr;
+         gettimeofday(&end, NULL);
+         timersub(&end, &begin, &elapsed);
+         hgettime_found += elapsed.tv_sec * 1000L * 1000L + elapsed.tv_usec;
+         return MAP_OK;
+      }
+      next = next->next;
+   }
+#else
+	/* Linear probing, if necessary */
+	for(i = 0; i<MAX_CHAIN_LENGTH; i++){
+
+        int in_use = mi->data[curr].in_use;
+        if (in_use == 1){
+            if (MeowHashesAreEqual(mi->data[curr].data.key, *key)){
+                //*arg = (mi->data[curr].data);
+                *arg = &(mi->data[curr].data);
+                //memcpy(arg, &(mi->data[curr].data), sizeof(page_meta));
+                return MAP_OK;
+            }
+		}
+
+		curr = (curr + 1) % mi->m->table_size;
+	}
+#endif
+
+	*arg = NULL;
+
+   gettimeofday(&end, NULL);
+   timersub(&end, &begin, &elapsed);
+   hgettime_miss += elapsed.tv_sec * 1000L * 1000L + elapsed.tv_usec;
+	/* Not found */
+	return MAP_MISSING;
+}
+#endif
+
+/*
+ * Remove an element with that key from the map
+ */
+int hashmap_remove(map_t in, meow_u128 *key){
+	//int i;
+	int curr;
+
+	hashmap_map_info* mi;
+
+	/* Cast the hashmap */
+	mi = (hashmap_map_info *) in;
+
+	/* Find key */
+	curr = MeowU32From(*key, 0) % mi->m->table_size;
+
+#ifdef USE_LIST
+   hashmap_element *next = &mi->data[curr];
+   hashmap_element *prev = &mi->data[curr];
+   while(next != NULL) {
+      if (next->in_use == 1 && MeowHashesAreEqual(next->key, *key)){
+         if(prev == next) {
+            next->in_use = 0;
+            next->idx = 0;
+            //next->key = _mm_setzero_si128();
+         } else {
+            prev->next = next->next;
+            free(next);
+         }
+         /* Reduce the n_elements */
+         mi->m->n_elements--;
+         return MAP_OK;
+      }
+      prev = next;
+      next = next->next;
+   }
+
+#else
+	/* Linear probing, if necessary */
+	for(i = 0; i<MAX_CHAIN_LENGTH; i++){
+
+        int in_use = mi->data[curr].in_use;
+        if (in_use == 1){
+            if (MeowHashesAreEqual(mi->data[curr].data.key, *key)){
+                /* Blank out the fields */
+                mi->data[curr].in_use = 0;
+                //mi->data[curr].data = NULL;
+                mi->data[curr].data.key = _mm_setzero_si128();
+                /* Reduce the n_elements */
+                mi->m->n_elements--;
+                return MAP_OK;
+            }
+		}
+		curr = (curr + 1) % mi->m->table_size;
+	}
+#endif
+
+	/* Data not found */
+	return MAP_MISSING;
+}
+
+/* Deallocate the hashmap */
+void hashmap_free(map_t in){
+	hashmap_map_info* mi = (hashmap_map_info*) in;
+	free(mi->data);
+	free(mi->m);
+	free(mi);
+}
+
+/* Return the length of the hashmap */
+int hashmap_length(map_t in){
+	hashmap_map_info* mi = (hashmap_map_info *) in;
+	if(mi->m != NULL) return mi->m->n_elements;
+	else return 0;
+}
+
+unsigned long hashmap_fixed_size(map_t in) {
+	hashmap_map_info* mi = (hashmap_map_info *) in;
+	if(mi->m != NULL) return mi->m->table_size * sizeof(hashmap_element);
+	else return 0;
+}
diff --git migration/c_hashmap/hashmap_custom.h migration/c_hashmap/hashmap_custom.h
new file mode 100644
index 0000000000..297c15efd7
--- /dev/null
+++ migration/c_hashmap/hashmap_custom.h
@@ -0,0 +1,82 @@
+/*
+ * Generic hashmap manipulation functions
+ *
+ * Originally by Elliot C Back - http://elliottback.com/wp/hashmap-implementation-in-c/
+ *
+ * Modified by Pete Warden to fix a serious performance problem, support strings as keys
+ * and removed thread synchronization - http://petewarden.typepad.com
+ */
+#ifndef HASHMAP_H
+#define HASHMAP_H
+
+#include "migration/meow_hash_x64_aesni.h"
+#define MAP_MISSING -3  /* No such element */
+#define MAP_FULL -2 	/* Hashmap is full */
+#define MAP_OMEM -1 	/* Out of Memory */
+#define MAP_OK 0 	/* OK */
+
+/*
+ * any_t is a pointer.  This allows you to put arbitrary structures in
+ * the hashmap.
+ */
+typedef void *any_t;
+
+/*
+ * PFany is a pointer to a function that can take two any_t arguments
+ * and return an integer. Returns status code..
+ */
+typedef int (*PFany)(any_t, any_t);
+
+/*
+ * map_t is a pointer to an internally maintained data structure.
+ * Clients of this package do not need to know how hashmaps are
+ * represented.  They see and manipulate only map_t's.
+ */
+typedef any_t map_t;
+
+/*
+ * Return an empty hashmap. Returns NULL if empty.
+*/
+//extern map_t hashmap_new(unsigned int initial_size);
+//extern map_t hashmap_new(void);
+//extern map_t hashmap_new(void *ptr, unsigned long n_entries);
+extern map_t hashmap_new(void *ptr, void *data_ptr, unsigned long size, int init);
+
+/*
+ * Add an element to the hashmap. Return MAP_OK or MAP_OMEM.
+ */
+extern int hashmap_put(map_t in, meow_u128 *key, any_t value);
+
+/*
+ * Get an element from the hashmap. Return MAP_OK or MAP_MISSING.
+ */
+extern int hashmap_get(map_t in, meow_u128 *key, any_t *arg);
+int hashmap_get_and_put(map_t in, meow_u128 *key, any_t *arg_get, any_t arg_put);
+int hashmap_get_and_put_static(map_t in, meow_u128 *key, unsigned int *idx_get, unsigned int **idx_put);
+
+/*
+ * Remove an element from the hashmap. Return MAP_OK or MAP_MISSING.
+ */
+extern int hashmap_remove(map_t in, meow_u128 *key);
+
+/*
+ * Free the hashmap
+ */
+extern void hashmap_free(map_t in);
+
+/*
+ * Get the current size of a hashmap
+ */
+extern int hashmap_length(map_t in);
+extern unsigned long hashmap_size(map_t in);
+unsigned long hashmap_fixed_size(map_t in);
+
+unsigned int hashmap_element_size(void);
+typedef struct page_meta {
+   unsigned int refcount;
+   unsigned int index;
+   meow_u128 key;
+} page_meta;
+
+
+#endif
diff --git migration/meow_hash_x64_aesni.h migration/meow_hash_x64_aesni.h
new file mode 100644
index 0000000000..3fac1fb5d7
--- /dev/null
+++ migration/meow_hash_x64_aesni.h
@@ -0,0 +1,745 @@
+/* ========================================================================
+
+   Meow - A Fast Non-cryptographic Hash
+   (C) Copyright 2018-2019 by Molly Rocket, Inc. (https://mollyrocket.com)
+   
+   See https://mollyrocket.com/meowhash for details.
+   
+   ========================================================================
+   
+   zlib License
+   
+   (C) Copyright 2018-2019 Molly Rocket, Inc.
+   
+   This software is provided 'as-is', without any express or implied
+   warranty.  In no event will the authors be held liable for any damages
+   arising from the use of this software.
+   
+   Permission is granted to anyone to use this software for any purpose,
+   including commercial applications, and to alter it and redistribute it
+   freely, subject to the following restrictions:
+   
+   1. The origin of this software must not be misrepresented; you must not
+      claim that you wrote the original software. If you use this software
+      in a product, an acknowledgment in the product documentation would be
+      appreciated but is not required.
+   2. Altered source versions must be plainly marked as such, and must not be
+      misrepresented as being the original software.
+   3. This notice may not be removed or altered from any source distribution.
+   
+   ========================================================================
+   
+   FAQ
+   
+   Q: What is it?
+   
+   A: Meow is a 128-bit Level 3 hash taking 128 bytes of seed.  It operates
+      at very high speeds on x64 processors, and potentially other processors
+      that provide accelerated AES instructions.
+      
+   Q: What is it GOOD for?
+   
+   A: Quickly hashing any amount of data for comparison purposes such as
+      block deduplication or change detection.  It is fast on all buffer
+      sizes, and can generally be used anywhere you need fast Level 3
+      hashing without worrying about how big or small the inputs tend to be.
+      
+      However, substantial speed improvements could be made over Meow
+      if you either a) know you are always hashing an exact, small number of bytes,
+      or b) can always supply a small number of bytes in a buffer padded to some
+      fixed multiple of 16.
+      
+   Q: What is it BAD for?
+   
+   A: Anything requiring Level 4 or Level 5 security guarantees (see
+      http://nohatcoder.dk/2019-05-19-1.html#level3).  Also, note that
+      Meow is a new hash and has not had the extensive community
+      cryptanalysis necessary to ensure that it is not breakable down to
+      a lower level of hash, so you must do your due diligence in
+      deciding when and where to use Meow instead of a slower but
+      more extensively studied existing hash.  We have tried to design
+      it to provide Level 3 security, but the possibility of the hash
+      being broken in the future always exists.
+      
+   Q: Why is it called the "Meow hash"?
+   
+   A: It is named after a character in Meow the Infinite
+      (https://meowtheinfinite.com)
+      
+   Q: Who wrote it?
+   
+   A: The final Meow Hash was created as a collaboration between
+      JACOB CHRISTIAN MUNCH-ANDERSEN (https://twitter.com/nohatcoder) and
+      CASEY MURATORI (https://caseymuratori.com).  Casey wrote the original
+      implementation for use in processing large-footprint assets for the
+      game 1935 (https://molly1935.com).  Jacob was the first to analyze
+      that implementation and determine the adversarial bit strength, which
+      was weaker than they would have liked.
+      
+      Following that, the two collaborated to figure out how the hash
+      could be strengthened without reducing Meow's 16 bytes/cycle
+      maximum theoretical throughput.  Jacob created the hash candidates
+      and Casey did the performance validation.  After a long and
+      exhaustive effort, Jacob found the unaligned aes/add/xor formulation
+      that forms the current Meow hash core.
+      
+      A number of valuable additions to Meow Hash were also contributed
+      by other great folks along the way:
+      
+      JEFF ROBERTS (https://radgametools.com) provided a super slick
+      way to handle the residual end-of-buffer bytes that dramatically
+      improved Meow's small hash performance.
+      
+      MARTINS MOZEIKO (https://matrins.ninja) ported Meow to ARM and
+      ANSI-C, and added the proper preprocessor dressing for clean
+      compilation on a variety of compiler configurations.
+      
+      FABIAN GIESEN (https://fgiesen.wordpress.com) analyzed many
+      performance oddities that came up during development, and
+      helped get the benchmarking working properly across a number
+      of platforms.
+      
+      ARAS PRANCKEVICIUS (https://aras-p.info) provided the allocation
+      shim for compilation on Mac OS X.
+      
+   ======================================================================== */
+
+//
+// IMPORTANT(casey): We are currently evaluating this hash construction as
+// the final one for Meow Hash.  If you find a way to produce collisions
+// that should not be possible with a Level 3 hash, find significant performance
+// problems, or see any bugs in this version, please be sure to report them
+// to the Meow Hash GitHub as soon as possible.  We would like to know as
+// much as we can about the robustness and performance before committing to
+// it as the final construction.
+//
+
+#if !defined(MEOW_HASH_X64_AESNI_H)
+
+#define MEOW_HASH_VERSION 5
+#define MEOW_HASH_VERSION_NAME "0.5/calico"
+
+#if !defined(meow_u8)
+
+#ifdef _MSC_VER
+#if !defined(__clang__)
+#define INSTRUCTION_REORDER_BARRIER _ReadWriteBarrier()
+#else
+#endif
+#include <intrin.h>
+#else
+#include <x86intrin.h>
+#endif
+
+#define meow_u8 char unsigned
+#define meow_u64 long long unsigned
+#define meow_u128 __m128i
+
+#if __x86_64__ || _M_AMD64
+#define meow_umm long long unsigned
+#define MeowU64From(A, I) (_mm_extract_epi64((A), (I)))
+#elif __i386__  || _M_IX86
+#define meow_umm int unsigned
+#define MeowU64From(A, I) (*(meow_u64 *)&(A))
+#else
+#error Cannot determine architecture to use!
+#endif
+
+#define MeowU16From(A, I) (_mm_extract_epi16((A), (I)))
+#define MeowU32From(A, I) (_mm_extract_epi32((A), (I)))
+#define MeowHashesAreEqual(A, B) (_mm_movemask_epi8(_mm_cmpeq_epi8((A), (B))) == 0xFFFF)
+
+#if !defined INSTRUCTION_REORDER_BARRIER
+#define INSTRUCTION_REORDER_BARRIER
+#endif
+
+#if !defined MEOW_PAGESIZE
+#define MEOW_PAGESIZE 4096
+#endif
+
+#if !defined MEOW_PREFETCH
+#define MEOW_PREFETCH 4096
+#endif
+
+#if !defined MEOW_PREFETCH_LIMIT
+#define MEOW_PREFETCH_LIMIT 0x3ff
+#endif
+
+#endif
+
+#define prefetcht0(A) _mm_prefetch((char *)(A), _MM_HINT_T0)
+#define movdqu(A, B)  A = _mm_loadu_si128((__m128i *)(B))
+#define movdqu_mem(A, B)  _mm_storeu_si128((__m128i *)(A), B)
+#define movq(A, B) A = _mm_set_epi64x(0, B);
+#define aesdec(A, B)  A = _mm_aesdec_si128(A, B)
+#define pshufb(A, B)  A = _mm_shuffle_epi8(A, B)
+#define pxor(A, B)    A = _mm_xor_si128(A, B)
+#define paddq(A, B) A = _mm_add_epi64(A, B)
+#define pand(A, B)    A = _mm_and_si128(A, B)
+#define palignr(A, B, i) A = _mm_alignr_epi8(A, B, i)
+#define pxor_clear(A, B)    A = _mm_setzero_si128(); // NOTE(casey): pxor_clear is a nonsense thing that is only here because compilers don't detect xor(a, a) is clearing a :(
+
+#define MEOW_MIX_REG(r1, r2, r3, r4, r5,  i1, i2, i3, i4) \
+aesdec(r1, r2); \
+INSTRUCTION_REORDER_BARRIER; \
+paddq(r3, i1); \
+pxor(r2, i2); \
+aesdec(r2, r4); \
+INSTRUCTION_REORDER_BARRIER; \
+paddq(r5, i3); \
+pxor(r4, i4);
+
+#define MEOW_MIX(r1, r2, r3, r4, r5,  ptr) \
+MEOW_MIX_REG(r1, r2, r3, r4, r5, _mm_loadu_si128( (__m128i *) ((ptr) + 15) ), _mm_loadu_si128( (__m128i *) ((ptr) + 0)  ), _mm_loadu_si128( (__m128i *) ((ptr) + 1)  ), _mm_loadu_si128( (__m128i *) ((ptr) + 16) ))
+
+#define MEOW_SHUFFLE(r1, r2, r3, r4, r5, r6) \
+aesdec(r1, r4); \
+paddq(r2, r5); \
+pxor(r4, r6); \
+aesdec(r4, r2); \
+paddq(r5, r6); \
+pxor(r2, r3)
+
+#ifdef MEOW_DUMP
+struct meow_dump
+{
+    meow_u128 xmm[8];
+    void *Ptr;
+    char const *Title;
+};
+extern "C" meow_dump *MeowDumpTo;
+meow_dump *MeowDumpTo;
+#define MEOW_DUMP_STATE(T, xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, ptr) \
+if(MeowDumpTo) \
+{ \
+    MeowDumpTo->xmm[0] = xmm0; \
+    MeowDumpTo->xmm[1] = xmm1; \
+    MeowDumpTo->xmm[2] = xmm2; \
+    MeowDumpTo->xmm[3] = xmm3; \
+    MeowDumpTo->xmm[4] = xmm4; \
+    MeowDumpTo->xmm[5] = xmm5; \
+    MeowDumpTo->xmm[6] = xmm6; \
+    MeowDumpTo->xmm[7] = xmm7; \
+    MeowDumpTo->Ptr = ptr; \
+    MeowDumpTo->Title = T; \
+    ++MeowDumpTo; \
+}
+#else
+#define MEOW_DUMP_STATE(...)
+#endif
+
+static meow_u8 MeowShiftAdjust[32] = {0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15};
+static meow_u8 MeowMaskLen[32] = {255,255,255,255, 255,255,255,255, 255,255,255,255, 255,255,255,255, 0,0,0,0, 0,0,0,0, 0,0,0,0, 0,0,0,0};
+
+// NOTE(casey): The default seed is now a "nothing-up-our-sleeves" number for good measure.  You may verify that it is just an encoding of Pi.
+static meow_u8 MeowDefaultSeed[128] =
+{
+    0x32, 0x43, 0xF6, 0xA8, 0x88, 0x5A, 0x30, 0x8D,
+	0x31, 0x31, 0x98, 0xA2, 0xE0, 0x37, 0x07, 0x34,
+	0x4A, 0x40, 0x93, 0x82, 0x22, 0x99, 0xF3, 0x1D,
+	0x00, 0x82, 0xEF, 0xA9, 0x8E, 0xC4, 0xE6, 0xC8,
+	0x94, 0x52, 0x82, 0x1E, 0x63, 0x8D, 0x01, 0x37,
+	0x7B, 0xE5, 0x46, 0x6C, 0xF3, 0x4E, 0x90, 0xC6,
+	0xCC, 0x0A, 0xC2, 0x9B, 0x7C, 0x97, 0xC5, 0x0D,
+	0xD3, 0xF8, 0x4D, 0x5B, 0x5B, 0x54, 0x70, 0x91,
+	0x79, 0x21, 0x6D, 0x5D, 0x98, 0x97, 0x9F, 0xB1,
+	0xBD, 0x13, 0x10, 0xBA, 0x69, 0x8D, 0xFB, 0x5A,
+	0xC2, 0xFF, 0xD7, 0x2D, 0xBD, 0x01, 0xAD, 0xFB,
+	0x7B, 0x8E, 0x1A, 0xFE, 0xD6, 0xA2, 0x67, 0xE9,
+	0x6B, 0xA7, 0xC9, 0x04, 0x5F, 0x12, 0xC7, 0xF9,
+	0x92, 0x4A, 0x19, 0x94, 0x7B, 0x39, 0x16, 0xCF,
+	0x70, 0x80, 0x1F, 0x2E, 0x28, 0x58, 0xEF, 0xC1,
+	0x66, 0x36, 0x92, 0x0D, 0x87, 0x15, 0x74, 0xE6
+};
+
+//
+// NOTE(casey): Single block version
+//
+
+static meow_u128
+MeowHash(void *Seed128Init, meow_umm Len, void *SourceInit)
+{
+    meow_u128 xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7; // NOTE(casey): xmm0-xmm7 are the hash accumulation lanes
+    meow_u128 xmm8, xmm9, xmm10, xmm11, xmm12, xmm13, xmm14, xmm15; // NOTE(casey): xmm8-xmm15 hold values to be appended (residual, length)
+    
+    meow_u8 *rax = (meow_u8 *)SourceInit;
+    meow_u8 *rcx = (meow_u8 *)Seed128Init;
+    
+    //
+	// NOTE(casey): Seed the eight hash registers
+    //
+    
+    movdqu(xmm0, rcx + 0x00);
+    movdqu(xmm1, rcx + 0x10);
+    movdqu(xmm2, rcx + 0x20);
+    movdqu(xmm3, rcx + 0x30);
+    
+    movdqu(xmm4, rcx + 0x40);
+    movdqu(xmm5, rcx + 0x50);
+    movdqu(xmm6, rcx + 0x60);
+    movdqu(xmm7, rcx + 0x70);
+    
+    MEOW_DUMP_STATE("Seed", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    //
+    // NOTE(casey): Hash all full 256-byte blocks
+    //
+    
+    meow_umm BlockCount = (Len >> 8);
+    if(BlockCount > MEOW_PREFETCH_LIMIT)
+    {
+        // NOTE(casey): For large input, modern Intel x64's can't hit full speed without prefetching, so we use this loop
+        while(BlockCount--)
+        {
+            prefetcht0(rax + MEOW_PREFETCH + 0x00);
+            prefetcht0(rax + MEOW_PREFETCH + 0x40);
+            prefetcht0(rax + MEOW_PREFETCH + 0x80);
+            prefetcht0(rax + MEOW_PREFETCH + 0xc0);
+            
+            MEOW_MIX(xmm0,xmm4,xmm6,xmm1,xmm2, rax + 0x00);
+            MEOW_MIX(xmm1,xmm5,xmm7,xmm2,xmm3, rax + 0x20);
+            MEOW_MIX(xmm2,xmm6,xmm0,xmm3,xmm4, rax + 0x40);
+            MEOW_MIX(xmm3,xmm7,xmm1,xmm4,xmm5, rax + 0x60);
+            MEOW_MIX(xmm4,xmm0,xmm2,xmm5,xmm6, rax + 0x80);
+            MEOW_MIX(xmm5,xmm1,xmm3,xmm6,xmm7, rax + 0xa0);
+            MEOW_MIX(xmm6,xmm2,xmm4,xmm7,xmm0, rax + 0xc0);
+            MEOW_MIX(xmm7,xmm3,xmm5,xmm0,xmm1, rax + 0xe0);
+            
+            rax += 0x100;
+        }
+    }
+    else
+    {
+        // NOTE(casey): For small input, modern Intel x64's can't hit full speed _with_ prefetching (because of port pressure), so we use this loop.
+        while(BlockCount--)
+        {
+            MEOW_MIX(xmm0,xmm4,xmm6,xmm1,xmm2, rax + 0x00);
+            MEOW_MIX(xmm1,xmm5,xmm7,xmm2,xmm3, rax + 0x20);
+            MEOW_MIX(xmm2,xmm6,xmm0,xmm3,xmm4, rax + 0x40);
+            MEOW_MIX(xmm3,xmm7,xmm1,xmm4,xmm5, rax + 0x60);
+            MEOW_MIX(xmm4,xmm0,xmm2,xmm5,xmm6, rax + 0x80);
+            MEOW_MIX(xmm5,xmm1,xmm3,xmm6,xmm7, rax + 0xa0);
+            MEOW_MIX(xmm6,xmm2,xmm4,xmm7,xmm0, rax + 0xc0);
+            MEOW_MIX(xmm7,xmm3,xmm5,xmm0,xmm1, rax + 0xe0);
+            
+            rax += 0x100;
+        }
+    }
+    
+    MEOW_DUMP_STATE("PostBlocks", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    //
+    // NOTE(casey): Load any less-than-32-byte residual
+    //
+    
+    pxor_clear(xmm9, xmm9);
+    pxor_clear(xmm11, xmm11);
+    
+    //
+    // TODO(casey): I need to put more thought into how the end-of-buffer stuff is actually working out here,
+    // because I _think_ it may be possible to remove the first branch (on Len8) and let the mask zero out the
+    // result, but it would take a little thought to make sure it couldn't read off the end of the buffer due
+    // to the & 0xf on the align computation.
+    //
+    
+    // NOTE(casey): First, we have to load the part that is _not_ 16-byte aligned
+    meow_u8 *Last = (meow_u8 *)SourceInit + (Len & ~0xf);
+    int unsigned Len8 = (Len & 0xf);
+    if(Len8)
+    {
+        // NOTE(casey): Load the mask early
+        movdqu(xmm8, &MeowMaskLen[0x10 - Len8]);
+        
+        meow_u8 *LastOk = (meow_u8*)((((meow_umm)(((meow_u8 *)SourceInit)+Len - 1)) | (MEOW_PAGESIZE - 1)) - 16);
+        int Align = (Last > LastOk) ? ((int)(meow_umm)Last) & 0xf : 0;
+        movdqu(xmm10, &MeowShiftAdjust[Align]);
+        movdqu(xmm9, Last - Align);
+        pshufb(xmm9, xmm10);
+        
+        // NOTE(jeffr): and off the extra bytes
+        pand(xmm9, xmm8);
+    }
+    
+    // NOTE(casey): Next, we have to load the part that _is_ 16-byte aligned
+    if(Len & 0x10)
+    {
+        xmm11 = xmm9;
+        movdqu(xmm9, Last - 0x10);
+    }
+    
+    //
+    // NOTE(casey): Construct the residual and length injests
+    //
+    
+    xmm8 = xmm9;
+    xmm10 = xmm9;
+    palignr(xmm8, xmm11, 15);
+    palignr(xmm10, xmm11, 1);
+    
+    // NOTE(casey): We have room for a 128-bit nonce and a 64-bit none here, but
+    // the decision was made to leave them zero'd so as not to confuse people
+    // about hwo to use them or what security implications they had.
+    pxor_clear(xmm12, xmm12);
+    pxor_clear(xmm13, xmm13);
+    pxor_clear(xmm14, xmm14);
+    movq(xmm15, Len);
+    palignr(xmm12, xmm15, 15);
+    palignr(xmm14, xmm15, 1);
+    
+    MEOW_DUMP_STATE("Residuals", xmm8, xmm9, xmm10, xmm11, xmm12, xmm13, xmm14, xmm15, 0);
+    
+    // NOTE(casey): To maintain the mix-down pattern, we always Meow Mix the less-than-32-byte residual, even if it was empty
+    MEOW_MIX_REG(xmm0, xmm4, xmm6, xmm1, xmm2,  xmm8, xmm9, xmm10, xmm11);
+    
+    // NOTE(casey): Append the length, to avoid problems with our 32-byte padding
+    MEOW_MIX_REG(xmm1, xmm5, xmm7, xmm2, xmm3,  xmm12, xmm13, xmm14, xmm15);
+    
+    MEOW_DUMP_STATE("PostAppend", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    //
+    // NOTE(casey): Hash all full 32-byte blocks
+    //
+    int unsigned LaneCount = (Len >> 5) & 0x7;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm2,xmm6,xmm0,xmm3,xmm4, rax + 0x00); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm3,xmm7,xmm1,xmm4,xmm5, rax + 0x20); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm4,xmm0,xmm2,xmm5,xmm6, rax + 0x40); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm5,xmm1,xmm3,xmm6,xmm7, rax + 0x60); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm6,xmm2,xmm4,xmm7,xmm0, rax + 0x80); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm7,xmm3,xmm5,xmm0,xmm1, rax + 0xa0); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm0,xmm4,xmm6,xmm1,xmm2, rax + 0xc0); --LaneCount;
+    
+    //
+    // NOTE(casey): Mix the eight lanes down to one 128-bit hash
+    //
+    
+    MixDown:
+    
+    MEOW_DUMP_STATE("PostLanes", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    MEOW_SHUFFLE(xmm0, xmm1, xmm2, xmm4, xmm5, xmm6);
+    MEOW_SHUFFLE(xmm1, xmm2, xmm3, xmm5, xmm6, xmm7);
+    MEOW_SHUFFLE(xmm2, xmm3, xmm4, xmm6, xmm7, xmm0);
+    MEOW_SHUFFLE(xmm3, xmm4, xmm5, xmm7, xmm0, xmm1);
+    MEOW_SHUFFLE(xmm4, xmm5, xmm6, xmm0, xmm1, xmm2);
+    MEOW_SHUFFLE(xmm5, xmm6, xmm7, xmm1, xmm2, xmm3);
+    MEOW_SHUFFLE(xmm6, xmm7, xmm0, xmm2, xmm3, xmm4);
+    MEOW_SHUFFLE(xmm7, xmm0, xmm1, xmm3, xmm4, xmm5);
+    MEOW_SHUFFLE(xmm0, xmm1, xmm2, xmm4, xmm5, xmm6);
+    MEOW_SHUFFLE(xmm1, xmm2, xmm3, xmm5, xmm6, xmm7);
+    MEOW_SHUFFLE(xmm2, xmm3, xmm4, xmm6, xmm7, xmm0);
+    MEOW_SHUFFLE(xmm3, xmm4, xmm5, xmm7, xmm0, xmm1);
+    
+    MEOW_DUMP_STATE("PostMix", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    paddq(xmm0, xmm2);
+    paddq(xmm1, xmm3);
+    paddq(xmm4, xmm6);
+    paddq(xmm5, xmm7);
+    pxor(xmm0, xmm1);
+    pxor(xmm4, xmm5);
+    paddq(xmm0, xmm4);
+    
+    MEOW_DUMP_STATE("PostFold", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    return(xmm0);
+}
+
+//
+// NOTE(casey): Streaming construction
+//
+
+typedef struct meow_state
+{
+    meow_u128 xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7;
+    meow_u64 TotalLengthInBytes;
+    
+    int unsigned BufferLen;
+    
+    meow_u8 Buffer[256];
+    meow_u128 Pad[2]; // NOTE(casey): So we know we can over-read Buffer as necessary
+} meow_state;
+
+static void
+MeowBegin(meow_state *State, void *Seed128)
+{
+    meow_u8 *rcx = (meow_u8 *)Seed128;
+    
+    movdqu(State->xmm0, rcx + 0x00);
+    movdqu(State->xmm1, rcx + 0x10);
+    movdqu(State->xmm2, rcx + 0x20);
+    movdqu(State->xmm3, rcx + 0x30);
+    movdqu(State->xmm4, rcx + 0x40);
+    movdqu(State->xmm5, rcx + 0x50);
+    movdqu(State->xmm6, rcx + 0x60);
+    movdqu(State->xmm7, rcx + 0x70);
+    
+    MEOW_DUMP_STATE("Seed", State->xmm0, State->xmm1, State->xmm2, State->xmm3, State->xmm4, State->xmm5, State->xmm6, State->xmm7, 0);
+    
+    State->BufferLen = 0;
+    State->TotalLengthInBytes = 0;
+}
+
+static void
+MeowAbsorbBlocks(meow_state *State, meow_umm BlockCount, meow_u8 *rax)
+{
+    meow_u128 xmm0 = State->xmm0;
+    meow_u128 xmm1 = State->xmm1;
+    meow_u128 xmm2 = State->xmm2;
+    meow_u128 xmm3 = State->xmm3;
+    meow_u128 xmm4 = State->xmm4;
+    meow_u128 xmm5 = State->xmm5;
+    meow_u128 xmm6 = State->xmm6;
+    meow_u128 xmm7 = State->xmm7;
+    
+    if(BlockCount > MEOW_PREFETCH_LIMIT)
+    {
+        while(BlockCount--)
+        {
+            prefetcht0(rax + MEOW_PREFETCH + 0x00);
+            prefetcht0(rax + MEOW_PREFETCH + 0x40);
+            prefetcht0(rax + MEOW_PREFETCH + 0x80);
+            prefetcht0(rax + MEOW_PREFETCH + 0xc0);
+            
+            MEOW_MIX(xmm0,xmm4,xmm6,xmm1,xmm2, rax + 0x00);
+            MEOW_MIX(xmm1,xmm5,xmm7,xmm2,xmm3, rax + 0x20);
+            MEOW_MIX(xmm2,xmm6,xmm0,xmm3,xmm4, rax + 0x40);
+            MEOW_MIX(xmm3,xmm7,xmm1,xmm4,xmm5, rax + 0x60);
+            MEOW_MIX(xmm4,xmm0,xmm2,xmm5,xmm6, rax + 0x80);
+            MEOW_MIX(xmm5,xmm1,xmm3,xmm6,xmm7, rax + 0xa0);
+            MEOW_MIX(xmm6,xmm2,xmm4,xmm7,xmm0, rax + 0xc0);
+            MEOW_MIX(xmm7,xmm3,xmm5,xmm0,xmm1, rax + 0xe0);
+            
+            rax += 0x100;
+        }
+    }
+    else
+    {
+        while(BlockCount--)
+        {
+            MEOW_MIX(xmm0,xmm4,xmm6,xmm1,xmm2, rax + 0x00);
+            MEOW_MIX(xmm1,xmm5,xmm7,xmm2,xmm3, rax + 0x20);
+            MEOW_MIX(xmm2,xmm6,xmm0,xmm3,xmm4, rax + 0x40);
+            MEOW_MIX(xmm3,xmm7,xmm1,xmm4,xmm5, rax + 0x60);
+            MEOW_MIX(xmm4,xmm0,xmm2,xmm5,xmm6, rax + 0x80);
+            MEOW_MIX(xmm5,xmm1,xmm3,xmm6,xmm7, rax + 0xa0);
+            MEOW_MIX(xmm6,xmm2,xmm4,xmm7,xmm0, rax + 0xc0);
+            MEOW_MIX(xmm7,xmm3,xmm5,xmm0,xmm1, rax + 0xe0);
+            
+            rax += 0x100;
+        }
+    }
+    
+    State->xmm0 = xmm0;
+    State->xmm1 = xmm1;
+    State->xmm2 = xmm2;
+    State->xmm3 = xmm3;
+    State->xmm4 = xmm4;
+    State->xmm5 = xmm5;
+    State->xmm6 = xmm6;
+    State->xmm7 = xmm7;
+}
+
+static void
+MeowAbsorb(meow_state *State, meow_umm Len, void *SourceInit)
+{
+    State->TotalLengthInBytes += Len;
+    meow_u8 *Source = (meow_u8 *)SourceInit;
+    
+    // NOTE(casey): Handle any buffered residual
+    if(State->BufferLen)
+    {
+        int unsigned Fill = (sizeof(State->Buffer) - State->BufferLen);
+        if(Fill > Len)
+        {
+            Fill = (int unsigned)Len;
+        }
+        
+        Len -= Fill;
+        while(Fill--)
+        {
+            State->Buffer[State->BufferLen++] = *Source++;
+        }
+        
+        if(State->BufferLen == sizeof(State->Buffer))
+        {
+            MeowAbsorbBlocks(State, 1, State->Buffer);
+            State->BufferLen = 0;
+        }
+    }
+    
+    // NOTE(casey): Handle any full blocks
+    meow_u64 BlockCount = (Len >> 8);
+    meow_u64 Advance = (BlockCount << 8);
+    MeowAbsorbBlocks(State, BlockCount, Source);
+    
+    Len -= Advance;
+    Source += Advance;
+    
+    // NOTE(casey): Store residual
+    while(Len--)
+    {
+        State->Buffer[State->BufferLen++] = *Source++;
+    }
+}
+
+static meow_u128
+MeowEnd(meow_state *State, meow_u8 *Store128)
+{
+    meow_umm Len = State->TotalLengthInBytes;
+    
+    meow_u128 xmm0 = State->xmm0;
+    meow_u128 xmm1 = State->xmm1;
+    meow_u128 xmm2 = State->xmm2;
+    meow_u128 xmm3 = State->xmm3;
+    meow_u128 xmm4 = State->xmm4;
+    meow_u128 xmm5 = State->xmm5;
+    meow_u128 xmm6 = State->xmm6;
+    meow_u128 xmm7 = State->xmm7;
+    
+    meow_u128 xmm8, xmm9, xmm10, xmm11, xmm12, xmm13, xmm14, xmm15;
+    
+    meow_u8 *rax = State->Buffer;
+    
+    pxor_clear(xmm9, xmm9);
+    pxor_clear(xmm11, xmm11);
+    
+    meow_u8 *Last = (meow_u8 *)rax + (Len & 0xf0);
+    int unsigned Len8 = (Len & 0xf);
+    if(Len8)
+    {
+        movdqu(xmm8, &MeowMaskLen[0x10 - Len8]);
+        movdqu(xmm9, Last);
+        pand(xmm9, xmm8);
+    }
+    
+    if(Len & 0x10)
+    {
+        xmm11 = xmm9;
+        movdqu(xmm9, Last - 0x10);
+    }
+    
+    xmm8 = xmm9;
+    xmm10 = xmm9;
+    palignr(xmm8, xmm11, 15);
+    palignr(xmm10, xmm11, 1);
+    
+    pxor_clear(xmm12, xmm12);
+    pxor_clear(xmm13, xmm13);
+    pxor_clear(xmm14, xmm14);
+    movq(xmm15, Len);
+    palignr(xmm12, xmm15, 15);
+    palignr(xmm14, xmm15, 1);
+    
+    MEOW_DUMP_STATE("PostBlocks", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    MEOW_DUMP_STATE("Residuals", xmm8, xmm9, xmm10, xmm11, xmm12, xmm13, xmm14, xmm15, 0);
+    
+    // NOTE(casey): To maintain the mix-down pattern, we always Meow Mix the less-than-32-byte residual, even if it was empty
+    MEOW_MIX_REG(xmm0, xmm4, xmm6, xmm1, xmm2,  xmm8, xmm9, xmm10, xmm11);
+    
+    // NOTE(casey): Append the length, to avoid problems with our 32-byte padding
+    MEOW_MIX_REG(xmm1, xmm5, xmm7, xmm2, xmm3,  xmm12, xmm13, xmm14, xmm15);
+    
+    MEOW_DUMP_STATE("PostAppend", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    //
+    // NOTE(casey): Hash all full 32-byte blocks
+    //
+    int unsigned LaneCount = (Len >> 5) & 0x7;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm2,xmm6,xmm0,xmm3,xmm4, rax + 0x00); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm3,xmm7,xmm1,xmm4,xmm5, rax + 0x20); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm4,xmm0,xmm2,xmm5,xmm6, rax + 0x40); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm5,xmm1,xmm3,xmm6,xmm7, rax + 0x60); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm6,xmm2,xmm4,xmm7,xmm0, rax + 0x80); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm7,xmm3,xmm5,xmm0,xmm1, rax + 0xa0); --LaneCount;
+    if(LaneCount == 0) goto MixDown; MEOW_MIX(xmm0,xmm4,xmm6,xmm1,xmm2, rax + 0xc0); --LaneCount;
+    
+    //
+    // NOTE(casey): Mix the eight lanes down to one 128-bit hash
+    //
+    
+    MixDown:
+    
+    MEOW_DUMP_STATE("PostLanes", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    MEOW_SHUFFLE(xmm0, xmm1, xmm2, xmm4, xmm5, xmm6);
+    MEOW_SHUFFLE(xmm1, xmm2, xmm3, xmm5, xmm6, xmm7);
+    MEOW_SHUFFLE(xmm2, xmm3, xmm4, xmm6, xmm7, xmm0);
+    MEOW_SHUFFLE(xmm3, xmm4, xmm5, xmm7, xmm0, xmm1);
+    MEOW_SHUFFLE(xmm4, xmm5, xmm6, xmm0, xmm1, xmm2);
+    MEOW_SHUFFLE(xmm5, xmm6, xmm7, xmm1, xmm2, xmm3);
+    MEOW_SHUFFLE(xmm6, xmm7, xmm0, xmm2, xmm3, xmm4);
+    MEOW_SHUFFLE(xmm7, xmm0, xmm1, xmm3, xmm4, xmm5);
+    MEOW_SHUFFLE(xmm0, xmm1, xmm2, xmm4, xmm5, xmm6);
+    MEOW_SHUFFLE(xmm1, xmm2, xmm3, xmm5, xmm6, xmm7);
+    MEOW_SHUFFLE(xmm2, xmm3, xmm4, xmm6, xmm7, xmm0);
+    MEOW_SHUFFLE(xmm3, xmm4, xmm5, xmm7, xmm0, xmm1);
+    
+    MEOW_DUMP_STATE("PostMix", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    if(Store128)
+    {
+        movdqu_mem(Store128 + 0x00, xmm0);
+        movdqu_mem(Store128 + 0x10, xmm1);
+        movdqu_mem(Store128 + 0x20, xmm2);
+        movdqu_mem(Store128 + 0x30, xmm3);
+        movdqu_mem(Store128 + 0x40, xmm4);
+        movdqu_mem(Store128 + 0x50, xmm5);
+        movdqu_mem(Store128 + 0x60, xmm6);
+        movdqu_mem(Store128 + 0x70, xmm7);
+    }
+    
+    paddq(xmm0, xmm2);
+    paddq(xmm1, xmm3);
+    paddq(xmm4, xmm6);
+    paddq(xmm5, xmm7);
+    pxor(xmm0, xmm1);
+    pxor(xmm4, xmm5);
+    paddq(xmm0, xmm4);
+    
+    MEOW_DUMP_STATE("PostFold", xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7, 0);
+    
+    return(xmm0);
+}
+
+#undef INSTRUCTION_REORDER_BARRIER
+#undef prefetcht0
+#undef movdqu
+#undef movdqu_mem
+#undef movq
+#undef aesdec
+#undef pshufb
+#undef pxor
+#undef paddq
+#undef pand
+#undef palignr
+#undef pxor_clear
+#undef MEOW_MIX
+#undef MEOW_MIX_REG
+#undef MEOW_SHUFFLE
+#undef MEOW_DUMP_STATE
+
+//
+// NOTE(casey): If you need to create your own seed from non-random data, you can use MeowExpandSeed
+// to create a seed which you then store for repeated use.  It is _expensive_ to generate the seed,
+// so you do not want to do this every time you hash.  You _only_ want to do it when you actually
+// need to create a new seed.
+//
+
+static void
+MeowExpandSeed(meow_umm InputLen, void *Input, meow_u8 *SeedResult)
+{
+    meow_state State;
+    meow_u64 LengthTab = (meow_u64)InputLen; // NOTE(casey): We need to always injest 8-byte lengths exactly, even on 32-bit builds, to ensure identical results
+    meow_umm InjestCount = (256 / InputLen) + 2;
+    
+    MeowBegin(&State, MeowDefaultSeed);
+    MeowAbsorb(&State, sizeof(LengthTab), &LengthTab);
+    while(InjestCount--)
+    {
+        MeowAbsorb(&State, InputLen, Input);
+    }
+    MeowEnd(&State, SeedResult);
+}
+
+#define MEOW_HASH_X64_AESNI_H
+#endif
diff --git migration/periscope-afl.c migration/periscope-afl.c
new file mode 100644
index 0000000000..d01cc2a4db
--- /dev/null
+++ migration/periscope-afl.c
@@ -0,0 +1,327 @@
+/*
+ * periscope-afl.c
+ *
+ * Authors:
+ *  dokyungs@uci.edu
+ */
+
+#include "qemu/osdep.h"
+#include "qapi/error.h"
+
+#include <sys/shm.h>
+
+#include "periscope.h"
+#include "periscope-timers.h"
+
+#include "libafl.h"
+
+#define AFL_COVERAGE_SUPPORT 1
+
+#define MAP_SIZE_POW2 16
+#define MAP_SIZE (1 << MAP_SIZE_POW2)
+
+static int st_pipe;
+static int ctl_pipe;
+static char *shm_ptr;
+static int shm_id;
+
+static char *afl_out_file = NULL;
+static char *afl_out_dir = NULL;
+static char afl_queue_file[512];
+static char *afl_cur_input = NULL;
+static int afl_cur_input_fd = -1;
+static int afl_cur_input_size = -1;
+
+static char *afl_get_cur_input(uint32_t *len) {
+    if (len) {
+        *len = afl_cur_input_size;
+
+        if (*len > MAX_INPUT_BYTES)
+            *len = MAX_INPUT_BYTES;
+    }
+
+    return afl_cur_input;
+}
+
+static char *afl_fetch_cur_input(uint32_t* len) {
+    int res;
+    int prev_timed_out;
+    int child_pid = 1; // fake child_pid
+
+    FuzzerState *s = fuzzer_get_current();
+    if (!s) {
+        printf("periscope: fuzzer not initialized!!!\n");
+        return NULL;
+    }
+
+    if ((res = read(ctl_pipe, &prev_timed_out, 4)) != 4) {
+        printf("periscope: read from control pipe failed\n");
+        return NULL;
+    }
+
+    if (prev_timed_out > 0) {
+        printf("periscope: AFL reports timeout\n");
+    }
+
+    if ((res = write(st_pipe, &child_pid, 4)) != 4) {
+        printf("periscope: write to status pipe failed\n");
+        return NULL;
+    }
+
+    // printf("periscope: fetching input...\n");
+
+    if (afl_cur_input) {
+        munmap(afl_cur_input, afl_cur_input_size);
+        afl_cur_input = NULL;
+    }
+
+    if (afl_cur_input_fd > 0) {
+        qemu_close(afl_cur_input_fd);
+    }
+
+    afl_cur_input_fd = qemu_open(afl_out_file, O_RDONLY|O_BINARY);
+    if (afl_cur_input_fd < 0) {
+        printf("periscope: afl cur input does not exist!!!\n");
+        exit(1);
+    }
+
+    struct stat st;
+    stat(afl_out_file, &st);
+    afl_cur_input_size = st.st_size;
+
+    afl_cur_input = mmap(NULL, afl_cur_input_size, PROT_READ,
+                         MAP_PRIVATE | MAP_POPULATE,
+                         afl_cur_input_fd, 0);
+
+    int mutated_at = -1;
+    int afl_cur_queue_fd = qemu_open(afl_queue_file, O_RDONLY | O_BINARY);
+    if (afl_cur_queue_fd > 0) {
+        stat(afl_queue_file, &st);
+        int afl_queue_input_size = st.st_size;
+
+        char *afl_queue_input =
+            mmap(NULL, afl_queue_input_size, PROT_READ,
+                 MAP_PRIVATE | MAP_POPULATE, afl_cur_queue_fd, 0);
+
+        if (afl_queue_input == NULL) {
+            printf("periscope: afl queue input mmap failed\n");
+        }
+
+        int smaller = afl_queue_input_size;
+        if (smaller > afl_cur_input_size) {
+            smaller = afl_cur_input_size;
+        }
+
+        mutated_at = 0;
+        for (int i = 0; i < smaller; i++) {
+            mutated_at = i;
+            if (afl_cur_input[i] != afl_queue_input[i]) {
+                break;
+            }
+        }
+
+        munmap(afl_queue_input, afl_queue_input_size);
+        close(afl_cur_queue_fd);
+    }
+
+    printf("periscope: afl mutated input at %d\n", mutated_at);
+
+    if (mutated_at > 0) {
+        periscope_change_chkpt_policy(
+            PERISCOPE_CHKPT_TIME_ONLY_DISABLED_AFTER_NTH, mutated_at - 1);
+    } else if (mutated_at == -1) {
+        periscope_change_chkpt_policy(PERISCOPE_CHKPT_TIME_ONLY, -1);
+    } else {
+        periscope_change_chkpt_policy(PERISCOPE_CHKPT_DISABLED, -1);
+    }
+
+#if !AFL_COVERAGE_SUPPORT
+    int status = 0;
+    if ((res = write(st_pipe, &status, 4)) != 4) {
+        printf("periscope: write to status pipe failed\n");
+    }
+#endif
+
+    return afl_get_cur_input(len);
+}
+
+static int afl_fuzzer_mmio_read(unsigned size, uint64_t *out) {
+    if (afl_cur_input == NULL) {
+        printf("periscope: input not found!!!\n");
+        return -1;
+    }
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    periscope_input_desc *cur = s->cur_input;
+    assert(cur != NULL);
+
+    *out = 0;
+
+    switch (size) {
+    case 1:
+        if (cur->used_len + size <= afl_cur_input_size) {
+            *out = *((uint8_t*)&afl_cur_input[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 2:
+        if (cur->used_len + size <= afl_cur_input_size) {
+            *out = *((uint16_t*)&afl_cur_input[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 4:
+        if (cur->used_len + size <= afl_cur_input_size) {
+            *out = *((uint32_t*)&afl_cur_input[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 8:
+        if (cur->used_len + sizeof(uint64_t) <= afl_cur_input_size) {
+            *out = *((uint64_t*)&afl_cur_input[cur->used_len]);
+            cur->used_len += sizeof(uint64_t);
+        }
+        break;
+    default:
+        printf("periscope: unexpected size!\n");
+        if (cur->used_len + sizeof(uint64_t) <= afl_cur_input_size) {
+            *out = *((uint64_t*)&afl_cur_input[cur->used_len]);
+            cur->used_len += sizeof(uint64_t);
+        }
+        break;
+    }
+
+    return 0;
+}
+
+#if AFL_COVERAGE_SUPPORT
+static void afl_cur_input_executed(uint8_t *trace_bits, uint32_t used_len, uint64_t elapsed_ms, bool timed_out) {
+    int res;
+    int status = 0;
+
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+    assert(fs->cur_cp);
+    qemu_timeval elapsed;
+    elapsed.tv_sec = (elapsed_ms) / 1000;
+    elapsed.tv_usec = ((elapsed_ms) % 1000) * 1000;
+    memcpy(&fs->cur_cp->exec_time, &elapsed, sizeof(qemu_timeval));
+
+    printf("periscope: stat=[");
+    for (int stat = 0; stat < stat_count; stat++) {
+        if (stat > 0)
+            printf(",");
+        if (stat == stat_killed) {
+            printf("%d", timed_out ? 1 : 0);
+            continue;
+        }
+        uint32_t v = periscope_get_stat(stat);
+        printf("%d", v);
+    }
+    char timestr[sizeof "2011-10-08T07:07:09Z"];
+    time_t now;
+    time(&now);
+    strftime(timestr, sizeof(timestr), "%FT%TZ", gmtime(&now));
+    printf("] @ %s\n", timestr);
+
+    // printf("periscope: feedback %p\n", trace_bits);
+
+    if (shm_ptr && trace_bits == NULL) {
+        printf("periscope: no feedback provided!\n");
+        goto signal_afl;
+    }
+
+    if (shm_ptr == NULL) { // dumb mode?
+        goto signal_afl;
+    }
+
+    memcpy(shm_ptr, trace_bits, MAP_SIZE);
+
+signal_afl:
+#if 0
+    if (timed_out) {
+        status = 9; // Give AFL a signal that this input causes timeout.
+        // printf("periscope: timeout\n");
+    }
+#endif
+
+    if ((res = write(st_pipe, &status, 4)) != 4) {
+        printf("periscope: write to status pipe failed\n");
+    }
+
+    if ((res = write(st_pipe, &used_len, 4)) != 4) {
+        printf("periscope: write to status pipe failed\n");
+    }
+}
+#endif
+
+void start_afl_fuzzer(const char *uri, int in_st_pipe, int in_ctl_pipe, int in_shm_id, Error **errp) {
+    printf("periscope: initializing AFL io channels\n");
+
+    if (uri == NULL) {
+        st_pipe = in_st_pipe;
+        ctl_pipe = in_ctl_pipe;
+        shm_id = in_shm_id;
+    }
+    else {
+        char tmp[1024];
+        strncpy(tmp, uri, sizeof(tmp));
+
+        st_pipe = strtol(strtok(tmp, ","), NULL, 0);
+        ctl_pipe = strtol(strtok(NULL, ","), NULL, 0);
+
+        shm_id = -1;
+        char *shm_str = strtok(NULL, ",");
+        if (shm_str) {
+            shm_id = strtol(shm_str, NULL, 0);
+        }
+    }
+
+    if (st_pipe == -1 || ctl_pipe == -1)
+        return;
+
+    shm_ptr = NULL;
+    if (shm_id > -1) {
+        shm_ptr = shmat(shm_id, NULL, 0);
+        if (shm_ptr) {
+            printf("periscope: AFL shm (id=%d, ptr=%p) initialized\n", shm_id, shm_ptr);
+        }
+    }
+
+    afl_out_file = getenv("__PERISCOPE_OUT_FILE");
+    afl_out_dir = getenv("__PERISCOPE_OUT_DIR");
+    strcpy(afl_queue_file, afl_out_dir);
+    char *master_id = getenv("__PERISCOPE_MASTER_ID");
+    if (master_id) {
+        strcat(afl_queue_file, "/");
+        strcat(afl_queue_file, master_id);
+    } else {
+        char *secondary_id = getenv("__PERISCOPE_SECONDARY_ID");
+        if (secondary_id) {
+            strcat(afl_queue_file, "/");
+            strcat(afl_queue_file, secondary_id);
+        }
+    }
+    strcat(afl_queue_file, "/queue_cur");
+    printf("periscope: queue_cur at '%s'\n", afl_queue_file);
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    s->mode = PERISCOPE_MODE_AFL;
+    s->mmio_read = afl_fuzzer_mmio_read;
+    s->fetch_next = afl_fetch_cur_input;
+    s->get_cur = afl_get_cur_input;
+#if AFL_COVERAGE_SUPPORT
+    s->cur_executed = afl_cur_input_executed;
+#endif
+
+#ifdef CONFIG_PERISCOPE
+    s->get_queue_cur_info = libafl_get_queue_cur_info;
+#endif
+
+    printf("periscope: AFL io channels (st=%d, ctl=%d) initialized\n",
+            st_pipe, ctl_pipe);
+}
diff --git migration/periscope-delta-snap-hash.c migration/periscope-delta-snap-hash.c
new file mode 100644
index 0000000000..38592b25b9
--- /dev/null
+++ migration/periscope-delta-snap-hash.c
@@ -0,0 +1,1196 @@
+#include "periscope-delta-snap.h"
+#include "hw/boards.h"
+#include "qemu/osdep.h"
+#include "qemu/atomic.h"
+#include "cpu.h"
+#include "migration/periscope.h"
+#include "migration/ram.h"
+#include "exec/ram_addr.h"
+
+#ifdef PERI_DEDUP
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <string.h>
+#include <unistd.h>
+#include <semaphore.h>
+#include <sys/mman.h>
+#ifndef PERI_DEDUP_NOHASH
+//#include "migration/c_hashmap/hashmap_custom.h"
+//#include "migration/meow_hash_x64_aesni.h"
+#endif
+#endif
+
+
+#define TRACE_TIME
+#undef TRACE_TIME
+#define TRACE_DEBUG
+#undef TRACE_DEBUG
+#define TRACE_DEBUG_STATS
+#undef TRACE_DEBUG_STATS
+#define TRACE_PAGES_STORED
+#undef TRACE_PAGES_STORED
+#define TEST_HASHING_OVERHEAD
+#undef TEST_HASHING_OVERHEAD
+
+#define CHUNK_SIZE (TARGET_PAGE_SIZE / CHUNK_DIV)
+/* Should be holding either ram_list.mutex, or the RCU lock. */
+#define  INTERNAL_RAMBLOCK_FOREACH(block)  \
+    QLIST_FOREACH_RCU(block, &ram_list.blocks, next)
+/* Never use the INTERNAL_ version except for defining other macros */
+#define RAMBLOCK_FOREACH(block) INTERNAL_RAMBLOCK_FOREACH(block)
+
+/* Should be holding either ram_list.mutex, or the RCU lock. */
+#define RAMBLOCK_FOREACH_NOT_IGNORED(block)            \
+    INTERNAL_RAMBLOCK_FOREACH(block)                   \
+        if (ramblock_is_ignored(block)) {} else
+
+#define RAMBLOCK_FOREACH_MIGRATABLE(block)             \
+    INTERNAL_RAMBLOCK_FOREACH(block)                   \
+        if (!qemu_ram_is_migratable(block)) {} else
+
+
+// this flag enables selective storing of dirty pages in ram_save ...
+#ifdef ENABLE_LW_CHKPT
+bool periscope_delta_snapshot = true;
+#else
+bool periscope_delta_snapshot = false;
+#endif
+bool periscope_save_ram_only = false;
+
+
+struct DirtyBitmapSnapshot {
+    ram_addr_t start;
+    ram_addr_t end;
+    unsigned long dirty[];
+};
+
+#ifdef PERI_DEDUP
+extern bool buffer_is_zero(const void *buf, size_t len);
+static bool is_zero_range(uint8_t *p, uint64_t size)
+{
+    return buffer_is_zero(p, size);
+}
+
+#ifndef PERI_DEDUP_NOHASH
+#define INVALID_KEY _mm_set_epi64x(0xdeadbeefdeadbeef, 0xdeadbeefdeadbeef);
+#ifdef FINE_CHUNKS
+typedef struct ram_cache_meta {
+   char idstr[256];
+   meow_u128* cache_meta_key;
+   int* cache_meta_id;
+} ram_cache_meta;
+static ram_cache_meta *ram_cache = NULL;
+static unsigned int n_cache;
+
+
+static ram_cache_meta* get_cache_meta(char* idstr) {
+   for(unsigned int i=0; i<n_cache; ++i) {
+      if(strcmp(ram_cache[i].idstr, idstr) == 0) {
+         return &ram_cache[i];
+      }
+   }
+   return NULL;
+}
+#endif /* FINE_CHUNKS */
+
+#define MAX_NEW_UPDATE 0.1f
+//#define MAX_NEW_PERC 0.1f
+static long max_new_min = 2000 * CHUNK_DIV;
+static long max_new_pages = 0;
+static int fuzzer_id = 0;
+static unsigned long page_pool_entries = 262144; // 1gb //fuzzer->chkpt_pool_size/getpagesize();
+static map_t ram_page_pool_hashmap = NULL;
+
+typedef struct ram_page_pool_info {
+   unsigned int n_pages;
+   unsigned int n_pages_free;
+} ram_page_pool_info;
+static ram_page_pool_info *rpp_info = NULL;
+static void *ram_page_pool = NULL;
+static unsigned int *ram_refc_pool = NULL;
+static meow_u128 *ram_key_pool = NULL;
+static unsigned long *ram_page_pool_free_bm = NULL;
+
+uint64_t get_ram_page_pool_size(void) {
+   return rpp_info->n_pages * CHUNK_SIZE;
+}
+
+uint64_t get_rpp_hashmap_size(void) {
+   return hashmap_fixed_size(ram_page_pool_hashmap);
+}
+
+static void init_ram_page_pool(void *rpp_info_ptr, void *rpp_free_bm_ptr,
+      void *ram_shared_ram_page_pool_ptr, unsigned long size, bool init) {
+   if(rpp_info_ptr) {
+      printf("Sharing ram_page_pool_info\n");
+      rpp_info = (ram_page_pool_info*)rpp_info_ptr;
+   } else {
+      printf("Allocating ram_page_pool_info\n");
+      rpp_info = (ram_page_pool_info*)g_malloc(sizeof(ram_page_pool_info));
+   }
+   printf("page pool map %p\n", rpp_info);
+   page_pool_entries = size/CHUNK_SIZE;
+   unsigned long bitmap_sz = BITS_TO_LONGS(page_pool_entries) * sizeof(unsigned long);
+   if(init) {
+      rpp_info->n_pages = page_pool_entries;
+      rpp_info->n_pages_free = page_pool_entries;
+   }
+   if(ram_shared_ram_page_pool_ptr) {
+      printf("Sharing ram_page_pool\n");
+      ram_page_pool = ram_shared_ram_page_pool_ptr;
+   } else {
+      printf("Allocating ram_page_pool %ld\n", size);
+      ram_page_pool = g_malloc(size);
+      //madvise(ram_page_pool, size, MADV_HUGEPAGE | MADV_WILLNEED | MADV_SEQUENTIAL);
+      ram_refc_pool = g_malloc(page_pool_entries * sizeof(unsigned int));
+      memset(ram_refc_pool, 0, page_pool_entries * sizeof(unsigned int));
+      ram_key_pool = g_malloc(page_pool_entries * sizeof(meow_u128));
+      for(int i=0; i<page_pool_entries; ++i) {
+         ram_key_pool[i] = INVALID_KEY; //_mm_setzero_si128();
+      }
+   }
+   printf("Page pool %p/%p, size %ld, entries %ld\n", ram_page_pool, ram_shared_ram_page_pool_ptr, size, page_pool_entries);
+   //ram_page_pool_free_bm = bitmap_new(page_pool_entries);
+   if(rpp_free_bm_ptr) {
+      printf("Sharing ram_page_pool_free_bm\n");
+      ram_page_pool_free_bm = rpp_free_bm_ptr;
+   } else {
+      printf("Allocating ram_page_pool_free_bm\n");
+      unsigned long long bitmap_sz = BITS_TO_LONGS(rpp_info->n_pages) * sizeof(unsigned long);
+      ram_page_pool_free_bm = g_malloc(bitmap_sz); //bitmap_new(page_pool_entries);
+   }
+   printf("Bitmap page pool %p, size %lx\n", ram_page_pool_free_bm, bitmap_sz);
+   if(init) {
+      bitmap_zero(ram_page_pool_free_bm, page_pool_entries);
+   }
+}
+
+static int next_free = 0;
+static void delete_rpp_index(int idx) {
+   //assert(idx >= 0 && idx < rpp_info->n_pages);
+   if(!test_bit(idx, ram_page_pool_free_bm)) {
+     printf("periscope: Error bit %d not set\n", idx);
+     //assert(false);
+   }
+   clear_bit(idx, ram_page_pool_free_bm);
+   rpp_info->n_pages_free++;
+   next_free = 0;
+}
+
+
+static int set_free_rpp_index(meow_u128 key, void* host) {
+   if(rpp_info->n_pages_free == 0) return -1;
+   unsigned int idx = find_next_zero_bit(ram_page_pool_free_bm, rpp_info->n_pages, next_free);
+   if(idx >= rpp_info->n_pages) {
+      printf("%d, %d, %d, %d\n", rpp_info->n_pages, rpp_info->n_pages_free, idx, next_free);
+      assert(false);
+   }
+   //assert(ram_refc_pool[idx] == 0);
+
+   ram_refc_pool[idx] = 1;
+   ram_key_pool[idx] = key;
+   memcpy(ram_page_pool + (idx * CHUNK_SIZE), host, CHUNK_SIZE);
+
+   //assert(idx < rpp_info->n_pages);
+   //assert(!test_bit(idx, ram_page_pool_free_bm));
+   next_free = idx + 1;
+   if(next_free >= rpp_info->n_pages) {
+      next_free = 0;
+   }
+   set_bit(idx, ram_page_pool_free_bm);
+   rpp_info->n_pages_free--;
+   return idx;
+}
+
+uint64_t get_free_pages(void) {
+   return rpp_info->n_pages_free;
+}
+
+int grow_ram_page_pool(unsigned long max_new)
+{
+   next_free = rpp_info->n_pages;
+   printf("%s by %ld\n", __FUNCTION__, max_new);
+   unsigned int new_entries = max_new / CHUNK_SIZE;
+   printf("%s new entries %d\n", __FUNCTION__, new_entries);
+   unsigned long oldsize = rpp_info->n_pages * CHUNK_SIZE;
+   unsigned long newsize = (new_entries + rpp_info->n_pages) * CHUNK_SIZE;
+   //unsigned long oldsize_meta = rpp_info->n_pages * sizeof(page_meta);
+   //unsigned long newsize_meta = (new_entries + rpp_info->n_pages) * sizeof(page_meta);
+   unsigned long oldsize_refc = (rpp_info->n_pages) * sizeof(unsigned int);
+   unsigned long newsize_refc = (new_entries + rpp_info->n_pages) * sizeof(unsigned int);
+   //unsigned long oldsize_key = (rpp_info->n_pages) * sizeof(meow_u128);
+   unsigned long newsize_key = (new_entries + rpp_info->n_pages) * sizeof(meow_u128);
+   unsigned long bitmap_sz_old = BITS_TO_LONGS(rpp_info->n_pages) * sizeof(unsigned long);
+   unsigned long bitmap_sz_new = BITS_TO_LONGS(rpp_info->n_pages + new_entries) * sizeof(unsigned long);
+   printf("%s oldsize %ld, newsize %ld\n", __FUNCTION__, oldsize, newsize);
+   printf("%s bitmap old_sz %ld, new_sz %ld\n", __FUNCTION__, bitmap_sz_old, bitmap_sz_new);
+   ram_page_pool_free_bm = g_realloc(ram_page_pool_free_bm, bitmap_sz_new);
+   assert(ram_page_pool_free_bm);
+   memset((void*)ram_page_pool_free_bm + bitmap_sz_old, 0, bitmap_sz_new - bitmap_sz_old);
+   ram_page_pool = g_realloc(ram_page_pool, newsize);
+   assert(ram_page_pool);
+   //madvise(ram_page_pool, newsize, MADV_HUGEPAGE | MADV_WILLNEED | MADV_SEQUENTIAL);
+   ram_refc_pool = g_realloc(ram_refc_pool, newsize_refc);
+   assert(ram_refc_pool);
+   memset((void*)ram_refc_pool + oldsize_refc, 0, newsize_refc - oldsize_refc);
+   ram_key_pool = g_realloc(ram_key_pool, newsize_key);
+   assert(ram_key_pool);
+   for(int i=rpp_info->n_pages; i<rpp_info->n_pages + new_entries; ++i) {
+      ram_key_pool[i] = INVALID_KEY; //_mm_setzero_si128();
+   }
+   rpp_info->n_pages += new_entries;
+   printf("%s old free %d\n", __FUNCTION__, rpp_info->n_pages_free);
+   rpp_info->n_pages_free += new_entries;
+   printf("%s new free %d\n", __FUNCTION__, rpp_info->n_pages_free);
+   return 0;
+}
+
+
+static void get_page_meta_idx(int idx) {
+   //assert(idx >= 0 && idx < rpp_info->n_pages);
+   //assert(ram_refc_pool[idx] > 0);
+   ram_refc_pool[idx]++;
+}
+
+static void put_page_meta_idx(int idx) {
+   //assert(idx >= 0 && idx < rpp_info->n_pages);
+   //assert(ram_refc_pool[idx] > 0);
+   ram_refc_pool[idx]--;
+   if(ram_refc_pool[idx] == 0) {
+      delete_rpp_index(idx);
+      hashmap_remove(ram_page_pool_hashmap, &ram_key_pool[idx]);
+      //int remove_status = hashmap_remove(ram_page_pool_hashmap, &ram_key_pool[idx]);
+      //assert(remove_status == MAP_OK);
+      //assert(hashmap_remove(ram_page_pool_hashmap, &ram_key_pool[idx]) == MAP_MISSING);
+      ram_key_pool[idx] = INVALID_KEY;
+   }
+}
+#endif /* PERI_DEDUP_NOHASH */
+
+unsigned long count_stored_pages_prbs(periscope_ramblock *prbs, unsigned int nprb) {
+   unsigned long count = 0;
+   for(unsigned int i=0; i<nprb; ++i) {
+      count += (prbs[i].npages_stored/CHUNK_DIV);
+   }
+   return count;
+}
+
+unsigned long count_hashed_pages_prbs(periscope_ramblock *prbs, unsigned int nprb) {
+   unsigned long count = 0;
+   for(unsigned int i=0; i<nprb; ++i) {
+      count += (prbs[i].npages_hashes_added/CHUNK_DIV);
+   }
+   return count;
+}
+
+unsigned long count_zero_pages_prbs(periscope_ramblock *prbs, unsigned int nprb) {
+   unsigned long count = 0;
+   for(unsigned int i=0; i<nprb; ++i) {
+      count += (prbs[i].npages_zero/CHUNK_DIV);
+   }
+   return count;
+}
+
+unsigned long count_skipped_pages_prbs(periscope_ramblock *prbs, unsigned int nprb) {
+   unsigned long count = 0;
+   for(unsigned int i=0; i<nprb; ++i) {
+      count += (prbs[i].npages_skipped/CHUNK_DIV);
+   }
+   return count;
+}
+
+unsigned long count_dirty_pages(void) {
+   unsigned long numdirtypages = 0;
+   RAMBlock *rb;
+   RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+      struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_get_dirty(
+            rb->mr,
+            0, rb->max_length,
+            DIRTY_MEMORY_DELTA
+            );
+      unsigned long npages_snap = (snap->end - snap->start) >> TARGET_PAGE_BITS;
+      numdirtypages += bitmap_count_one(snap->dirty, npages_snap);
+      g_free(snap);
+   }
+   return numdirtypages;
+}
+
+#ifndef PERI_DEDUP_NOHASH
+float compute_uniqueness(periscope_ramblock *prbs, unsigned int nprb) {
+   float cost = 0;
+   for(int i=0; i<nprb; i++) {
+      periscope_ramblock *prb = &prbs[i];
+      if(prb->empty || prb->npages_stored == 0) {
+         cost += prb->npages;
+         continue;
+      }
+      float cost_prb = 0;
+      for(unsigned int j=0; j<prb->npages_stored; ++j) {
+         unsigned long page_chunk = prb->offsets[j];
+         if(test_bit(page_chunk, prb->zero_pages)) continue;
+         unsigned int meta_idx = prb->ram_idx[j];
+         cost_prb += ram_refc_pool[meta_idx];
+      }
+      cost += cost_prb / prb->npages_stored;
+   }
+   return cost;
+}
+
+unsigned long compute_prb_freed(periscope_ramblock *prb) {
+   unsigned long cost = 0;
+   for(unsigned int i=0; i<prb->npages_stored; ++i) {
+      unsigned int meta_idx = prb->ram_idx[i];
+      if(ram_refc_pool[meta_idx] == 1)
+         cost++;
+
+   }
+   return cost;
+}
+#endif
+
+uint64_t compute_dirty_cost(unsigned long num_dirty_pages) {
+#ifndef PERI_DEDUP_NOHASH
+    uint64_t dirty_cost = num_dirty_pages *
+       (sizeof(unsigned int) +
+        sizeof(meow_u128) +
+        hashmap_element_size());
+   return dirty_cost;
+#else
+   return num_dirty_pages * (TARGET_PAGE_SIZE + sizeof(unsigned int));
+#endif
+}
+
+
+#ifndef PERI_DEDUP_NOHASH
+unsigned long get_max_new_pages(void) {
+   return max_new_pages;
+}
+unsigned long compute_hash_cost(periscope_ramblock *prbs, unsigned int nprb) {
+   unsigned long cost = 0;
+   for(unsigned int i=0; i<nprb; ++i) {
+      cost += (prbs[i].npages_hashes_added * CHUNK_SIZE);
+   }
+   return cost;
+}
+#endif
+
+unsigned long compute_prb_cost(periscope_ramblock *prbs, unsigned int nprb) {
+   unsigned long cost = 0;
+   unsigned long list_cost = 0;
+   unsigned long bitmap_cost = 0;
+   unsigned long fixed_cost = 0;
+   unsigned long hash_cost = 0;
+   for(unsigned int i=0; i<nprb; ++i) {
+      // struct cost
+      fixed_cost += sizeof(periscope_ramblock);
+      if(prbs[i].empty) continue;
+      // offsets
+      list_cost += prbs[i].npages_stored * sizeof(unsigned int);
+#ifdef PERI_DEDUP_NOHASH
+      // ram
+      list_cost += prbs[i].npages_stored * TARGET_PAGE_SIZE;
+#else
+      // hash cost
+      hash_cost += prbs[i].npages_stored * hashmap_element_size();
+      // ram_idx
+      list_cost += prbs[i].npages_stored * sizeof(unsigned int);
+#endif
+      // dirty
+      bitmap_cost += (BITS_TO_LONGS(prbs[i].npages) * sizeof(unsigned long));
+      // zero_pages
+      bitmap_cost += (BITS_TO_LONGS(prbs[i].npages * CHUNK_DIV) * sizeof(unsigned long));
+//#ifdef FINE_CHUNKS
+      //  dirty_fine
+      bitmap_cost += (BITS_TO_LONGS(prbs[i].npages * CHUNK_DIV) * sizeof(unsigned long));
+//#endif
+   }
+   cost = list_cost + bitmap_cost + fixed_cost + hash_cost;
+   //printf("%s: %ld + %ld + %ld + %ld= %ld\n", __FUNCTION__,
+   //      hash_cost, list_cost, bitmap_cost, hash_cost, cost);
+   return cost;
+}
+
+static inline unsigned long get_page_index(unsigned long start_index,
+      unsigned long npages_stored,
+      unsigned int *offsets,
+      unsigned int target
+      ) {
+   unsigned long page_index = 0;
+   for(unsigned long restore_page = start_index;
+         restore_page < npages_stored; ++restore_page) {
+      if(offsets[restore_page] == target)
+      {
+         page_index = restore_page;
+         break;
+      }
+   }
+   return page_index;
+}
+
+static int store_ram_pages(RAMBlock *rb, periscope_ramblock *prb) {
+    //rcu_read_lock();
+    //assert(rb);
+
+#ifdef FINE_CHUNKS
+    ram_cache_meta *rcm = get_cache_meta(rb->idstr);
+    //assert(rcm);
+#endif
+
+    if(prb->empty) {
+#ifdef TRACE_DEBUG
+       printf("%s no dirty -> skip\n", rb->idstr);
+#endif
+       return 0;
+    }
+    unsigned long npages = prb->npages;
+    //unsigned long npages_dirty = prb->npages_dirty * CHUNK_DIV;
+
+#ifdef TRACE_DEBUG
+    printf("%s: %s pages %ld\n", __FUNCTION__, rb->idstr, npages);
+#endif
+
+    unsigned long page = find_first_bit(prb->dirty, npages);
+    while(page < npages) {
+       unsigned long offset_base = page << TARGET_PAGE_BITS;
+       for(int chunk=0; chunk<CHUNK_DIV; ++chunk) {
+          unsigned long offset = offset_base + (CHUNK_SIZE * chunk);
+          void *host = host_from_ram_block_offset(rb, offset);
+          unsigned long page_chunk = (offset) >> (TARGET_PAGE_BITS - CHUNK_SHIFT);
+          //assert(host);
+          //assert(prb->npages_stored < npages_dirty);
+          if(is_zero_range(host, CHUNK_SIZE)) {
+#ifdef FINE_CHUNKS
+             if(!MeowHashesAreEqual(rcm->cache_meta_key[page_chunk], _mm_setzero_si128())) {
+                set_bit(page_chunk, prb->dirty_fine);
+                rcm->cache_meta_key[page_chunk] = _mm_setzero_si128();
+                rcm->cache_meta_id[page_chunk] = prb->id;
+                // XXX
+                //prb->offsets_zero[prb->npages_zero] = page_chunk;
+                set_bit(page_chunk, prb->zero_pages);
+                prb->npages_zero++;
+             } else {
+                prb->npages_skipped++;
+             }
+#else
+             set_bit(page_chunk, prb->zero_pages);
+             prb->npages_zero++;
+#endif
+             continue;
+          }
+#ifndef PERI_DEDUP_NOHASH
+          meow_u128 key = MeowHash(MeowDefaultSeed, CHUNK_SIZE, host);
+#ifdef FINE_CHUNKS
+          if(MeowHashesAreEqual(rcm->cache_meta_key[page_chunk], key)) {
+              prb->npages_skipped++;
+              continue;
+          }
+#endif /* FINE_CHUNKS */
+
+          unsigned int idx_get, *idx_put;
+          int status = hashmap_get_and_put_static(
+                ram_page_pool_hashmap,
+                &key, &idx_get, &idx_put);
+          if(status == MAP_MISSING) {
+             int rm_idx = set_free_rpp_index(key, host);
+             if(rm_idx >= 0) {
+                *idx_put = rm_idx;
+                prb->npages_hashes_added++;
+                prb->ram_idx[prb->npages_stored] = rm_idx;
+             } else {
+                hashmap_remove(ram_page_pool_hashmap, &key);
+                //int remove_status = hashmap_remove(ram_page_pool_hashmap, &key);
+                //assert(remove_status == MAP_OK);
+                //assert(hashmap_remove(ram_page_pool_hashmap, &key) == MAP_MISSING);
+                printf("periscope: page pool full\n");
+                return -1;
+             }
+          } else {
+             //assert(idx_get < rpp_info->n_pages);
+             //assert(ram_refc_pool[idx_get] > 0);
+             get_page_meta_idx(idx_get);
+             prb->ram_idx[prb->npages_stored] = idx_get;
+          }
+#ifdef FINE_CHUNKS
+          set_bit(page_chunk, prb->dirty_fine);
+          rcm->cache_meta_key[page_chunk] = key;
+          rcm->cache_meta_id[page_chunk] = prb->id;
+#endif /* FINE_CHUNKS */
+#else /*PERI_DEDUP_NOHASH*/
+          memcpy(prb->ram + prb->npages_stored * TARGET_PAGE_SIZE, host, TARGET_PAGE_SIZE);
+#endif
+          prb->offsets[prb->npages_stored] = page_chunk;
+          prb->npages_stored++;
+       }
+       page = find_next_bit(prb->dirty, npages, page+1);
+    }
+#ifdef TRACE_DEBUG_STATS
+   printf("periscope: %s stored %ld,%ld,%ld,%ld stored/skipped/zero/hashes\n",
+         prb->idstr, prb->npages_stored, prb->npages_skipped, prb->npages_zero, prb->npages_hashes_added);
+#endif
+   //assert(prb->npages_skipped + prb->npages_stored + prb->npages_zero == npages_dirty);
+   //rcu_read_unlock();
+#ifndef PERI_DEDUP_NOHASH
+   if(max_new_pages > 0 && prb->npages_hashes_added * 2 > max_new_min) {
+      long new_val = max_new_pages + ((long)(prb->npages_hashes_added * 2) - max_new_pages) * MAX_NEW_UPDATE;
+      printf("Updating max new pages with %ld: %ld -> %ld\n", prb->npages_hashes_added * 2, max_new_pages, new_val);
+      max_new_pages = new_val;
+   }
+#endif
+   return 0;
+}
+void restore_ram_pages(RAMBlock *rb, periscope_ramblock *prb, unsigned long* dirty) {
+    //rcu_read_lock();
+#ifdef FINE_CHUNKS
+    ram_cache_meta *rcm = get_cache_meta(rb->idstr);
+#endif
+
+   unsigned long npages = prb->npages * CHUNK_DIV;
+#ifdef TRACE_DEBUG_STATS
+    //printf("%s: %s %p %ld\n", __FUNCTION__, rb->idstr, dirty, npages);
+    printf("periscope: %s restoring %ld,%ld,%ld,%ld,%ld stored/skipped/zero/hashes/dirty\n",
+         prb->idstr, prb->npages_stored, prb->npages_skipped, prb->npages_zero,
+         prb->npages_hashes_added, bitmap_count_one(dirty, npages));
+#endif
+    //assert(prb->npages_stored + prb->npages_zero >= bitmap_count_one(dirty, npages));
+
+//   for(unsigned int page_index = 0; page_index < prb->npages_stored; ++page_index) {
+//      unsigned int page_chunk = prb->offsets[page_index];
+//      if(!test_bit(page_chunk, dirty)) continue;
+//      unsigned long offset = page_chunk << (TARGET_PAGE_BITS-CHUNK_SHIFT);
+//      void *host = host_from_ram_block_offset(rb, offset);
+//      unsigned int meta_idx = prb->ram_idx[page_index];
+//      //assert(ram_refc_pool[meta_idx] > 0);
+//#ifdef FINE_CHUNKS
+//      rcm->cache_meta_key[page_chunk] = ram_key_pool[meta_idx];
+//      rcm->cache_meta_id[page_chunk] = prb->id;
+//#endif
+//       memcpy(host,
+//             ram_page_pool + (meta_idx * CHUNK_SIZE),
+//             CHUNK_SIZE);
+//
+//   }
+//
+//   for(unsigned int page_index = 0; page_index < prb->npages_zero; ++page_index) {
+//      unsigned int page_chunk = prb->offsets_zero[page_index];
+//      if(!test_bit(page_chunk, dirty)) continue;
+//      unsigned long offset = page_chunk << (TARGET_PAGE_BITS-CHUNK_SHIFT);
+//      void *host = host_from_ram_block_offset(rb, offset);
+//#ifdef FINE_CHUNKS
+//      rcm->cache_meta_key[page_chunk] = _mm_setzero_si128();
+//      rcm->cache_meta_id[page_chunk] = prb->id;
+//#endif
+//      memset(host, 0, CHUNK_SIZE);
+//   }
+
+    unsigned long page_index = 0;
+    unsigned long page = find_first_bit(dirty, npages);
+    while(page < npages) {
+       unsigned long offset = page << (TARGET_PAGE_BITS-CHUNK_SHIFT);
+       unsigned int page_chunk = page;
+       void *host = host_from_ram_block_offset(rb, offset);
+       if(test_bit(page_chunk, prb->zero_pages)) {
+#ifdef FINE_CHUNKS
+          rcm->cache_meta_key[page_chunk] = _mm_setzero_si128();
+          rcm->cache_meta_id[page_chunk] = prb->id;
+#endif
+          memset(host, 0, CHUNK_SIZE);
+          page = find_next_bit(dirty, npages, page + 1);
+          continue;
+       }
+
+       unsigned int target = page_chunk;
+       //assert(page_index < prb->npages_stored);
+       page_index = get_page_index(
+             page_index,
+             prb->npages_stored,
+             prb->offsets,
+             target);
+#ifdef PERI_DEDUP_NOHASH
+       memcpy(host,
+             prb->ram + page_index * TARGET_PAGE_SIZE,
+             TARGET_PAGE_SIZE);
+#else /* PERI_DEDUP_NOHASH */
+       unsigned int meta_idx = prb->ram_idx[page_index];
+       //assert(ram_refc_pool[meta_idx] > 0);
+#ifdef FINE_CHUNKS
+       rcm->cache_meta_key[page_chunk] = ram_key_pool[meta_idx];
+       rcm->cache_meta_id[page_chunk] = prb->id;
+#endif /*FINE_CHUNKS*/
+       memcpy(host,
+             ram_page_pool + (meta_idx * CHUNK_SIZE),
+             CHUNK_SIZE);
+#endif /* PERI_DEDUP_NOHASH */
+       page = find_next_bit(dirty, npages, page + 1);
+       page_index++;
+    }
+    //rcu_read_unlock();
+}
+
+periscope_ramblock *get_ramblock(periscope_ramblock *prbs, unsigned int nprb, const char *name) {
+   for(unsigned int i=0; i<nprb; ++i) {
+      if(strcmp(name, prbs[i].idstr) == 0)
+         return &prbs[i];
+   }
+   return NULL;
+}
+
+#ifdef PERI_DEDUP_NOHASH
+static void delete_stored_pages(periscope_ramblock *prb, periscope_ramblock *prb_parent) {
+   return;
+}
+#else
+static void delete_stored_pages(periscope_ramblock *prb, periscope_ramblock *prb_parent) {
+#ifdef FINE_CHUNKS
+   ram_cache_meta *rcm = get_cache_meta(prb->idstr);
+#endif
+
+   unsigned int page_index = 0;
+   unsigned int npages_fine = prb->npages * CHUNK_DIV;
+#ifdef FINE_CHUNKS
+   unsigned int page = find_first_bit(prb->dirty_fine, npages_fine);
+#else
+   unsigned int page = find_first_bit(prb->dirty, npages_fine);
+#endif
+   unsigned int n_cache_reset = 0;
+   while(page < npages_fine) {
+      //unsigned int offset_base = page << (TARGET_PAGE_BITS-CHUNK_SHIFT);
+      //unsigned long offset = offset_base;
+      unsigned long page_chunk = page;
+      if(test_bit(page_chunk, prb->zero_pages)) {
+#ifdef FINE_CHUNKS
+         if(rcm->cache_meta_id[page_chunk] == prb->id) {
+            //assert(MeowHashesAreEqual(rcm->cache_meta_key[page_chunk], _mm_setzero_si128()));
+            rcm->cache_meta_key[page_chunk] = INVALID_KEY;
+            rcm->cache_meta_id[page_chunk] =  0;
+            n_cache_reset++;
+         }
+#endif
+#ifdef FINE_CHUNKS
+         page = find_next_bit(prb->dirty_fine, npages_fine, page + 1);
+#else
+         page = find_next_bit(prb->dirty, npages_fine, page + 1);
+#endif
+         continue;
+      }
+
+      unsigned int target = page_chunk;
+      //assert(page_index < prb->npages_stored);
+      page_index = get_page_index(
+            page_index,
+            prb->npages_stored,
+            prb->offsets,
+            target);
+
+      unsigned int meta_idx = prb->ram_idx[page_index];
+#ifdef FINE_CHUNKS
+      if(rcm->cache_meta_id[page_chunk] == prb->id) {
+         //assert(MeowHashesAreEqual(rcm->cache_meta_key[page_chunk], ram_key_pool[meta_idx]));
+         rcm->cache_meta_key[page_chunk] =  INVALID_KEY;
+         rcm->cache_meta_id[page_chunk] =  0;
+         n_cache_reset++;
+      }
+#endif
+      put_page_meta_idx(meta_idx);
+#ifdef FINE_CHUNKS
+      page = find_next_bit(prb->dirty_fine, npages_fine, page + 1);
+#else
+      page = find_next_bit(prb->dirty, npages_fine, page + 1);
+#endif
+      page_index++;
+   }
+#ifdef TRACE_DEBUG
+   printf("%s: reset %d cache entries\n", prb->idstr, n_cache_reset);
+#endif
+}
+#endif
+
+static void delete_ramblock(periscope_ramblock *prb, periscope_ramblock *prb_parent) {
+#ifdef TRACE_DEBUG
+   printf("Delete rb %s\n", prb->idstr);
+#endif
+   if(prb->empty) return;
+   delete_stored_pages(prb, prb_parent);
+   if(prb->dirty) {
+      g_free(prb->dirty);
+      prb->dirty = NULL;
+   }
+#ifdef FINE_CHUNKS
+   if(prb->dirty_fine) {
+      g_free(prb->dirty_fine);
+      prb->dirty_fine = NULL;
+   }
+#endif
+#ifdef DBG_RAM_STORED
+   if(prb->rambkp) {
+      g_free(prb->rambkp);
+      prb->rambkp = NULL;
+   }
+   prb->rambkp_size = 0;
+#endif
+   prb->npages_stored = 0;
+   if(prb->offsets){
+      g_free(prb->offsets);
+      prb->offsets = NULL;
+   }
+#ifdef PERI_DEDUP_NOHASH
+   if(prb->ram) {
+      g_free(prb->ram);
+      prb->ram = NULL;
+   }
+#else
+   if(prb->ram_idx) {
+      g_free(prb->ram_idx);
+      prb->ram_idx = NULL;
+   }
+#endif
+   if(prb->zero_pages){
+      g_free(prb->zero_pages);
+      prb->zero_pages = NULL;
+   }
+}
+
+void delete_peri_rbs(periscope_ramblock *prbs, unsigned int nprb,
+      periscope_ramblock *prbs_parent) {
+   if(prbs == NULL) return;
+   for(unsigned int i=0; i<nprb; ++i) {
+      delete_ramblock(&prbs[i], &prbs_parent[i]);
+   }
+   //g_free(prb);
+}
+
+// must hold rcu and ramlist lock
+static unsigned int count_ramblocks(void) {
+   RAMBlock *rb;
+   unsigned int nrb = 0;
+   RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+      nrb++;
+   }
+   return nrb;
+}
+
+static void zero_static_counters(periscope_ramblock *prb) {
+   prb->npages = 0;
+   prb->npages_dirty = 0;
+}
+static void zero_dynamic_counters(periscope_ramblock *prb) {
+   prb->npages_stored = 0;
+   prb->npages_skipped = 0;
+   prb->npages_hashes_added = 0;
+   prb->npages_zero = 0;
+}
+
+static void create_ramblock(char *name, periscope_ramblock *prb) {
+   prb->dirty_done = false;
+   prb->store_done = false;
+   prb->dirty = NULL;
+#ifdef FINE_CHUNKS
+   prb->dirty_fine = NULL;
+#endif
+   zero_static_counters(prb);
+   zero_dynamic_counters(prb);
+   prb->offsets = NULL;
+   //prb->offsets_zero = NULL;
+   prb->zero_pages = NULL;
+#ifdef PERI_DEDUP_NOHASH
+   prb->ram = NULL;
+#else
+   prb->ram_idx = NULL;
+#endif
+   prb->empty = true;
+   strcpy(prb->idstr, name);
+#ifdef DBG_RAM_STORED
+   prb->rambkp = NULL;
+   prb->rambkp_size = 0;
+#endif
+}
+
+static bool maybe_reset_ramblock(periscope_ramblock *prb)
+{
+   if(prb->store_done) return true;
+   if(!prb->dirty_done) return false;
+   printf("Restart %s\n", prb->idstr);
+#ifndef PERI_DEDUP_NOHASH
+   delete_stored_pages(prb, NULL);
+#endif
+   bitmap_zero(prb->zero_pages, prb->npages * CHUNK_DIV);
+#ifdef FINE_CHUNKS
+   bitmap_zero(prb->dirty_fine, prb->npages * CHUNK_DIV);
+#endif
+   zero_dynamic_counters(prb);
+   prb->empty = false;
+   return false;
+}
+
+static void maybe_realloc_ramblock(periscope_ramblock *prb)
+{
+   if(prb->npages_stored == 0) {
+      if(prb->offsets) {
+         g_free(prb->offsets);
+         prb->offsets = NULL;
+      }
+#ifdef PERI_DEDUP_NOHASH
+      if(prb->ram) {
+         g_free(prb->ram);
+         prb->ram = NULL;
+      }
+#else
+      if(prb->ram_idx) {
+         g_free(prb->ram_idx);
+         prb->ram_idx = NULL;
+      }
+#endif
+   } else if (prb->npages_stored != prb->npages_dirty * CHUNK_DIV ) {
+      // TODO maybe determine zero pages befor, might be faster?
+      if(prb->offsets) prb->offsets = g_realloc(prb->offsets, prb->npages_stored * sizeof(unsigned int));
+#ifdef PERI_DEDUP_NOHASH
+      if(prb->ram) prb->ram = g_realloc(prb->ram, prb->npages_stored * TARGET_PAGE_SIZE);
+#else
+      if(prb->ram_idx) prb->ram_idx = g_realloc(prb->ram_idx, prb->npages_stored * sizeof(unsigned int));
+#endif
+   }
+#if 0
+   if(prb->npages_zero == 0) {
+      if(prb->offsets_zero) {
+         g_free(prb->offsets_zero);
+         prb->offsets_zero = NULL;
+      }
+   } else if (prb->npages_zero != prb->npages_dirty * CHUNK_DIV ) {
+      if(prb->offsets_zero) prb->offsets_zero = g_realloc(prb->offsets_zero, prb->npages_zero * sizeof(unsigned int));
+   }
+#endif
+   if(prb->npages_zero == 0 && prb->npages_stored == 0) {
+      prb->empty = true;
+      if(prb->dirty) g_free(prb->dirty);
+#ifdef FINE_CHUNKS
+      if(prb->dirty_fine) g_free(prb->dirty_fine);
+#endif
+      if(prb->zero_pages) g_free(prb->zero_pages);
+   }
+}
+
+static bool init_ramblock(periscope_ramblock *prb,
+      unsigned long *dirty,
+      unsigned long npages_create,
+      unsigned long npages_dirty, bool fill) {
+   if(npages_dirty == 0) return true;
+   prb->dirty = bitmap_new(npages_create);
+   if(fill) bitmap_fill(prb->dirty, npages_dirty);
+   else     bitmap_copy(prb->dirty, dirty, npages_create);
+#ifdef FINE_CHUNKS
+   prb->dirty_fine = bitmap_new(npages_create * CHUNK_DIV);
+   if(fill) bitmap_fill(prb->dirty_fine, npages_dirty * CHUNK_DIV);
+   else bitmap_zero(prb->dirty_fine, npages_create * CHUNK_DIV);
+#endif
+   prb->npages = npages_create;
+   prb->npages_dirty = npages_dirty;
+   prb->zero_pages = bitmap_new(npages_create * CHUNK_DIV);
+   bitmap_zero(prb->zero_pages, npages_create * CHUNK_DIV);
+   prb->offsets = g_malloc(npages_dirty * CHUNK_DIV * sizeof(unsigned int));
+#ifdef PERI_DEDUP_NOHASH
+   prb->ram = g_malloc(npages_dirty * TARGET_PAGE_SIZE);
+#else
+   prb->ram_idx = g_malloc(npages_dirty * CHUNK_DIV  * sizeof(unsigned int));
+#endif
+   // XXX
+   //prb->offsets_zero = g_malloc(npages_dirty * CHUNK_DIV * sizeof(unsigned int));
+   prb->empty = false;
+   prb->dirty_done = true;
+   return false;
+}
+
+//#undef TRACE_PAGES_STORED
+unsigned int create_prb_and_fill(periscope_ramblock **prbs, unsigned long *num_dirty_pages, int id, bool store_ram) {
+   RAMBlock *rb;
+   //qemu_mutex_lock_ramlist();
+   //rcu_read_lock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+
+#ifdef TRACE_DEBUG
+   printf("%s\n", __FUNCTION__);
+#endif
+#ifndef PERI_DEDUP_NOHASH
+   max_new_pages = 0;
+#endif
+   unsigned int nrb = count_ramblocks();
+
+   *prbs = g_malloc(sizeof(periscope_ramblock) * nrb);
+   //assert(*prbs);
+#ifdef FINE_CHUNKS
+   if(store_ram && ram_cache == NULL) {
+      ram_cache = (ram_cache_meta*)g_malloc(sizeof(ram_cache_meta) * nrb);
+      n_cache = nrb;
+   }
+#endif
+
+   unsigned int rbs_idx = 0;
+
+   RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+      unsigned long npages_snap = (rb->max_length) >> TARGET_PAGE_BITS;
+      unsigned long npages_dirty = (rb->used_length) >> TARGET_PAGE_BITS;
+      if(num_dirty_pages != NULL) *num_dirty_pages = *num_dirty_pages + (npages_dirty/CHUNK_DIV);
+      // based on observation, early small memory areas are resized to 64 later
+      // might have to adapt.
+      if(npages_snap < 64) npages_snap = 64;
+      periscope_ramblock *prb = &((*prbs)[rbs_idx]);
+      prb->id = id;
+      create_ramblock(rb->idstr, prb);
+      init_ramblock(prb, NULL,
+            npages_snap, npages_dirty, true);
+#ifdef FINE_CHUNKS
+      if(store_ram) {
+         ram_cache_meta *prb_cache = &((ram_cache)[rbs_idx]);
+         //prb_cache->cache_meta = (void**)g_malloc(sizeof(void*) * npages_snap * CHUNK_DIV);
+         //memset(prb_cache->cache_meta, 0, sizeof(void*) * npages_snap * CHUNK_DIV);
+         prb_cache->cache_meta_key = (meow_u128*)g_malloc(sizeof(meow_u128) * npages_snap * CHUNK_DIV);
+         for(int i=0; i<npages_snap * CHUNK_DIV; ++i) {
+            prb_cache->cache_meta_key[i] = INVALID_KEY;//_mm_setzero_si128();
+         }
+         prb_cache->cache_meta_id = (int*)g_malloc(sizeof(int) * npages_snap * CHUNK_DIV);
+         for(int i=0; i<npages_snap * CHUNK_DIV; ++i) {
+            prb_cache->cache_meta_id[i] = 0;//_mm_setzero_si128();
+         }
+         strcpy(prb_cache->idstr, rb->idstr);
+      }
+#endif
+      rbs_idx++;
+      if(store_ram) {
+         int ret = store_ram_pages(rb, prb);
+         assert(ret == 0);
+         //assert(prb->npages_stored <= npages_dirty * CHUNK_DIV );
+         //assert(prb->npages_hashes_added <= prb->npages_stored);
+         //maybe_realloc_ramblock(prb);
+      }
+      prb->store_done = true;
+      prb->dirty_done = true;
+#ifdef TRACE_PAGES_STORED
+      printf("periscope: storing %lu/%lu dirty pages for snapshot %s\n", npages_dirty * CHUNK_DIV , npages_snap, rb->idstr);
+#endif
+   }
+
+   //rcu_read_unlock();
+   //qemu_mutex_unlock_ramlist();
+#ifndef PERI_DEDUP_NOHASH
+   max_new_pages = max_new_min;
+#endif
+   //assert(rbs_idx == nrb);
+   return nrb;
+}
+
+int create_prb_and_clear_delta_bm(periscope_ramblock **prbs, unsigned long *num_dirty_pages, int id) {
+   RAMBlock *rb;
+   //qemu_mutex_lock_ramlist();
+   //rcu_read_lock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+
+#ifdef TRACE_DEBUG
+   printf("%s\n", __FUNCTION__);
+#endif
+   unsigned int nrb = count_ramblocks();
+   unsigned long npages_snap;
+   unsigned long npages_dirty;
+
+   if(*prbs == NULL) {
+      *prbs = g_malloc(sizeof(periscope_ramblock) * nrb);
+      memset(*prbs, 0, sizeof(periscope_ramblock) * nrb);
+   }
+   //assert(*prbs);
+
+   unsigned int rbs_idx = 0;
+
+   RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+      periscope_ramblock *prb = &((*prbs)[rbs_idx++]);
+      prb->id = id;
+      bool skip = maybe_reset_ramblock(prb);
+      if(skip) continue;
+      if(!prb->dirty_done) {
+         struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_clear_dirty(
+               rb->mr,
+               0, rb->max_length,
+               DIRTY_MEMORY_DELTA
+               );
+         npages_snap = (snap->end - snap->start) >> TARGET_PAGE_BITS;
+         npages_dirty = bitmap_count_one(snap->dirty, npages_snap);
+         create_ramblock(rb->idstr, prb);
+         init_ramblock(prb, snap->dirty, npages_snap, npages_dirty, false);
+      } else {
+         npages_snap = prb->npages;
+         npages_dirty = bitmap_count_one(prb->dirty, prb->npages);
+      }
+      if(prb->empty) continue;
+      if(num_dirty_pages != NULL) *num_dirty_pages = *num_dirty_pages + (npages_dirty/CHUNK_DIV);
+      int ret = store_ram_pages(rb, prb);
+      if(ret < 0) {
+         //rcu_read_unlock();
+         //qemu_mutex_unlock_ramlist();
+         return -nrb;
+      }
+      //assert(prb->npages_stored <= npages_dirty * CHUNK_DIV );
+      //assert(prb->npages_hashes_added <= prb->npages_stored);
+      maybe_realloc_ramblock(prb);
+      prb->store_done = true;
+#ifdef TRACE_PAGES_STORED
+      printf("periscope: storing %lu/%lu dirty pages for snapshot %s\n", npages_dirty * CHUNK_DIV , npages_snap, rb->idstr);
+#endif
+   }
+
+   //rcu_read_unlock();
+   //qemu_mutex_unlock_ramlist();
+   //assert(rbs_idx == nrb);
+   return nrb;
+}
+
+unsigned long *new_fine_bitmap(unsigned long npages) {
+   unsigned long *bm = bitmap_new(npages * CHUNK_DIV);
+   bitmap_zero(bm, npages * CHUNK_DIV);
+   return bm;
+}
+unsigned long *copy_fine_bitmap(unsigned long *bm, unsigned long npages) {
+   unsigned long *new_bm = new_fine_bitmap(npages);
+   unsigned long ii = find_first_bit(bm, npages);
+   while(ii < npages) {
+      for(int i=0; i<CHUNK_DIV; ++i) {
+         set_bit(ii*CHUNK_DIV + i, new_bm);
+      }
+      ii = find_next_bit(bm, npages, ii+1);
+   }
+   return new_bm;
+}
+
+#define RAM_POOL_PERC 0.8f
+void delta_snap_init(int id, unsigned long pool_size) {
+#ifndef PERI_DEDUP_NOHASH
+    pool_size = pool_size * 1024 * 1024 * RAM_POOL_PERC;
+    unsigned long pool_entries = pool_size / CHUNK_SIZE;
+    unsigned long hashmap_entries = pool_entries * 8;
+    unsigned long hashmap_size = hashmap_entries * hashmap_element_size();
+    if(hashmap_size > pool_size * 0.6) {
+       hashmap_size = pool_size * 0.6;
+    }
+    unsigned long ram_page_pool_size = pool_size - hashmap_size;
+    pool_entries = ram_page_pool_size / CHUNK_SIZE;
+    printf("Instance id %d, pool size %ld/%ld, hashmap %ld/%ld\n",
+          id, ram_page_pool_size, pool_entries, hashmap_size, hashmap_entries);
+    //max_new_min = pool_entries * MAX_NEW_PERC;
+    fuzzer_id = id;
+    // TODO move to shared mem
+    ram_page_pool_hashmap = hashmap_new(NULL, NULL, hashmap_size, 1); // need twice as many entries for some reason
+    init_ram_page_pool(NULL, NULL, NULL, ram_page_pool_size, true);
+    assert(ram_page_pool_hashmap != NULL);
+    assert(rpp_info != NULL);
+#else
+    return;
+#endif
+}
+
+
+#endif /*PERI_DEDUP */
+
+// TODO: to be removed
+// get the bitmap of currently diry pages
+// this is used to determine which pages to RE-STORE
+unsigned long get_current_delta_bm(unsigned long **dirty) {
+    RAMBlock *rb;
+    unsigned long npages_snap = 0;
+    //qemu_mutex_lock_ramlist();
+    //rcu_read_lock();
+
+    MachineState *machine = MACHINE(qdev_get_machine());
+    assert(machine != NULL);
+    npages_snap = machine->ram_size >> TARGET_PAGE_BITS;
+
+    if(dirty) {
+       *dirty = bitmap_new(npages_snap);
+       bitmap_zero(*dirty, npages_snap);
+    }
+
+    RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+
+        // for now only handle ram
+        if (strcmp(rb->idstr, "pc.ram") != 0) {
+            continue;
+        }
+
+        // sync dirty bitmap from kvm and copy to local buffer
+        struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_get_dirty(
+            rb->mr,
+            0, rb->max_length,
+            DIRTY_MEMORY_DELTA
+        );
+
+        //printf("%s: update bm %lx - %lx\n", __FUNCTION__, snap->start, snap->end);
+        bitmap_or(*dirty, *dirty, snap->dirty, npages_snap);
+        g_free(snap);
+    }
+
+    //rcu_read_unlock();
+    //qemu_mutex_unlock_ramlist();
+    return npages_snap;
+}
+
+unsigned long update_and_clear_delta_snap_bm(unsigned long ** dirty) {
+    RAMBlock *rb;
+    unsigned long npages_snap = 0;
+    //qemu_mutex_lock_ramlist();
+    //rcu_read_lock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+
+    MachineState *machine = MACHINE(qdev_get_machine());
+    assert(machine != NULL);
+    npages_snap = machine->ram_size / TARGET_PAGE_SIZE;
+
+    if(dirty) {
+       *dirty = bitmap_new(npages_snap);
+       bitmap_zero(*dirty, npages_snap);
+    }
+
+    RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+
+        // for now only handle ram
+        if (strcmp(rb->idstr, "pc.ram") != 0) {
+            continue;
+        }
+
+        struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_clear_dirty(
+            rb->mr,
+            0, rb->max_length,
+            DIRTY_MEMORY_DELTA // TODO: do we need a custom flag?
+        );
+        //printf("%s: update bm %lx - %lx\n", __FUNCTION__, snap->start, snap->end);
+        if(dirty)
+           bitmap_or(*dirty, *dirty, snap->dirty, npages_snap);
+        g_free(snap);
+    }
+    //rcu_read_unlock();
+    //qemu_mutex_unlock_ramlist();
+    return npages_snap;
+}
+
+
+// call this before initiating checkpoint creation
+// this will update ramblock->bmap_delta_snap
+// ram_save_ ... will then only store pages which are
+// marked as dirty in ramblock->bmap_delta_snap
+int update_delta_snap_bm(unsigned long *dirty, unsigned long npages) {
+    RAMBlock *rb;
+    int ret = 1;
+
+    //qemu_mutex_lock_ramlist();
+    //rcu_read_lock();
+    RAMBLOCK_FOREACH(rb) {
+        // for now only handle ram
+        if (strcmp(rb->idstr, "pc.ram") != 0) {
+            continue;
+        }
+        if (rb->bmap_delta_snap == NULL) {
+           unsigned long npages_rb = rb->max_length >> TARGET_PAGE_BITS;
+           assert(npages_rb == npages);
+           if(rb->bmap_delta_snap != NULL) g_free(rb->bmap_delta_snap);
+           rb->bmap_delta_snap = bitmap_new(npages);
+        }
+        bitmap_copy(rb->bmap_delta_snap, dirty, npages);
+        ret = 0;
+        //goto out;
+    }
+//out:
+    //rcu_read_unlock();
+    //qemu_mutex_unlock_ramlist();
+    return ret;
+}
diff --git migration/periscope-delta-snap.c migration/periscope-delta-snap.c
new file mode 100644
index 0000000000..4fac6f800c
--- /dev/null
+++ migration/periscope-delta-snap.c
@@ -0,0 +1,425 @@
+#include "periscope-delta-snap.h"
+#include "hw/boards.h"
+#include "qemu/osdep.h"
+#include "cpu.h"
+#include "migration/periscope.h"
+#include "migration/ram.h"
+#include "exec/ram_addr.h"
+
+/* Should be holding either ram_list.mutex, or the RCU lock. */
+#define  INTERNAL_RAMBLOCK_FOREACH(block)  \
+    QLIST_FOREACH_RCU(block, &ram_list.blocks, next)
+/* Never use the INTERNAL_ version except for defining other macros */
+#define RAMBLOCK_FOREACH(block) INTERNAL_RAMBLOCK_FOREACH(block)
+
+/* Should be holding either ram_list.mutex, or the RCU lock. */
+#define RAMBLOCK_FOREACH_NOT_IGNORED(block)            \
+    INTERNAL_RAMBLOCK_FOREACH(block)                   \
+        if (ramblock_is_ignored(block)) {} else
+
+#define RAMBLOCK_FOREACH_MIGRATABLE(block)             \
+    INTERNAL_RAMBLOCK_FOREACH(block)                   \
+        if (!qemu_ram_is_migratable(block)) {} else
+
+
+// this flag enables selective storing of dirty pages in ram_save ...
+#ifdef ENABLE_LW_CHKPT
+bool periscope_delta_snapshot = true;
+#else
+bool periscope_delta_snapshot = false;
+#endif
+bool periscope_save_ram_only = false;
+
+struct DirtyBitmapSnapshot {
+    ram_addr_t start;
+    ram_addr_t end;
+    unsigned long dirty[];
+};
+
+unsigned long compute_prb_cost(periscope_ramblock *prbs, unsigned int nprb) {
+   unsigned long cost = 0;
+   for(unsigned int i=0; i<nprb; ++i) {
+      cost += prbs[i].npages_stored * TARGET_PAGE_SIZE;
+#ifdef DBG_RAM_STORED
+      cost += prbs[i].rambkp_size;
+#endif
+   }
+   return cost;
+ }
+
+void restore_ram_pages(RAMBlock *rb, void* ram, unsigned long* offsets,
+    unsigned long npages_stored, unsigned long npages, unsigned long* dirty) {
+    rcu_read_lock();
+    assert(rb);
+    unsigned long page_index = 0;
+    unsigned long pages_restored = 0;
+    for(unsigned long i=0; i<BITS_TO_LONGS(npages); ++i) {
+       if(dirty[i] == 0) continue;
+       unsigned long mask = dirty[i];
+       for(int mask_offset = 0; mask_offset < BITS_PER_LONG; ++mask_offset) {
+          if((mask & (1ul<<mask_offset)) != 0) {
+             unsigned long page = ((i * BITS_PER_LONG) + mask_offset) ;
+             unsigned long offset = page << TARGET_PAGE_BITS;
+             // skip to the next page to be restored
+             for(unsigned long restore_page = page_index;
+                   restore_page < npages_stored; ++restore_page) {
+                if(offsets[restore_page] == offset) {
+                   page_index = restore_page;
+                   break;
+                }
+             }
+             assert(page_index < npages_stored);
+             void *host = host_from_ram_block_offset(rb, offset);
+             assert(host);
+             //printf("restoring offset %#lx, page_index %#lx\n", offset, page_index);
+             memcpy(host,
+                   ram + (page_index * TARGET_PAGE_SIZE),
+                   TARGET_PAGE_SIZE);
+             page_index++;
+             pages_restored++;
+          }
+       }
+    }
+    rcu_read_unlock();
+    printf("restored %ld pages\n", pages_restored);
+}
+
+static void store_ram_pages(RAMBlock *rb, void* ram, unsigned long* offsets,
+    unsigned long npages_dirty, unsigned long npages, unsigned long* dirty) {
+    rcu_read_lock();
+    assert(rb);
+    printf("%s: %s\n", __FUNCTION__, rb->idstr);
+    unsigned long pages_stored = 0;
+    for(unsigned long i=0; i<BITS_TO_LONGS(npages); ++i) {
+       if(dirty[i] == 0) continue;
+       unsigned long mask = dirty[i];
+       for(int mask_offset = 0; mask_offset < BITS_PER_LONG; ++mask_offset) {
+          if((mask & (1ul<<mask_offset)) != 0) {
+             unsigned long page = ((i * BITS_PER_LONG) + mask_offset) ;
+             unsigned long offset = page << TARGET_PAGE_BITS;
+             void *host = host_from_ram_block_offset(rb, offset);
+             if(!host) {
+                printf("offset %lx, host %lx, %lx\n", offset, rb->max_length, rb->used_length);
+             }
+             assert(host);
+             assert(pages_stored < npages_dirty);
+             offsets[pages_stored] = offset;
+             memcpy(ram + (pages_stored * TARGET_PAGE_SIZE),
+                   host, TARGET_PAGE_SIZE);
+             pages_stored++;
+          }
+       }
+    }
+   assert(pages_stored == npages_dirty);
+   rcu_read_unlock();
+}
+
+periscope_ramblock *get_ramblock(periscope_ramblock *prbs, unsigned int nprb, const char *name) {
+   for(unsigned int i=0; i<nprb; ++i) {
+      if(strcmp(name, prbs[i].idstr) == 0)
+         return &prbs[i];
+   }
+   return NULL;
+}
+
+static periscope_ramblock *delete_ramblock(periscope_ramblock *prb) {
+   printf("Deleting peri_rb %s\n", prb->idstr);
+   if(prb->dirty) {
+      g_free(prb->dirty);
+      prb->dirty = NULL;
+   }
+   prb->npages = 0;
+#ifdef DBG_RAM_STORED
+   if(prb->rambkp) {
+      g_free(prb->rambkp);
+      prb->rambkp = NULL;
+   }
+   prb->rambkp_size = 0;
+#endif
+   prb->npages_stored = 0;
+   if(prb->offsets){
+      g_free(prb->offsets);
+      prb->offsets = NULL;
+   }
+   if(prb->ram) {
+      g_free(prb->ram);
+      prb->ram = NULL;
+   }
+   return prb;
+}
+void delete_peri_rbs(periscope_ramblock *prb, unsigned int nprb) {
+   assert(prb);
+   printf("Deleting %d peri_rbs\n", nprb);
+   for(unsigned int i=0; i<nprb; ++i) {
+      delete_ramblock(&prb[i]);
+   }
+}
+
+static void create_ramblock(char *name, periscope_ramblock *prb) {
+   assert(name);
+   assert(prb);
+   prb->dirty = NULL;
+   prb->npages = 0;
+#ifdef DBG_RAM_STORED
+   prb->rambkp = NULL;
+   prb->rambkp_size = 0;
+#endif
+   prb->npages_stored = 0;
+   prb->offsets = NULL;
+   prb->ram = NULL;
+   strcpy(prb->idstr, name);
+}
+
+// must hold rcu and ramlist lock
+static unsigned int count_ramblocks(void) {
+   RAMBlock *rb;
+   unsigned int nrb = 0;
+   RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+      nrb++;
+   }
+   return nrb;
+}
+
+
+unsigned int create_prb_and_fill(periscope_ramblock **prbs) {
+   RAMBlock *rb;
+   qemu_mutex_lock_ramlist();
+   rcu_read_lock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+
+   unsigned int nrb = count_ramblocks();
+   printf("%s: #ramblocks %d\n", __FUNCTION__, nrb);
+
+   *prbs = g_malloc(sizeof(periscope_ramblock) * nrb);
+   assert(*prbs);
+
+   unsigned int rbs_idx = 0;
+
+   RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+      periscope_ramblock *prb = &((*prbs)[rbs_idx++]);
+      create_ramblock(rb->idstr, prb);
+
+      unsigned long npages_snap = (rb->max_length) >> TARGET_PAGE_BITS;
+      prb->dirty = bitmap_new(npages_snap);
+      bitmap_fill(prb->dirty, rb->used_length >> TARGET_PAGE_BITS);
+      prb->npages = npages_snap;
+#ifdef DBG_RAM_STORED
+      prb->rambkp = g_malloc(rb->max_length);
+      prb->rambkp_size = rb->max_length;
+      memcpy(prb->rambkp, rb->host, rb->max_length);
+#endif
+      unsigned long npages_dirty = bitmap_count_one(prb->dirty, npages_snap);
+      prb->offsets = g_malloc(npages_dirty * sizeof(unsigned long));
+      prb->ram = g_malloc(npages_dirty * TARGET_PAGE_SIZE);
+      store_ram_pages(rb, prb->ram, prb->offsets, npages_dirty, npages_snap, prb->dirty);
+      prb->npages_stored = npages_dirty;
+   }
+
+   rcu_read_unlock();
+   qemu_mutex_unlock_ramlist();
+   assert(rbs_idx == nrb);
+   return nrb;
+}
+
+unsigned int create_prb_and_clear_delta_bm(periscope_ramblock **prbs) {
+   RAMBlock *rb;
+   qemu_mutex_lock_ramlist();
+   rcu_read_lock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+
+   unsigned int nrb = count_ramblocks();
+   printf("%s: #ramblocks %d\n", __FUNCTION__, nrb);
+
+   *prbs = g_malloc(sizeof(periscope_ramblock) * nrb);
+   assert(*prbs);
+
+
+   unsigned int rbs_idx = 0;
+
+   RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+      periscope_ramblock *prb = &((*prbs)[rbs_idx++]);
+      create_ramblock(rb->idstr, prb);
+
+      struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_clear_dirty(
+            rb->mr,
+            0, rb->max_length,
+            DIRTY_MEMORY_DELTA
+            );
+      unsigned long npages_snap = (snap->end - snap->start) >> TARGET_PAGE_BITS;
+      printf("%s: update bm %s %lx - %lx\n", __FUNCTION__, rb->idstr, snap->start, snap->end);
+      prb->dirty = bitmap_new(npages_snap);
+      bitmap_copy(prb->dirty, snap->dirty, npages_snap);
+      prb->npages = npages_snap;
+#ifdef DBG_RAM_STORED
+      prb->rambkp = g_malloc(rb->max_length);
+      prb->rambkp_size = rb->max_length;
+      memcpy(prb->rambkp, rb->host, rb->max_length);
+#endif
+      unsigned long npages_dirty = bitmap_count_one(prb->dirty, npages_snap);
+      prb->offsets = g_malloc(npages_dirty * sizeof(unsigned long));
+      prb->ram = g_malloc(npages_dirty * TARGET_PAGE_SIZE);
+      store_ram_pages(rb, prb->ram, prb->offsets, npages_dirty, npages_snap, prb->dirty);
+      prb->npages_stored = npages_dirty;
+      g_free(snap);
+   }
+
+   rcu_read_unlock();
+   qemu_mutex_unlock_ramlist();
+   assert(rbs_idx == nrb);
+   return nrb;
+}
+
+
+// TODO: to be removed
+// get the bitmap of currently diry pages
+// this is used to determine which pages to RE-STORE
+unsigned long get_current_delta_bm(unsigned long **dirty) {
+    RAMBlock *rb;
+    unsigned long npages_snap = 0;
+    qemu_mutex_lock_ramlist();
+    rcu_read_lock();
+
+    MachineState *machine = MACHINE(qdev_get_machine());
+    assert(machine != NULL);
+    npages_snap = machine->ram_size / TARGET_PAGE_SIZE;
+
+    if(dirty) {
+       *dirty = bitmap_new(npages_snap);
+       bitmap_zero(*dirty, npages_snap);
+    }
+
+    RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+
+        // for now only handle ram
+        if (strcmp(rb->idstr, "pc.ram") != 0) {
+            continue;
+        }
+
+        // sync dirty bitmap from kvm and copy to local buffer
+        struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_get_dirty(
+            rb->mr,
+            0, rb->max_length,
+            DIRTY_MEMORY_DELTA
+        );
+
+        printf("%s: update bm %lx - %lx\n", __FUNCTION__, snap->start, snap->end);
+        bitmap_or(*dirty, *dirty, snap->dirty, npages_snap);
+        g_free(snap);
+    }
+
+    rcu_read_unlock();
+    qemu_mutex_unlock_ramlist();
+    return npages_snap;
+}
+
+#if 0
+unsigned long update_and_clear_delta_snap_bm(unsigned long ** dirty) {
+    RAMBlock *rb;
+    unsigned long npages_snap = 0;
+    qemu_mutex_lock_ramlist();
+    rcu_read_lock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+
+    MachineState *machine = MACHINE(qdev_get_machine());
+    assert(machine != NULL);
+    npages_snap = machine->ram_size / TARGET_PAGE_SIZE;
+
+    if(dirty) {
+       *dirty = bitmap_new(npages_snap);
+       bitmap_zero(*dirty, npages_snap);
+    }
+
+    RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+
+        // for now only handle ram
+        if (strcmp(rb->idstr, "pc.ram") != 0) {
+            continue;
+        }
+
+        struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_clear_dirty(
+            rb->mr,
+            0, rb->max_length,
+            DIRTY_MEMORY_DELTA // TODO: do we need a custom flag?
+        );
+        //printf("%s: update bm %lx - %lx\n", __FUNCTION__, snap->start, snap->end);
+        if(dirty)
+           bitmap_or(*dirty, *dirty, snap->dirty, npages_snap);
+        g_free(snap);
+    }
+    rcu_read_unlock();
+    qemu_mutex_unlock_ramlist();
+    return npages_snap;
+}
+
+// get the bitmap of currently diry pages
+// this is used to determine which pages to RE-STORE
+unsigned long get_current_delta_bm(unsigned long **dirty) {
+    RAMBlock *rb;
+    unsigned long npages_snap = 0;
+    qemu_mutex_lock_ramlist();
+    rcu_read_lock();
+
+    MachineState *machine = MACHINE(qdev_get_machine());
+    assert(machine != NULL);
+    npages_snap = machine->ram_size / TARGET_PAGE_SIZE;
+
+    if(dirty) {
+       *dirty = bitmap_new(npages_snap);
+       bitmap_zero(*dirty, npages_snap);
+    }
+
+    RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+
+        // for now only handle ram
+        if (strcmp(rb->idstr, "pc.ram") != 0) {
+            continue;
+        }
+
+        // sync dirty bitmap from kvm and copy to local buffer
+        struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_get_dirty(
+            rb->mr,
+            0, rb->max_length,
+            DIRTY_MEMORY_DELTA
+        );
+
+        //printf("%s: update bm %lx - %lx\n", __FUNCTION__, snap->start, snap->end);
+        //npages_snap = (snap->end - snap->start) >> TARGET_PAGE_BITS;
+        bitmap_or(*dirty, *dirty, snap->dirty, npages_snap);
+        g_free(snap);
+        //goto out;
+        //return npages_snap;
+    }
+
+//out:
+    rcu_read_unlock();
+    qemu_mutex_unlock_ramlist();
+    return npages_snap;
+}
+
+// call this before initiating checkpoint creation
+// this will update ramblock->bmap_delta_snap
+// ram_save_ ... will then only store pages which are
+// marked as dirty in ramblock->bmap_delta_snap
+int update_delta_snap_bm(unsigned long *dirty, unsigned long npages) {
+    RAMBlock *rb;
+    int ret = 1;
+
+    qemu_mutex_lock_ramlist();
+    rcu_read_lock();
+    RAMBLOCK_FOREACH(rb) {
+        // for now only handle ram
+        if (strcmp(rb->idstr, "pc.ram") != 0) {
+            continue;
+        }
+        if (rb->bmap_delta_snap == NULL) {
+           unsigned long npages_rb = rb->max_length >> TARGET_PAGE_BITS;
+           assert(npages_rb == npages);
+           rb->bmap_delta_snap = bitmap_new(npages);
+        }
+        bitmap_copy(rb->bmap_delta_snap, dirty, npages);
+        ret = 0;
+        //goto out;
+    }
+//out:
+    rcu_read_unlock();
+    qemu_mutex_unlock_ramlist();
+    return ret;
+}
+#endif
diff --git migration/periscope-delta-snap.h migration/periscope-delta-snap.h
new file mode 100644
index 0000000000..83986d338c
--- /dev/null
+++ migration/periscope-delta-snap.h
@@ -0,0 +1,66 @@
+#ifndef PERISCOPE_DELTA_SNAP_H
+#define PERISCOPE_DELTA_SNAP_H
+
+#include "qemu/osdep.h"
+#include "qemu/units.h"
+#include "qapi/error.h"
+
+#define ENABLE_LW_CHKPT
+//#undef ENABLE_LW_CHKPT
+
+// TODO: remove
+extern bool periscope_delta_snapshot;
+extern bool periscope_save_ram_only;
+
+struct periscope_ramblock;
+
+unsigned long count_unique_pages(void);
+unsigned long count_dirty_pages(void);
+unsigned long count_hashed_pages_prbs(struct periscope_ramblock *prbs, unsigned int nprb);
+unsigned long count_stored_pages_prbs(struct periscope_ramblock *prbs, unsigned int nprb);
+unsigned long count_zero_pages_prbs(struct periscope_ramblock *prbs, unsigned int nprb);
+unsigned long count_skipped_pages_prbs(struct periscope_ramblock *prbs, unsigned int nprb);
+//void delta_snap_init(MemoryRegion *mem_pool, MemoryRegion *mem_meta, int id);
+void delta_snap_init(int id, unsigned long chkpt_pool_size);
+uint64_t chkpt_memory_free(void);
+// compute cost of stored data for all ramblocks
+unsigned long compute_hashmap_cost(void);
+unsigned long compute_total_hashmap_cost(void);
+unsigned long compute_hash_cost(struct periscope_ramblock *prbs, unsigned int nprb);
+unsigned long compute_prb_cost(struct periscope_ramblock *prbs, unsigned int nprb);
+unsigned long compute_prb_freed(struct periscope_ramblock *prb);
+uint64_t get_ram_page_pool_size(void);
+uint64_t get_rpp_hashmap_size(void);
+uint64_t get_free_pages(void);
+uint64_t compute_dirty_cost(unsigned long num_dirty_pages);
+// delete all periscope ramblock data stored in the peri_rb array
+void delete_peri_rbs(struct periscope_ramblock *prbs, unsigned int nprb, struct periscope_ramblock *prbs_parent);
+// Go through all ramblocks and create a periscope ramblock entry for each one
+// copy the current delta dirty bitmap of that ramblock in the peri_rb structure
+// and store all the dirty pages
+int create_prb_and_clear_delta_bm(struct periscope_ramblock **prbs, unsigned long *num_dirty_pages, int id);
+// Go through all ramblocks and create a periscope ramblock entry for each one
+// fill the dirty bitmap of each new entry and copy the complete ramblock data
+unsigned int create_prb_and_fill(struct periscope_ramblock **prbs, unsigned long *num_dirty_pages, int id, bool store_ram);
+struct periscope_ramblock *get_ramblock(struct periscope_ramblock *prbs, unsigned int nprb, const char *name);
+// restore stored ram pages
+void restore_ram_pages(RAMBlock *rb, struct periscope_ramblock *prb, unsigned long* dirty);
+float compute_uniqueness(struct periscope_ramblock *prbs, unsigned int nprb);
+
+unsigned long get_current_delta_bm(unsigned long **dirty);
+unsigned long get_max_new_pages(void);
+int grow_ram_page_pool(unsigned long max_new);
+
+
+unsigned long update_and_clear_delta_snap_bm(unsigned long ** dirty);
+// refresh bmap_delta_snap from kvm and clear kvm bitmap
+// copy bmap_delta_snap into **dirty
+// it **dirty is null, it will be allocated
+// but do not zero bmap_delta_snap
+//unsigned long get_current_delta_bm(unsigned long **dirty);
+// copy bmap_delta_snap (managed by qemu into *dirty
+int update_delta_snap_bm(unsigned long *dirty, unsigned long npages);
+unsigned long *copy_fine_bitmap(unsigned long *bm, unsigned long npages);
+unsigned long *new_fine_bitmap(unsigned long npages);
+
+#endif
diff --git migration/periscope-exec.c migration/periscope-exec.c
new file mode 100644
index 0000000000..90be955045
--- /dev/null
+++ migration/periscope-exec.c
@@ -0,0 +1,115 @@
+#include "qemu/osdep.h"
+#include "qapi/error.h"
+
+#include <sys/shm.h>
+
+#include "periscope.h"
+
+static char *exec_input = NULL;
+static int exec_input_used_len = 0;
+static int exec_input_size = -1;
+
+static int executor_mmio_read(unsigned size, uint64_t *out) {
+    if (exec_input == NULL) {
+        printf("periscope: no exec input\n");
+        return -1;
+    }
+
+    if (exec_input_used_len + size > exec_input_size) {
+        printf("periscope: exec input fully consumed\n");
+        *out = 0;
+        return 0;
+    }
+
+    exec_input_used_len += size;
+
+    printf("periscope: exec input \"");
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    periscope_input_desc *cur = s->cur_input;
+    assert(cur != NULL);
+
+    switch (size) {
+    case 1:
+        if (cur->used_len + size <= exec_input_size) {
+            *out = *((uint8_t*)&exec_input[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 2:
+        if (cur->used_len + size <= exec_input_size) {
+            *out = *((uint16_t*)&exec_input[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 4:
+        if (cur->used_len + size <= exec_input_size) {
+            *out = *((uint32_t*)&exec_input[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 8:
+        if (cur->used_len + sizeof(uint64_t) <= exec_input_size) {
+            *out = *((uint64_t*)&exec_input[cur->used_len]);
+            cur->used_len += sizeof(uint64_t);
+        }
+        break;
+    default:
+        printf("periscope: unexpected size!\n");
+        if (cur->used_len + sizeof(uint64_t) <= exec_input_size) {
+            *out = *((uint64_t*)&exec_input[cur->used_len]);
+            cur->used_len += sizeof(uint64_t);
+        }
+        break;
+    }
+
+    printf("0x%lx\" consumed. (%d/%d bytes)\n", *out,
+           exec_input_used_len,
+           exec_input_size);
+
+    return 0;
+}
+
+static char *executor_fetch_next(uint32_t* len) {
+    printf("periscope: executor input fetch requested\n");
+    *len = exec_input_size;
+    return exec_input;
+}
+
+void start_input_executor(const char *uri, Error **errp) {
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    int fd = qemu_open(uri, O_RDONLY|O_BINARY);
+    if (fd < 0) {
+        printf("periscope: exec file open failed\n");
+        return;
+    }
+
+    struct stat st;
+    stat(uri, &st);
+
+    exec_input_size = st.st_size;
+
+    printf("periscope: executing input %s (size: %u)\n", uri, exec_input_size);
+
+    exec_input = mmap(NULL, exec_input_size, PROT_READ,
+                      MAP_PRIVATE | MAP_POPULATE,
+                      fd, 0);
+    if (!exec_input) {
+        printf("periscope: exec input mmap failed\n");
+    }
+
+    // HACK
+    s->cur_input->input = exec_input;
+    s->cur_input->len = exec_input_size;
+    s->cur_input->used_len = 0;
+
+    s->mode = PERISCOPE_MODE_EXEC;
+    s->mmio_read = executor_mmio_read;
+    s->fetch_next = executor_fetch_next;
+    s->get_cur = NULL;
+    s->cur_executed = NULL;
+}
diff --git migration/periscope-kcov.c migration/periscope-kcov.c
new file mode 100644
index 0000000000..38b0083aa1
--- /dev/null
+++ migration/periscope-kcov.c
@@ -0,0 +1,187 @@
+#include "qemu/osdep.h"
+#include "qapi/error.h"
+
+#include <sys/shm.h>
+
+#include "periscope.h"
+#include "hw/periscope/kcov_vdev.h"
+
+#define MAX_CORPUS_ARGS 10
+
+static int total_corpus_paths = 0;
+static int cur_corpus_path = -1;
+static char *corpus_paths[MAX_CORPUS_ARGS];
+static char *corpus_blob = NULL;
+static int corpus_blob_size = 0;
+
+static DIR *open_dir = NULL;
+static char *open_dirname = NULL;
+static struct dirent *dp = NULL;
+
+static int kcov_mmio_read(unsigned size, uint64_t *out) {
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    periscope_input_desc *cur = s->cur_input;
+    assert(cur != NULL);
+
+    kcov_flush_area(false);
+
+    *out = 0;
+
+    switch (size) {
+    case 1:
+        if (cur->used_len + size <= corpus_blob_size) {
+            *out = *((uint8_t*)&corpus_blob[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 2:
+        if (cur->used_len + size <= corpus_blob_size) {
+            *out = *((uint16_t*)&corpus_blob[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 4:
+        if (cur->used_len + size <= corpus_blob_size) {
+            *out = *((uint32_t*)&corpus_blob[cur->used_len]);
+            cur->used_len += size;
+        }
+        break;
+    case 8:
+        if (cur->used_len + sizeof(uint64_t) <= corpus_blob_size) {
+            *out = *((uint64_t*)&corpus_blob[cur->used_len]);
+            cur->used_len += sizeof(uint64_t);
+        }
+        break;
+    default:
+        printf("periscope: unexpected size!\n");
+        if (cur->used_len + sizeof(uint64_t) <= corpus_blob_size) {
+            *out = *((uint64_t*)&corpus_blob[cur->used_len]);
+            cur->used_len += sizeof(uint64_t);
+        }
+        break;
+    }
+
+    return 0;
+}
+
+static void kcov_maybe_exit(void) {
+    if (cur_corpus_path >= total_corpus_paths) {
+        printf("periscope: no corpus left. \n");
+
+        if (open_dir) {
+            closedir(open_dir);
+            open_dir = NULL;
+        }
+
+        exit(0);
+    }
+}
+
+static char *kcov_fetch_next(uint32_t* len) {
+    char cpath[1024];
+    struct stat cpath_stat;
+
+    if (open_dir) {
+        while ((dp = readdir(open_dir)) != NULL) {
+            if (dp->d_type == DT_REG) {
+                sprintf(cpath, "%s/%s", open_dirname, dp->d_name);
+                stat(cpath, &cpath_stat);
+                break;
+            }
+        }
+
+        if (dp == NULL) {
+            closedir(open_dir);
+            open_dir = NULL;
+        }
+    }
+    
+    if (open_dir == NULL) {
+        cur_corpus_path++;
+        kcov_maybe_exit();
+        strncpy(cpath, corpus_paths[cur_corpus_path], sizeof(cpath));
+    }
+
+    // Prune invalid paths.
+    while (stat(cpath, &cpath_stat) < 0) {
+        printf("periscope: wrong corpus path '%s'. skipping...\n", cpath);
+        cur_corpus_path++;
+        kcov_maybe_exit();
+        strncpy(cpath, corpus_paths[cur_corpus_path], sizeof(cpath));
+    }
+
+    // We ignore sub-directories of the given directories.
+    if (open_dir == NULL && S_ISDIR(cpath_stat.st_mode)) {
+        printf("periscope: opening corpus directory %s.\n", cpath);
+        open_dir = opendir(cpath);
+        open_dirname = corpus_paths[cur_corpus_path];
+        dp = NULL;
+        return kcov_fetch_next(len);
+    }
+
+    // cpath must refer to a regular file at this point.
+    if (!S_ISREG(cpath_stat.st_mode)) {
+        cur_corpus_path++;
+        kcov_maybe_exit();
+        strncpy(cpath, corpus_paths[cur_corpus_path], sizeof(cpath));
+    }
+
+    int cfd = qemu_open(cpath, O_RDONLY|O_BINARY);
+
+    printf("periscope: opened corpus file '%s' (fd=%d, len=%ld)\n",
+           cpath, cfd, cpath_stat.st_size);
+
+    if (corpus_blob != NULL) {
+        munmap(corpus_blob, cpath_stat.st_size);
+    }
+
+    corpus_blob = mmap(NULL, cpath_stat.st_size, PROT_READ,
+                       MAP_PRIVATE | MAP_POPULATE,
+                       cfd, 0);
+    corpus_blob_size = cpath_stat.st_size;
+
+    *len = cpath_stat.st_size;
+
+    return corpus_blob;
+}
+
+// This function returns a correct result only if the trace-pc option was used.
+static void kcov_cur_executed(uint8_t *trace_pcs, uint32_t used_len, uint64_t elapsed_ms, bool timed_out) {
+    if (!trace_pcs) return;
+
+    kcov_flush_area(false);
+}
+
+void start_coverage_collector(const char *args, Error **errp) {
+    printf("periscope: initializing coverage collector\n");
+
+    char tmp[1024];
+    strncpy(tmp, args, sizeof(tmp));
+
+    char *path = strtok(tmp, ",");
+
+    while (path && total_corpus_paths < MAX_CORPUS_ARGS) {
+        corpus_paths[total_corpus_paths] = strdup(path);
+        total_corpus_paths++;
+
+        printf("periscope: corpus path '%s'\n", path);
+
+        path = strtok(NULL, ",");
+    }
+
+    if (total_corpus_paths < 0) {
+        printf("periscope: no corpus dir/file paths given.\n");
+        exit(1);
+    }
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    s->mode = PERISCOPE_MODE_COVERAGE;
+    s->mmio_read = kcov_mmio_read;
+    s->fetch_next = kcov_fetch_next;
+    s->get_cur = NULL;
+    s->cur_executed = kcov_cur_executed;
+}
diff --git migration/periscope-profiler.c migration/periscope-profiler.c
new file mode 100644
index 0000000000..b0eb31ac6d
--- /dev/null
+++ migration/periscope-profiler.c
@@ -0,0 +1,357 @@
+/// Before running this, DISABLE zero-page opt by adding the following code to save_zero_page_to_file
+///     if (strcmp(block->idstr, "pc.ram") == 0)
+///         return 0;
+
+
+#include "qemu/osdep.h"
+
+#include "hw/boards.h"
+#include "cpu.h"
+#include "exec/ram_addr.h"
+#include "io/channel-file.h"
+#include "io/channel-buffer.h"
+#include "migration/migration.h"
+#include "migration/qemu-file.h"
+#include "migration/savevm.h"
+#include "migration/global_state.h"
+#include "qemu-file-channel.h"
+
+#include "migration/periscope.h"
+#include "migration/periscope_perf_switches.h"
+
+enum {
+    PERISCOPE_PROFILE_CHECKPOINT = 1,
+    PERISCOPE_PROFILE_RESTORE,
+    PERISCOPE_PROFILE_BASELINE,
+};
+
+#define DIRTY_PAGE_RANGE_BEGIN 1024 // 4MB worh of dirty pages
+#define DIRTY_PAGE_RANGE_INCR 1024
+#define DIRTY_PAGE_RANGE_MAX 1024 * 512 / 8 // 512MB
+
+static int profiler_type = 0;
+static int profiler_mode = PERISCOPE_PROFILE_CHECKPOINT;
+static int num_dirty_pages = DIRTY_PAGE_RANGE_BEGIN;
+
+unsigned char dummy[1024];
+unsigned char dummy_val = 0x1;
+int used_len = 0;
+
+static char *fetch_next(uint32_t *len)
+{
+    if (dummy_val == 0xff) {
+        dummy_val = 0x1;
+    }
+    if (profiler_mode == PERISCOPE_PROFILE_RESTORE) {
+        dummy_val = 0xff; // give a value that never get matched with any checkpoint
+    }
+    memset(dummy, dummy_val++, sizeof(dummy));
+    *len = sizeof(dummy);
+    return (char *)dummy;
+}
+
+static int snapshot_and_restore_requested = 0;
+
+static void snapshot_and_restore_request(void)
+{
+    vm_stop(RUN_STATE_SAVE_VM);
+
+    snapshot_and_restore_requested = 1;
+}
+
+int periscope_snapshot_and_restore_baseline_requested(void)
+{
+    return snapshot_and_restore_requested;
+}
+
+#define USE_CHANNEL_BUFFER
+
+void periscope_snapshot_and_restore_baseline(void)
+{
+    snapshot_and_restore_requested = 0;
+
+    Error *err = NULL;
+    int ret = -1;
+
+    QEMUFile *file;
+#ifdef USE_CHANNEL_BUFFER
+    QIOChannelBuffer *iochannel;
+#else
+    QIOChannelFile *iochannel;
+    int memfd = -1;
+#endif
+
+    qemu_timeval tv1, tv2, tv3, sub;
+
+    vm_stop(RUN_STATE_SAVE_VM);
+    global_state_store_running();
+
+    // snapshot
+    qemu_gettimeofday(&tv1);
+
+#ifdef USE_CHANNEL_BUFFER
+    MachineState *machine = MACHINE(qdev_get_machine());
+    assert(machine != NULL);
+    size_t channel_buffer_size = machine->ram_size + 32*1024*1024;
+    iochannel = qio_channel_buffer_new(channel_buffer_size);
+    file = qemu_fopen_channel_output(QIO_CHANNEL(iochannel));
+#else
+    memfd = memfd_create("baseline", 0);
+    int dupfd = dup(memfd);
+
+    iochannel = qio_channel_file_new_fd(dupfd);
+    file = qemu_fopen_channel_output(QIO_CHANNEL(iochannel));
+#endif
+    //iochannel = NULL;
+
+    ret = qemu_savevm_state(file, &err);
+    qemu_gettimeofday(&tv2);
+
+    qemu_fflush(file);
+    size_t file_sz = qemu_ftell(file);
+#ifdef USE_CHANNEL_BUFFER
+    char *tmp = g_malloc(file_sz);
+    memcpy(tmp, iochannel->data, file_sz);
+#endif
+    object_unref(OBJECT(iochannel));
+    iochannel = NULL;
+    qemu_fclose(file);
+    file = NULL;
+
+    if (ret < 0) {
+        printf("periscope: benchmark-baseline-snapshot failed\n");
+        goto exit;
+    }
+
+    timersub(&tv2, &tv1, &sub);
+
+    printf("periscope: benchmark-baseline-snapshot took %lu ms\n",
+           sub.tv_sec * 1000L + sub.tv_usec / 1000L);
+
+    printf("periscope: benchmark-baseline-snapshot consumed %lu MiB\n",
+           file_sz/1024UL/1024UL);
+
+    vm_stop(RUN_STATE_RESTORE_VM);
+
+    // restore
+#ifdef USE_CHANNEL_BUFFER
+    iochannel = qio_channel_buffer_new(file_sz);
+    iochannel->usage = file_sz;
+    memcpy(iochannel->data, tmp, file_sz);
+    g_free(tmp);
+#else
+    lseek(memfd, 0, SEEK_SET);
+    iochannel = qio_channel_file_new_fd(dup(memfd));
+#endif
+    file = qemu_fopen_channel_input(QIO_CHANNEL(iochannel));
+    MigrationIncomingState *mis = migration_incoming_get_current();
+    mis->from_src_file = file;
+
+    qemu_gettimeofday(&tv2);
+    ret = qemu_loadvm_state(file);
+    qemu_gettimeofday(&tv3);
+
+    mis->from_src_file = NULL;
+    migration_incoming_state_destroy();
+
+    qemu_fflush(file);
+    qemu_fclose(file);
+    file = NULL;
+
+    if (ret < 0) {
+        printf("periscope: benchmark-baseline-restore failed\n");
+        goto exit;
+    }
+
+    timersub(&tv3, &tv2, &sub);
+
+    printf("periscope: benchmark-baseline-restore took %lu ms\n",
+           sub.tv_sec * 1000L + sub.tv_usec / 1000L);
+
+exit:
+    if (iochannel) {
+        object_unref(OBJECT(iochannel));
+        iochannel = NULL;
+    }
+
+#ifndef USE_CHANNEL_BUFFER
+    close(memfd);
+    memfd = -1;
+#endif
+
+    vm_start();
+}
+
+static bool ensure_dirty_pages(int in_num_dirty_pages, int *real_dirty_pages)
+{
+    //size_t sz = in_num_dirty_pages * TARGET_PAGE_SIZE;
+    RAMBlock *rb = qemu_ram_block_by_name("pc.ram");
+    assert(rb);
+    MemoryRegion *mr = rb->mr;
+    assert(mr);
+
+    unsigned long *dirty = NULL;
+    unsigned long num_pages = get_current_delta_bm(&dirty);
+    assert(dirty != NULL);
+
+    unsigned long num_dirty_pages = bitmap_count_one(dirty, num_pages);
+
+    unsigned long pgidx = 0;
+    while (num_dirty_pages < in_num_dirty_pages) {
+        while (test_bit(pgidx, dirty) != 0) {
+            pgidx++;
+        }
+        memory_region_set_dirty(mr, pgidx*TARGET_PAGE_SIZE, TARGET_PAGE_SIZE);
+        pgidx++;
+        num_dirty_pages++;
+    }
+
+    g_free(dirty);
+    dirty = NULL;
+
+    if (real_dirty_pages) {
+        num_pages = get_current_delta_bm(&dirty);
+        assert(dirty != NULL);
+
+        num_dirty_pages = bitmap_count_one(dirty, num_pages);
+        g_free(dirty);
+        dirty = NULL;
+
+        *real_dirty_pages = num_dirty_pages;
+    }
+    return true;
+}
+
+#define CHKPT_TRIALS 10
+static int chkpt_trials = CHKPT_TRIALS;
+
+#define RESTORE_TRIALS 10
+static int restore_trials = RESTORE_TRIALS;
+
+static int baseline_trials = 10;
+
+void periscope_benchmark_hypercall(uint64_t arg)
+{
+    printf("periscope: benchmark hypercall\n");
+
+    int num_real_dirty_pages;
+
+    switch (profiler_mode) {
+    case PERISCOPE_PROFILE_CHECKPOINT:
+        if (!periscope_snapshot_inited()) {
+            periscope_maybe_checkpoint_request();
+            periscope_restore_request();
+            break;
+        }
+
+        if (ensure_dirty_pages(num_dirty_pages, &num_real_dirty_pages)) {
+            printf("periscope: benchmark-checkpoint %d dirty pages\n",
+                   num_real_dirty_pages);
+
+            FuzzerState *fs = fuzzer_get_current();
+            assert(fs);
+            assert(fs->cur_cp);
+            fs->cur_cp->len = 1;
+            memcpy(fs->cur_cp->io, dummy + used_len, 1);
+
+            assert(fs->cur_input);
+            fs->cur_input->used_len++;
+
+            assert(fs->cur_input->used_len <= sizeof(dummy));
+
+            periscope_purge_and_checkpoint_request();
+            periscope_restore_request();
+
+            chkpt_trials--;
+            if (chkpt_trials == 0) {
+                num_dirty_pages += DIRTY_PAGE_RANGE_INCR;
+                chkpt_trials = RESTORE_TRIALS;
+            }
+
+            if (num_dirty_pages > DIRTY_PAGE_RANGE_MAX) {
+                num_dirty_pages = DIRTY_PAGE_RANGE_BEGIN;
+                profiler_mode = PERISCOPE_PROFILE_RESTORE;
+            }
+        } else {
+            periscope_restore_request();
+        }
+        break;
+
+    case PERISCOPE_PROFILE_RESTORE:
+        if (ensure_dirty_pages(num_dirty_pages, &num_real_dirty_pages)) {
+            printf("periscope: benchmark-restore %d dirty pages\n",
+                   num_real_dirty_pages);
+
+            periscope_restore_request();
+
+            restore_trials--;
+            if (restore_trials == 0) {
+                num_dirty_pages += DIRTY_PAGE_RANGE_INCR;
+                restore_trials = RESTORE_TRIALS;
+            }
+
+            if (num_dirty_pages > DIRTY_PAGE_RANGE_MAX) {
+                num_dirty_pages = DIRTY_PAGE_RANGE_BEGIN;
+                profiler_mode = -1;
+            }
+        } else {
+            periscope_restore_request();
+        }
+        break;
+
+    case PERISCOPE_PROFILE_BASELINE:
+        // make sure these are turned off for baseline benchmarking
+        periscope_no_loadvm_state_setup = false;
+        periscope_no_loadvm_state_cleanup = false;
+
+        if (baseline_trials > 0) {
+            snapshot_and_restore_request();
+            baseline_trials--;
+            break;
+        }
+        profiler_mode = -1;
+        break;
+
+    default:
+        qemu_system_shutdown_request(SHUTDOWN_CAUSE_GUEST_RESET);
+        break;
+    }
+}
+
+void start_profiler(int type, Error **errp)
+{
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    profiler_type = type;
+
+    switch (profiler_type) {
+#define PROF_MICRO 0
+#define PROF_BASELINE 1
+    case PROF_MICRO:
+        profiler_mode = PERISCOPE_PROFILE_CHECKPOINT;
+        break;
+    case PROF_BASELINE:
+        profiler_mode = PERISCOPE_PROFILE_BASELINE;
+        periscope_delta_snapshot = false;
+        periscope_save_ram_only = false;
+        periscope_no_loadvm_state_setup = false;
+        periscope_no_loadvm_state_cleanup = false;
+        quick_snapshot = false;
+        quick_reset_devs = false;
+        quick_reset_ram = false;
+        break;
+    }
+
+    s->mode = PERISCOPE_MODE_PROFILER;
+    s->mmio_read = NULL;
+    s->fetch_next = fetch_next;
+    s->get_cur = NULL;
+    s->cur_executed = NULL;
+    s->restored = NULL;
+    s->should_restore = NULL;
+    s->guest_crashed = NULL;
+    s->get_stat = NULL;
+
+    printf("periscope: profiler initialized\n");
+}
diff --git migration/periscope-syzkaller.c migration/periscope-syzkaller.c
new file mode 100644
index 0000000000..bc889116cc
--- /dev/null
+++ migration/periscope-syzkaller.c
@@ -0,0 +1,922 @@
+#include "qemu/osdep.h"
+
+#include "migration/ram.h"
+#include "qapi/error.h"
+#include "qom/cpu.h"
+#include "sysemu/kvm.h"
+
+#include <sys/shm.h>
+
+#include "migration/periscope.h"
+
+static int chkpt_disable_after_nth = 0; // one-indexed
+
+#define CHKPT_TIME_THRESHOLD_MS 500
+#define CHKPT_TIME_THRESHOLD_MULTIPLIER 2
+
+static uint64_t chkpt_time_threshold_ms = CHKPT_TIME_THRESHOLD_MS;
+
+#define CHKPT_COV_THRESHOLD 1500
+//#define CHKPT_COV_THRESHOLD 500
+
+static uint64_t last_chkpt_ms = 0;
+static int chkpt_policy = PERISCOPE_CHKPT_TIME_ONLY; // default policy
+static int restore_policy = PERISCOPE_RESTORE_LONGEST;
+
+static uint8_t
+    last_execute_req_input[sizeof(struct syzkaller_execute_req) + kMaxInput];
+
+static uint64_t call_to_input_pos[30 * 10];
+
+// TODO(dokyungs): later this can be merged into periscope.c, which other
+// fuzzer backends can also benefit from.
+uint64_t syzkaller_maybe_checkpoint(uint64_t input_pos, uint64_t cov_size)
+{
+    uint64_t now = qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL);
+    uint64_t time_since_last_chkpt_ms = now - last_chkpt_ms;
+
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+    assert(fs->cur_cp);
+    fs->cur_cp->exec_time.tv_sec = time_since_last_chkpt_ms / 1000UL;
+    fs->cur_cp->exec_time.tv_usec =
+        (time_since_last_chkpt_ms % 1000UL) * 1000UL;
+
+//#define TRACE_CHKPT_POLICY
+#ifdef TRACE_CHKPT_POLICY
+    printf("periscope: call_num=%d input_pos=0x%lx cov_size=%lu "
+           "time_since_last_chkpt=%lums\n", call_num,
+           input_pos, cov_size, time_since_last_chkpt_ms);
+#endif
+
+    bool should_chkpt = true;
+    int call_num = 0;
+
+    switch (chkpt_policy) {
+    case PERISCOPE_CHKPT_TIME_AND_COV:
+        should_chkpt &= (cov_size > CHKPT_COV_THRESHOLD);
+        should_chkpt &= (time_since_last_chkpt_ms > chkpt_time_threshold_ms);
+        break;
+    case PERISCOPE_CHKPT_TIME_ONLY:
+        should_chkpt &= (time_since_last_chkpt_ms > chkpt_time_threshold_ms);
+        break;
+    case PERISCOPE_CHKPT_DISABLED:
+        should_chkpt = false;
+        break;
+    case PERISCOPE_CHKPT_TIME_ONLY_DISABLED_AFTER_NTH:
+        call_num = 0;
+
+        for (int i=0; i<sizeof(call_to_input_pos)/sizeof(call_to_input_pos[0]); i++) {
+            if (call_to_input_pos[i] == 0) {
+                break;
+            }
+
+            if (input_pos == call_to_input_pos[i]) {
+                printf("periscope: call_num=%d input_pos=0x%lx\n", i, call_to_input_pos[i]);
+                call_num = i;
+                break;
+            }
+        }
+
+        if (chkpt_disable_after_nth < call_num) {
+            printf("periscope: chkpt disabled for call %d (>%d)\n",
+                   call_num, chkpt_disable_after_nth);
+            should_chkpt = false;
+        } else {
+            should_chkpt &= (time_since_last_chkpt_ms > chkpt_time_threshold_ms);
+        }
+        break;
+    default:
+        printf("periscope: unknown checkpoint policy\n");
+        break;
+    }
+
+    if (should_chkpt == true) {
+        printf("periscope: policy %d requests checkpoint\n", chkpt_policy);
+
+        FuzzerState *fs = fuzzer_get_current();
+        assert(fs);
+
+        uint32_t len = sizeof(struct syzkaller_execute_req) + input_pos;
+
+        // used from full-length
+        assert(fs->cur_input);
+        fs->cur_input->used_len = len;
+
+        // delta from base
+        uint32_t len_base = 0;
+        assert(fs->cur_cp);
+        periscope_cp_desc *parent = fs->cur_cp->parent;
+        while (parent != NULL) {
+            len_base += parent->len;
+            parent = parent->parent;
+        }
+        assert(len > len_base);
+        fs->cur_cp->len = len - len_base;
+
+        memcpy(fs->cur_cp->io, last_execute_req_input + len_base,
+               fs->cur_cp->len);
+
+        if (periscope_purge_and_checkpoint_request() == 0) {
+            // reset chkpt counter
+            last_chkpt_ms = now;
+            // exponentially increasing intervals
+            chkpt_time_threshold_ms *= CHKPT_TIME_THRESHOLD_MULTIPLIER;
+            return 0; // SUCCESS
+        }
+    }
+
+    return -1;
+}
+
+static bool read_virtual_memory(uint64_t address, uint8_t *data, uint32_t size,
+                                CPUState *cpu)
+{
+    uint8_t tmp_buf[TARGET_PAGE_SIZE];
+    MemTxAttrs attrs;
+    hwaddr phys_addr;
+    int asidx;
+    uint64_t counter, l;
+    int i = 0;
+
+    counter = size;
+
+    while (counter != 0) {
+        l = TARGET_PAGE_SIZE;
+        if (l > counter)
+            l = counter;
+
+        asidx = cpu_asidx_from_attrs(cpu, MEMTXATTRS_UNSPECIFIED);
+        attrs = MEMTXATTRS_UNSPECIFIED;
+        phys_addr = cpu_get_phys_page_attrs_debug(
+            cpu, (address & TARGET_PAGE_MASK), &attrs);
+
+        phys_addr += (address & ~TARGET_PAGE_MASK);
+
+        printf("periscope: paddr=0x%lx for vaddr=0x%lx l=0x%lx\n", phys_addr,
+               address, l);
+
+        address_space_rw(cpu_get_address_space(cpu, asidx), phys_addr,
+                         MEMTXATTRS_UNSPECIFIED, tmp_buf, l, false);
+
+        memcpy(data + (i * TARGET_PAGE_SIZE), tmp_buf, l);
+
+        i++;
+        address += l;
+        counter -= l;
+    }
+
+    return true;
+}
+
+static bool write_virtual_memory(uint64_t address, uint8_t *data, uint32_t size,
+                                 CPUState *cpu)
+{
+    int asidx;
+    MemTxAttrs attrs;
+    hwaddr phys_addr;
+    MemTxResult res;
+
+    uint64_t counter, l, i;
+
+    counter = size;
+    while (counter != 0) {
+        l = TARGET_PAGE_SIZE;
+        if (l > counter)
+            l = counter;
+
+        asidx = cpu_asidx_from_attrs(cpu, MEMTXATTRS_UNSPECIFIED);
+        attrs = MEMTXATTRS_UNSPECIFIED;
+        phys_addr = cpu_get_phys_page_attrs_debug(
+            cpu, (address & TARGET_PAGE_MASK), &attrs);
+
+        if (phys_addr == -1) {
+            printf("periscope: failed to get paddr for vaddr=0x%lx\n", address);
+            return false;
+        }
+
+        phys_addr += (address & ~TARGET_PAGE_MASK);
+
+        printf("periscope: paddr=0x%lx for vaddr=0x%lx l=0x%lx\n", phys_addr,
+               address, l);
+
+        res = address_space_rw(cpu_get_address_space(cpu, asidx), phys_addr,
+                               MEMTXATTRS_UNSPECIFIED, data, l, true);
+        if (res != MEMTX_OK) {
+            printf("periscope: failed to write to vaddr=0x%lx paddr=0x%lx\n",
+                   address, phys_addr);
+            return false;
+        }
+
+        i++;
+        data += l;
+        address += l;
+        counter -= l;
+    }
+
+    return true;
+}
+
+static int kInPipeFd = -1;
+static int kOutPipeFd = -1;
+
+#define kInMagic (uint64_t)0xbadc0ffeebadface
+#define kOutMagic (uint32_t)0xbadf00d
+#define kCrashMagic (uint32_t)0xbadcbadc
+
+void syzkaller_reply_handshake(void)
+{
+    printf("periscope: replying handshake\n");
+
+    struct syzkaller_handshake_reply reply = {};
+    reply.magic = kOutMagic;
+
+    if (write(kOutPipeFd, &reply, sizeof(reply)) != sizeof(reply))
+        printf("periscope: syz-fuzzer control pipe write failed\n");
+}
+
+void syzkaller_reply_execute_crash(void)
+{
+    struct syzkaller_execute_reply repl = {};
+    printf("periscope: syz-fuzzer reply execute crash size=%lu\n",
+           sizeof(repl));
+
+    repl.magic = kCrashMagic;
+    repl.done = true;
+    repl.status = 0;
+
+    if (write(kOutPipeFd, &repl, sizeof(repl)) != sizeof(repl))
+        printf("periscope: syz-fuzzer control pipe write failed\n");
+}
+
+void syzkaller_reply_execute(uint32_t status)
+{
+    struct syzkaller_execute_reply repl = {};
+    printf("periscope: syz-fuzzer reply execute status=%d size=%lu\n", status,
+           sizeof(repl));
+
+    bool killed = false;
+    if (status == 1) {
+        killed = true;
+        status = 0;
+    }
+
+    repl.magic = kOutMagic;
+    repl.done = true;
+    repl.status = status;
+
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+    assert(fs->cur_cp);
+    uint64_t now = qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL);
+    qemu_timeval elapsed;
+    elapsed.tv_sec = (now - last_chkpt_ms) / 1000;
+    elapsed.tv_usec = ((now - last_chkpt_ms) % 1000) * 1000;
+    memcpy(&fs->cur_cp->exec_time, &elapsed, sizeof(qemu_timeval));
+
+    for (int stat = 0; stat < stat_count; stat++) {
+        if (stat == stat_killed) {
+            repl.stats[stat] = killed ? 1 : 0;
+            continue;
+        }
+        uint32_t v = periscope_get_stat(stat);
+        repl.stats[stat] = v;
+    }
+
+    if (write(kOutPipeFd, &repl, sizeof(repl)) != sizeof(repl))
+        printf("periscope: syz-fuzzer control pipe write failed\n");
+}
+
+void syzkaller_receive_handshake(CPUState *cpu, uint64_t addr)
+{
+    // printf("periscope: syz-fuzzer receive handshake kInPipe=%d,
+    // addr=0x%lx\n", kInPipeFd, addr);
+
+    struct syzkaller_handshake_req req = {};
+
+    if (read_virtual_memory(addr, (uint8_t *)&req, sizeof(req), cpu) == false) {
+        printf("periscope: mem tx failed\n");
+        return;
+    }
+
+    for (unsigned i = 0; i < sizeof(req); i++) {
+        if (*((uint8_t *)&req + i) != 0xdc) {
+            printf("periscope: buffer sanity check failed\n");
+            exit(1);
+        }
+    }
+
+    int n = read(kInPipeFd, &req, sizeof(req));
+    if (n != sizeof(req)) {
+        printf("periscope: handshake read failed: %d", n);
+        return;
+    }
+
+    printf("periscope: syz-fuzzer receive handshake (magic=0x%lx)\n",
+           req.magic);
+
+#if 1
+    bool res = write_virtual_memory(addr, (uint8_t *)&req, sizeof(req), cpu);
+    if (res == false) {
+        printf("periscope: mem tx failed %d\n", res);
+        return;
+    }
+#else
+    RAMBlock *block = qemu_ram_block_by_name("pc.ram");
+    if (!block) {
+        printf("periscope: could not find ramblock\n");
+        return;
+    }
+    struct syzkaller_handshake_req *dst =
+        host_from_ram_block_offset(block, addr);
+    if (!dst) {
+        printf("periscope: could not find offset=0x%lx in ramblock", addr);
+        return;
+    }
+    memcpy(dst, &req, sizeof(req));
+#endif
+
+    printf("periscope: syz-fuzzer receive handshake (size=%lu)\n", sizeof(req));
+}
+
+/*
+ * executor input buffer parsing logic
+ */
+typedef unsigned char uint8;
+typedef unsigned long long uint64;
+
+static char *input_data;
+
+#define kMaxArgs 9
+#define kFailStatus 67
+
+static void fail(const char *msg, ...)
+{
+    int e = errno;
+    va_list args;
+    va_start(args, msg);
+#if 0
+	printk(msg, args);
+#else
+    vfprintf(stderr, msg, args);
+#endif
+    va_end(args);
+    fprintf(stderr, " (errno %d)\n", e);
+    exit(kFailStatus);
+}
+
+static unsigned long long procid;
+
+#define kMaxCommands 1000
+
+#define instr_eof -1
+#define instr_copyin -2
+#define instr_copyout -3
+#define instr_nextcall -4
+
+#define arg_const 0
+#define arg_result 1
+#define arg_data 2
+#define arg_csum 3
+
+#define binary_format_native 0
+#define binary_format_bigendian 1
+#define binary_format_strdec 2
+#define binary_format_strhex 3
+#define binary_format_stroct 4
+
+struct res_t {
+    bool executed;
+    uint64 val;
+};
+
+static uint64 read_input(uint64 **input_posp /*, bool peek*/)
+{
+    uint64 *input_pos = *input_posp;
+    if ((char *)input_pos >= input_data + kMaxInput)
+        fail("input command overflows input %p: [%p:%p)", input_pos, input_data,
+             input_data + kMaxInput);
+    // if (!peek)
+    *input_posp = input_pos + 1;
+    return *input_pos;
+}
+
+#ifdef DEBUG_CALL
+static void debug_call(uint64 call_num, uint64 *args, int num_args)
+{
+    printf("periscope: syscall #%lld (", call_num);
+    for (int i = 0; i < num_args; i++) {
+        if (i != 0)
+            printf(", ");
+        printf("0x%llx", (uint64)args[i]);
+    }
+    printf(")\n");
+}
+#endif
+
+static void read_execute_req(uint8 *out_buf, uint64 *out_len,
+                             uint32_t *out_num_calls)
+{
+    struct syzkaller_execute_req *req = (struct syzkaller_execute_req *)out_buf;
+    assert(req != NULL);
+
+    uint8 *input = out_buf + sizeof(struct syzkaller_execute_req);
+    assert(input != NULL);
+
+    // printf("periscope: read execute req\n");
+
+    int n = read(kInPipeFd, req, sizeof(struct syzkaller_execute_req));
+    if (n != sizeof(struct syzkaller_execute_req)) {
+        printf("periscope: read execute req failed: %d\n", n);
+        return;
+    }
+
+    if (req->magic != kInMagic) {
+        printf("periscope: read execute req magic value incorrect 0x%lx\n",
+               req->magic);
+    }
+
+    procid = req->pid;
+
+    // printf("periscope: syz-fuzzer receive execute (magic=0x%lx)\n",
+    // req.magic);
+
+    // checkpoint and restore policy determination before execution based on
+    // the hints provided by syz-fuzzer
+    bool flag_triage = req->exec_flags & (1 << 6);
+    bool flag_minimize = req->exec_flags & (1 << 7);
+    bool flag_minimize_retry = req->exec_flags & (1 << 8);
+    bool flag_fuzz = req->exec_flags & (1 << 9);
+    bool flag_generate = req->exec_flags & (1 << 10);
+    bool flag_smash = req->exec_flags & (1 << 11);
+
+    uint64_t mutated_from_nth = req->mut_from_nth;
+
+    // cleanup any auxiliary flags (e.g., hint flags) not affecting test case
+    // execution by any means
+    req->exec_flags &= ((uint64)(1 << 6) - 1);
+    req->mut_from_nth = 0;
+
+    assert(req->prog_size == 0);
+
+    printf("periscope: t=%d m=%d mr=%d, f=%d g=%d s=%d exec_flags=0x%lx\n",
+           flag_triage, flag_minimize, flag_minimize_retry, flag_fuzz,
+           flag_generate, flag_smash, req->exec_flags);
+
+    chkpt_disable_after_nth = 0;
+
+    if (flag_triage) {
+        chkpt_policy = PERISCOPE_CHKPT_TIME_ONLY;
+
+        // restore to root to help determine flaky coverage signals; this is to
+        // preserve intended functionality of the triaging process
+        restore_policy = PERISCOPE_RESTORE_LONGEST;
+    } else if (flag_minimize) {
+        if (flag_minimize_retry) {
+            chkpt_policy = PERISCOPE_CHKPT_TIME_ONLY;
+            restore_policy = PERISCOPE_RESTORE_LONGEST;
+        } else {
+            chkpt_policy = PERISCOPE_CHKPT_TIME_ONLY;
+            restore_policy = PERISCOPE_RESTORE_LONGEST;
+        }
+    } else if (flag_fuzz || flag_smash) {
+        if (mutated_from_nth > 0) {
+            chkpt_policy = PERISCOPE_CHKPT_TIME_ONLY_DISABLED_AFTER_NTH;
+            chkpt_disable_after_nth = mutated_from_nth;
+            restore_policy = PERISCOPE_RESTORE_LONGEST;
+            printf("periscope: disable chkpt after %dth\n",
+                   chkpt_disable_after_nth);
+        } else {
+            chkpt_policy = PERISCOPE_CHKPT_DISABLED;
+            restore_policy = PERISCOPE_RESTORE_LONGEST;
+            printf("periscope: disable chkpt\n");
+        }
+    } else if (flag_generate) {
+        chkpt_policy = PERISCOPE_CHKPT_DISABLED;
+        restore_policy = PERISCOPE_RESTORE_LONGEST;
+    } else {
+        // conservative default
+        chkpt_policy = PERISCOPE_CHKPT_DISABLED;
+        restore_policy = PERISCOPE_RESTORE_ROOT;
+    }
+
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+
+    MemoryRegion *mr = fs->mr[0];
+    assert(mr);
+
+    // determine program size for chkpt search & potential chkpt
+    input_data = memory_region_get_ram_ptr(
+        mr); // ensure nobody else is modifying this region concurrently.
+    if (input_data) {
+        uint64 *input_pos = (uint64 *)input_data;
+        *out_num_calls = 0;
+
+        for (;;) {
+            uint64 call_num = read_input(&input_pos);
+            // printf("periscope: pos=0x%lx call_num=0x%llx\n",
+            //        (char *)input_pos - input_data, call_num);
+
+            if (call_num == instr_nextcall) {
+                uint64 next_call = read_input(&input_pos);
+                // printf("periscope: pos=0x%lx next_call=0x%llx\n",
+                //        (char *)input_pos - input_data, next_call*8);
+                call_to_input_pos[*out_num_calls] = (uint64_t)input_pos - (uint64_t)input_data;
+                call_to_input_pos[*out_num_calls+1] = 0;
+
+                input_pos += next_call;
+                if (next_call > 0)
+                    *out_num_calls += 1;
+                continue;
+            }
+
+            if (call_num == instr_eof) {
+                uint64 len = (char *)input_pos - input_data;
+                printf("periscope: %llu bytes (instr_eof after %d calls)\n",
+                       len, *out_num_calls);
+
+                memcpy(input, input_data, len);
+                *out_len = sizeof(struct syzkaller_execute_req) + len;
+                break;
+            }
+
+            // must be unreachable
+            assert(false);
+        }
+    }
+}
+
+void syzkaller_receive_execute(CPUState *cpu, uint64_t addr)
+{
+    printf("periscope: syz-fuzzer receive execute (addr=0x%lx)\n", addr);
+
+    struct syzkaller_execute_req req = {};
+    if (read_virtual_memory(addr, (uint8_t *)&req, sizeof(req), cpu) == false) {
+        printf("periscope: mem tx failed\n");
+        return;
+    }
+
+    if (req.magic != 0xfefefefefefefefe) {
+        printf("periscope: wrong execute_req.magic=0x%lx\n", req.magic);
+        exit(1);
+    }
+
+#if 1
+    bool res = write_virtual_memory(addr, last_execute_req_input,
+                                    sizeof(struct syzkaller_execute_req), cpu);
+
+    if (res == false) {
+        printf("periscope: syz-fuzzer receive exeucte mem tx failed %d\n", res);
+    }
+#else
+    RAMBlock *block = qemu_ram_block_by_name("pc.ram");
+    if (!block) {
+        printf("periscope: could not find ramblock\n");
+        return;
+    }
+
+    struct syzkaller_execute_req *dst = host_from_ram_block_offset(block, addr);
+    if (!dst) {
+        printf("periscope: could not find offset=0x%lx in ramblock", addr);
+        return;
+    }
+    memcpy(dst, &req, sizeof(req));
+#endif
+
+    // printf("periscope: syz-fuzzer receive execute (size=%lu)\n",
+    // sizeof(req));
+}
+
+struct syzkaller_forksrv_ctx {
+    uint32_t magic; // expected to be kOutMagic
+    uint64_t start;
+    uint64_t last_executed;
+
+    // TODO
+};
+
+static uint64_t forksrv_ctx_ptr = 0UL;
+
+void syzkaller_submit_forkserver_context(uint64_t ptr)
+{
+    printf("periscope: submit forkserver context ptr=0x%lx\n", ptr);
+
+    forksrv_ctx_ptr = ptr;
+}
+
+#if 0
+static void update_forkserver_context(struct syzkaller_forksrv_ctx *ctx,
+                                      CPUState *cpu)
+{
+    if (forksrv_ctx_ptr == 0UL) {
+        printf("periscope: no fork server context submitted\n");
+        return;
+    }
+
+    // TODO: check magic byte is equal to kOutMagic
+
+    write_virtual_memory(forksrv_ctx_ptr, (uint8_t *)ctx,
+                         sizeof(struct syzkaller_forksrv_ctx), cpu);
+}
+#endif
+
+static int mmio_read(unsigned size, uint64_t *out) { return -1; }
+
+static void restored(void)
+{
+    // reset timer
+    last_chkpt_ms = qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL);
+
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+    assert(fs->cur_input);
+    assert(fs->cur_input->restored_cp);
+    int level = 0;
+    periscope_cp_desc *cp = fs->cur_input->restored_cp;
+    while (cp != NULL) {
+        level++;
+        cp = cp->parent;
+    }
+
+    // reset chkpt time threshold
+    chkpt_time_threshold_ms = CHKPT_TIME_THRESHOLD_MS;
+    level--;
+    while (level > 0) {
+        chkpt_time_threshold_ms *= CHKPT_TIME_THRESHOLD_MULTIPLIER;
+        level--;
+    }
+}
+
+// return buffer should be prefixed by `syzkaller_execute_req` to make sure that
+// all environment/configuration vars are taken into account when performing a
+// prefix match.
+static char *fetch_next(uint32_t *len)
+{
+    // printf("periscope: syz fetch next\n");
+
+    uint64 buf_len = 0;
+    uint32_t num_calls = 0;
+    read_execute_req(last_execute_req_input, &buf_len, &num_calls);
+
+    if (restore_policy == PERISCOPE_RESTORE_ROOT) {
+        *len = sizeof(struct syzkaller_execute_req);
+        return (char *)last_execute_req_input;
+    }
+
+    *len = buf_len;
+
+    return (char *)last_execute_req_input;
+}
+
+static int mgr_pipe_st;
+static int mgr_pipe_ctl;
+
+static bool should_restore(void)
+{
+    int nread;
+    int res;
+    if (mgr_pipe_ctl < -1) {
+        printf("periscope: syz-manager no ctl pipe found\n");
+        return false;
+    }
+
+#if 0
+    if (mgr_pipe_st < -1) {
+        printf("periscope: syz-manager no st pipe found\n");
+        return false;
+    }
+
+    int val = 0xbadf00d;
+    if ((res = write(mgr_pipe_st, &val, 4)) != 4) {
+        printf("periscope: syz-manager pipe write failed\n");
+    }
+#endif
+
+    nread = read(mgr_pipe_ctl, &res, 4);
+    if (nread == -1) {
+        printf("periscope: syz-manager did not request restore yet\n");
+        return false;
+    }
+    if (nread != 4) {
+        printf("periscope: syz-manager sent wrong # of bytes\n");
+        return false;
+    }
+
+    if (res != 0xdeadf00d) {
+        return false;
+    }
+
+    printf("periscope: syz-manager requested restore\n");
+
+    return true;
+}
+
+static int st_pipe;
+static int ctl_pipe;
+static char *shm_ptr = NULL;
+static int shm_id;
+
+void periscope_syzkaller_send_addr_offset(uint64_t offset)
+{
+    // TODO overflow check
+    uint32_t val = (uint32_t)offset;
+    int res;
+
+    printf("periscope: writing to status pipe\n");
+    return;
+
+    if ((res = write(st_pipe, &val, 4)) != 4) {
+        printf("periscope: write to status pipe failed\n");
+    }
+
+    // printf("periscope: reading from control pipe\n");
+
+    if ((res = read(ctl_pipe, &val, 4)) != 4) {
+        printf("periscope: read from control pipe failed\n");
+    }
+
+    if (val > 0) {
+        printf("periscope: val=0x%x\n", val);
+    }
+}
+
+void periscope_syzkaller_notify_boot(void)
+{
+    uint32_t res, val;
+    val = 0xbeeff00d;
+    // notify manager
+    if (mgr_pipe_st > 0) {
+        if ((res = write(mgr_pipe_st, &val, 4)) != 4) {
+            printf("periscope: syzkaller notify boot failed\n");
+        }
+    }
+    // notify fuzzer
+    if (kOutPipeFd > 0) {
+        if ((res = write(kOutPipeFd, &val, 4)) != 4) {
+            printf("periscope: syzkaller notify boot failed\n");
+        }
+    }
+    printf("periscope: syzkaller notify boot\n");
+}
+
+static int guest_crashed(void)
+{
+    int res;
+    int val = 0xdeadf00d;
+
+    // suspend VM for restore
+    bool should_suspend_on_crash = periscope_snapshot_inited();
+
+    printf("periscope: guest crashed %d %d\n", periscope_snapshot_inited(),
+           periscope_total_execs());
+
+    if (should_suspend_on_crash) {
+        val = 0xbadf00d;
+    }
+
+    // inform manager about suspension
+    if (mgr_pipe_st < -1) {
+        printf("periscope: syz-manager no st pipe found\n");
+        return 0;
+    }
+
+    if ((res = write(mgr_pipe_st, &val, 4)) != 4) {
+        printf("periscope: syz-manager crash signalling failed\n");
+        return 0;
+    }
+
+    if (should_suspend_on_crash) {
+        // let fuzzer know
+        syzkaller_reply_execute_crash();
+
+        return PERISCOPE_GUEST_SUSPEND;
+    }
+
+    // otherwise, restart VM
+    return 0;
+}
+
+static bool get_stat(int stat, uint32_t *statVal)
+{
+    FuzzerState *fs = fuzzer_get_current();
+
+    if (!fs || !fs->cur_input) {
+        return false;
+    }
+
+    return false;
+}
+
+void start_syzkaller_fuzzer(const char *uri, int in_st_pipe, int in_ctl_pipe,
+                            const char *in_mgr_pipe, int in_shm_id,
+                            Error **errp)
+{
+    printf("periscope: initializing syz-fuzzer io channels\n");
+
+    char tmp[1024];
+    if (uri) {
+        strncpy(tmp, uri, strlen(uri));
+
+        char *tok;
+        tok = strtok(tmp, ",");
+        if (!tok)
+            return;
+
+        st_pipe = strtol(tok, NULL, 0);
+
+        tok = strtok(NULL, ",");
+        if (!tok)
+            return;
+
+        ctl_pipe = strtol(tok, NULL, 0);
+
+        tok = strtok(NULL, ",");
+        if (!tok)
+            return;
+
+        shm_id = strtol(tok, NULL, 0);
+    } else {
+        st_pipe = in_st_pipe;
+        ctl_pipe = in_ctl_pipe;
+        shm_id = in_shm_id;
+
+        if (in_mgr_pipe) {
+            memcpy(tmp, in_mgr_pipe, strlen(in_mgr_pipe) + 1);
+            tmp[strlen(in_mgr_pipe) - 1] = '0';
+            mgr_pipe_st = open(tmp, O_WRONLY);
+            if (mgr_pipe_st < 0) {
+                printf("periscope: mgr_pipe %s open failed\n", tmp);
+            }
+            tmp[strlen(in_mgr_pipe) - 1] = '1';
+            mgr_pipe_ctl = open(tmp, O_RDONLY);
+            if (mgr_pipe_ctl < 0) {
+                printf("periscope: mgr_pipe %s open failed\n", tmp);
+            }
+        }
+    }
+
+    if (st_pipe == -1 || ctl_pipe == -1)
+        return;
+
+    if (shm_id > -1) {
+        int kCoverSize = 256 << 10;
+        shm_ptr = mmap(NULL, kCoverSize * sizeof(uintptr_t) * 2,
+                       PROT_READ | PROT_WRITE, MAP_SHARED, shm_id, 0);
+        if (shm_ptr != MAP_FAILED) {
+            printf("periscope: syz-fuzzer shm (id=%d, ptr=%p) initialized\n",
+                   shm_id, shm_ptr);
+        } else {
+            printf("periscope: syz-fuzzer mmap failed\n");
+        }
+    }
+
+    // int res;
+    // int magic_value;
+    // if ((res = read(ctl_pipe, &magic_value, 4)) != 4) {
+    //     printf("periscope: syz-fuzzer magic value=0x%x\n", magic_value);
+    // }
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    s->mode = PERISCOPE_MODE_SYZKALLER_USBFUZZER;
+    s->mmio_read = mmio_read;
+    s->fetch_next = fetch_next;
+    s->get_cur = NULL;
+    s->cur_executed = NULL;
+    s->restored = restored;
+    s->should_restore = should_restore;
+    s->guest_crashed = guest_crashed;
+    s->get_stat = get_stat;
+
+    // pipe sanity check
+    uint32_t res, val;
+    if ((res = read(ctl_pipe, &val, 4)) != 4) {
+        printf("periscope: syz-fuzzer read from control pipe failed\n");
+    }
+
+    if (val == 0xdeadf00d) {
+        // if (shm_ptr != MAP_FAILED && *((uint32_t *)shm_ptr) == 0xbeefbeef)
+        printf("periscope: syz-fuzzer handshake successful\n");
+    } else {
+        printf("periscope: syz-fuzzer handshake failed 0x%x 0x%x\n", val,
+               *shm_ptr);
+
+        // TODO: exit?
+    }
+
+    // TODO: probably create another set of pipes for in/out pipes?
+    kInPipeFd = ctl_pipe;
+    kOutPipeFd = st_pipe;
+
+#if 0
+    val = 0xbeeff00d;
+    if ((res = write(kOutPipeFd, &val, 4)) != 4) {
+        printf("periscope: syz-fuzzer write to out pipe failed\n");
+    }
+#endif
+
+    printf("periscope: syz-fuzzer io channels (st=%d, ctl=%d) initialized\n",
+           st_pipe, ctl_pipe);
+}
diff --git migration/periscope-timers.c migration/periscope-timers.c
new file mode 100644
index 0000000000..455a50405d
--- /dev/null
+++ migration/periscope-timers.c
@@ -0,0 +1,96 @@
+#include "periscope-timers.h"
+
+#ifdef PERISCOPE_TIMERS
+static QLIST_HEAD( ,peri_timer) peri_timers =
+    QLIST_HEAD_INITIALIZER(peri_timers);
+
+static unsigned long long cntr = 0;
+
+static peri_timer* find_ptimer(const char* name)
+{
+   peri_timer *pt;
+   QLIST_FOREACH(pt, &peri_timers, list) {
+      if(strcmp(name, pt->name) == 0) return pt;
+   }
+   return NULL;
+
+}
+
+int add_timer(const char* name)
+{
+   peri_timer *pt = find_ptimer(name);
+   if(pt != NULL) {
+      printf("Warning timer %s already active\n", name);
+      return -1;
+   }
+   pt = g_malloc(sizeof(peri_timer));
+   pt->started = 0;
+   pt->name = g_malloc(strlen(name));
+   strcpy(pt->name, name);
+   pt->fp = fopen(name, "w");
+   if(!pt->fp) {
+      printf("Failed to open %s\n", name);
+      g_free(pt->name);
+      g_free(pt);
+      return -1;
+   }
+   QLIST_INSERT_HEAD(&peri_timers, pt, list);
+   return 0;
+}
+
+int remove_timer(const char* name)
+{
+   peri_timer *pt = find_ptimer(name);
+   if(pt == NULL) {
+      printf("Warning timer %s not active\n", name);
+      return -1;
+   }
+   QLIST_REMOVE(pt, list);
+   fclose(pt->fp);
+   g_free(pt->name);
+   g_free(pt);
+   return 0;
+}
+
+peri_timer* start_interval(const char* name)
+{
+   peri_timer *pt = find_ptimer(name);
+   if(pt == NULL) {
+      printf("Warning timer %s not active\n", name);
+      return NULL;
+   }
+   if(pt->started) {
+      printf("Warning timer %s already started\n", name);
+      return NULL;
+   }
+   pt->started = 1;
+   qemu_gettimeofday(&pt->t0);
+   return pt;
+}
+
+int stop_interval(peri_timer* pt)
+{
+   qemu_timeval elapsed;
+   char buf[256];
+   if(!pt->started) {
+      printf("Warning timer %s not started\n", pt->name);
+      return -1;
+   }
+   qemu_gettimeofday(&pt->t1);
+   timersub(&pt->t1, &pt->t0, &elapsed);
+   snprintf(buf, 256, "%llu %llu\n", cntr++, elapsed.tv_sec * 1000000ULL + elapsed.tv_usec);
+   fwrite(buf, strlen(buf), 1, pt->fp);
+   fflush(pt->fp);
+   pt->started = 0;
+   return 0;
+}
+
+void pt_mark_all(const char *mark)
+{
+   peri_timer *pt;
+   QLIST_FOREACH(pt, &peri_timers, list) {
+      fwrite(mark, strlen(mark), 1, pt->fp);
+      fflush(pt->fp);
+   }
+}
+#endif
diff --git migration/periscope-timers.h migration/periscope-timers.h
new file mode 100644
index 0000000000..e961934541
--- /dev/null
+++ migration/periscope-timers.h
@@ -0,0 +1,35 @@
+#ifndef PERISCOPE_TIMERS_H
+#define PERISCOPE_TIMERS_H
+
+#include <stdio.h>
+#include "qemu/osdep.h"
+#include "sysemu/sysemu.h"
+
+//#define PERISCOPE_TIMERS
+
+struct peri_timer;
+typedef struct peri_timer {
+   char* name;
+   qemu_timeval t0;
+   qemu_timeval t1;
+   char started;
+   FILE* fp;
+   QLIST_ENTRY(peri_timer) list;
+} peri_timer;
+
+#ifdef PERISCOPE_TIMERS
+int add_timer(const char* name);
+int remove_timer(const char* name);
+peri_timer* start_interval(const char* name);
+int stop_interval(peri_timer* pt);
+void pt_mark_all(const char *mark);
+#else
+static inline int add_timer(const char* name) { return 0;}
+static inline int remove_timer(const char* name) {return 0;}
+static inline peri_timer* start_interval(const char* name) {return NULL;}
+static inline int stop_interval(peri_timer* pt) {return 0;}
+static inline void pt_mark_all(const char *mark) {}
+#endif
+
+
+#endif
diff --git migration/periscope.c migration/periscope.c
new file mode 100644
index 0000000000..91cb4bde0e
--- /dev/null
+++ migration/periscope.c
@@ -0,0 +1,3632 @@
+#include "qemu/osdep.h"
+
+#include "hw/boards.h"
+#include "qemu/cutils.h"
+#include "qapi/error.h"
+
+#include <stdlib.h>
+#include <unistd.h>
+#include <stdbool.h>
+
+#include "hw/pci/pci.h"
+#include "qemu-common.h"
+#include "block/snapshot.h"
+#include "migration/snapshot.h"
+#include "migration/global_state.h"
+#include "hw/hw.h"
+#include "sysemu/cpus.h"
+#include "sysemu/sysemu.h"
+#include "qemu/rcu.h"
+#include "qemu-file-channel.h"
+#include "io/channel-file.h"
+#include "io/channel-buffer.h"
+#include "io/channel-util.h"
+#include "migration/migration.h"
+#include "migration/savevm.h"
+#include "migration/qemu-file.h"
+#include "migration/ram.h"
+
+#include "trace.h"
+#include "periscope.h"
+#include "hw/periscope/kcov_vdev.h"
+#include "hw/periscope/pci.h"
+
+#include "cpu.h"
+#include "exec/ram_addr.h"
+#include "exec/address-spaces.h"
+#include "migration/periscope_perf_switches.h"
+#include "migration/periscope-timers.h"
+#include "migration/periscope-delta-snap.h"
+
+// see comments in snaphost
+// #include "migration/periscope_perf_switches.h"
+bool quick_snapshot;
+bool quick_reset_devs;
+bool quick_reset_ram;
+
+// This will disable storing of all ram sections
+// not individual pages but the whole section
+// it is only checked in migration/savevm.c
+bool dev_only_snapshot = false;
+
+bool periscope_no_loadvm_state_setup;
+bool periscope_no_loadvm_state_cleanup;
+
+static bool snapshot_inited = false;
+// enable only creation of root checkpoint
+static bool root_only_chkpt = false;
+static bool no_restore = false;
+
+static bool single_exec = false;
+
+static uint32_t max_used_len = 0;
+static uint32_t max_irqs = 0;
+static uint32_t max_io_reads = 0;
+static qemu_timeval max_exec_time = {0, 0};
+//static qemu_timeval max_restore_time = {0, 0};
+static qemu_timeval max_chkpt_time = {0, 0};
+static qemu_timeval last_chkpt_time = {0, 0};
+static qemu_timeval last_restore_time = {0, 0};
+
+static int total_execs = 0;
+int periscope_total_execs(void)
+{
+    return total_execs;
+}
+
+static int total_non_root_restores = 0;
+static int total_chkpts = 0;
+
+static qemu_timeval total_exec_time = {0, 0};
+static qemu_timeval total_restore_time = {0, 0};
+static qemu_timeval total_chkpt_time = {0, 0};
+static qemu_timeval total_chkpt_saving_time = {0, 0};
+
+static void print_time_consumption_statistics(void) {
+    uint64_t exec_ms = total_exec_time.tv_sec * 1000L + total_exec_time.tv_usec / 1000L;
+    uint64_t restore_ms = total_restore_time.tv_sec * 1000L + total_restore_time.tv_usec / 1000L;
+    uint64_t chkpt_ms = total_chkpt_time.tv_sec * 1000L + total_chkpt_time.tv_usec / 1000L;
+    uint64_t sum_ms = exec_ms + restore_ms + chkpt_ms;
+    uint64_t chkpt_saving_ms = total_chkpt_saving_time.tv_sec * 1000L + total_chkpt_saving_time.tv_usec / 1000L;
+
+    printf("periscope: %d execs %lu ms (%.1f%%), %d restores (%d non-root) %lu ms (%.1f%%), %d chkpts %lu ms (%.1f%%) to save %lu ms\n",
+           total_execs, exec_ms, (float)exec_ms/sum_ms*100,
+           total_execs, total_non_root_restores, restore_ms, (float)restore_ms/sum_ms*100,
+           total_chkpts, chkpt_ms, (float)chkpt_ms/sum_ms*100, chkpt_saving_ms);
+}
+
+#define SNAPSHOT_INVALID 0
+#define SNAPSHOT_ROOT_ID 1
+#define MAX_SNAPSHOT_ID INT_MAX
+
+// TODO: Exponential/Linear/Adaptive back-off to handle
+// drivers putting itself on a sleep?
+#define MMIO_RESPONSE_TIMEOUT 100 // ms
+
+// We want to give the guest OS some time to schedule
+// whatever bottom-half handler the driver uses to process
+// an interrupt in full.
+#define INTERRUPT_RESPONSE_TIMEOUT 100 // ms
+
+enum TimeoutReason {
+    TIMEOUT_UNKNOWN = -1,
+    TIMEOUT_RESTORE,
+    TIMEOUT_CHECKPOINT,
+    TIMEOUT_MMIO,
+    TIMEOUT_INTERRUPT,
+};
+
+static int timed_out = 0;
+
+static int timeout_reason = TIMEOUT_UNKNOWN;
+
+static int next_snapshot_id = SNAPSHOT_ROOT_ID;
+
+static periscope_cp_desc cp_root = {
+    .len = 0,
+    .n_children = 0,
+    .parent = NULL, // root does not have a parent
+    .closed = false, // root will be closed at the first checkpoint
+    .snapshot = {
+        .id = SNAPSHOT_ROOT_ID,
+#ifndef PERI_DEDUP
+        .memfd = -1,
+        .memfd_quick = -1,
+        .memfd_ram = -1,
+        .buf_quick = NULL,
+        .buf_ram = NULL,
+        .dirty = NULL,
+        .npages = 0,
+#else
+        .buf_dev = NULL,
+        .dev_sz = 0,
+        .peri_rb = NULL,
+        .n_peri_rb = 0,
+#endif
+
+    }
+};
+
+static periscope_input_desc root = {
+    .input = NULL,
+    .len = 0,
+    .used_len = 0,
+    .num_irqs = 0,
+    .num_io_reads = 0,
+    .base_cp = NULL,
+};
+
+static int __periscope_purge_and_checkpoint_request(bool do_request);
+#ifdef ENABLE_LW_CHKPT
+static int close_cp_desc(periscope_cp_desc *cpd, uint16_t snapid, int memfd, int memfd_quick, unsigned long dirty[], unsigned long npages);
+#else
+static int close_cp_desc(periscope_cp_desc *cpd, uint16_t snapid, int memfd, int memfd_quick);
+#endif
+static int delete_cp_desc(periscope_cp_desc *cpd);
+static periscope_cp_desc *create_cp_desc(periscope_cp_desc *parent);
+
+static uint32_t mlen(char* a, char *b, uint32_t a_len, uint32_t b_len) {
+    uint32_t i;
+    for(i=0; i<a_len && i<b_len; ++i) {
+        if(a[i] != b[i])
+            return i;
+    }
+    return i;
+}
+
+static periscope_cp_desc *get_longest_match(char *ref, uint32_t reflen,
+                                            uint32_t *matched_len,
+                                            periscope_cp_desc *node)
+{
+    uint32_t ml_node = mlen(node->io, ref, node->len, reflen);
+
+    // if there is no full match, no need to look at children
+    if (ml_node != node->len) {
+        *matched_len = 0;
+        return NULL;
+    }
+
+    // if there are no children, return the full match
+    if (node->n_children == 0) {
+        *matched_len = ml_node;
+        return node;
+    }
+
+    // search children
+    uint32_t ml_child;
+    periscope_cp_desc *child;
+    periscope_cp_desc *match;
+    for (int i = 0; i < node->n_children; ++i) {
+        child = node->children[i];
+        assert(child != NULL);
+
+        match = get_longest_match(&ref[ml_node], reflen - ml_node, &ml_child,
+                                  child);
+        if (match != NULL) {
+            break;
+        }
+    }
+
+    // no match found, return current node
+    if (match == NULL) {
+        *matched_len = ml_node;
+        return node;
+    }
+
+    *matched_len = ml_node + ml_child;
+
+    return match;
+}
+
+//#define FULL_DELTA_RESTORE
+//#define FULL_SNAPSHOT_RESTORE
+
+static periscope_cp_desc *periscope_find_closest_snapshot(
+    char *next, uint32_t next_len, periscope_input_desc *cur, uint32_t *matched_len) {
+
+    assert(next != NULL);
+    assert(cur != NULL);
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+    assert(s->root != NULL);
+
+    periscope_cp_desc* max_cp = get_longest_match(next, next_len, matched_len, &cp_root);
+
+#define TRACE_SNAPSHOT_SEARCH
+#undef TRACE_SNAPSHOT_SEARCH
+
+#ifdef TRACE_SNAPSHOT_SEARCH
+    printf("Best match %p snap id %d, len %d\n", max_cp, max_cp->snapshot.id, *matched_len);
+#endif
+
+    assert(max_cp->snapshot.id > 0);
+
+    // Mark this checkpoint and its parents used.
+    periscope_cp_desc* cp = max_cp;
+    while (cp != NULL) {
+        cp->num_restored++;
+        qemu_gettimeofday(&cp->last_restored);
+        cp = cp->parent;
+    }
+
+#ifdef FULL_SNAPSHOT_RESTORE
+    return &cp_root;
+#else
+    return max_cp;
+#endif
+}
+
+#if 0
+#ifdef ENABLE_LW_CHKPT
+static int periscope_ram_checkpoint(char *name, size_t *sz) {
+    int ret;
+    Error *err = NULL;
+    int memfd = memfd_create(name, 0);
+    int dupfd = dup(memfd);
+    QIOChannelFile *iochannel = qio_channel_file_new_fd(dupfd);
+    QEMUFile *file = qemu_fopen_channel_output(QIO_CHANNEL(iochannel));
+    object_unref(OBJECT(iochannel));
+
+    periscope_save_ram_only = true;
+    ret = qemu_savevm_state(file, &err);
+    periscope_save_ram_only = false;
+
+    if(ret != 0) {
+      printf("%s: ERR %d\n", __FUNCTION__, ret);
+      return -1;
+    }
+    qemu_fflush(file);
+    if (sz) {
+        *sz = qemu_ftell(file);
+        printf("periscope: ram chkpt sz=%lu\n", *sz);
+    }
+    qemu_fclose(file);
+    return memfd;
+}
+#endif
+
+static int periscope_quick_checkpoint(char *name, size_t *sz) {
+    int ret;
+    Error *err = NULL;
+    int memfd = memfd_create(name, 0);
+    int dupfd = dup(memfd);
+    QIOChannelFile *iochannel = qio_channel_file_new_fd(dupfd);
+    QEMUFile *file = qemu_fopen_channel_output(QIO_CHANNEL(iochannel));
+    object_unref(OBJECT(iochannel));
+
+    global_state_store_running();
+    quick_snapshot = true;
+    ret = qemu_savevm_state(file, &err);
+    quick_snapshot = false;
+
+    if(ret != 0) {
+      printf("%s: ERR %d\n", __FUNCTION__, ret);
+      return -1;
+    }
+    qemu_fflush(file);
+    if (sz) {
+        *sz = qemu_ftell(file);
+        printf("periscope: dev chkpt sz=%lu\n", *sz);
+    }
+    qemu_fclose(file);
+    return memfd;
+}
+#endif
+
+#ifdef PERI_DEDUP
+static uint8_t *periscope_quick_checkpoint(char *name, size_t *sz) {
+    int ret;
+    Error *err = NULL;
+    QIOChannelBuffer *iochannel_quick = qio_channel_buffer_new(32*1024*1024);
+    assert(iochannel_quick);
+    QEMUFile *file_quick = qemu_fopen_channel_output(QIO_CHANNEL(iochannel_quick));
+    assert(file_quick);
+    object_unref(OBJECT(iochannel_quick));
+
+    //int memfd_ram = -1;
+    //QIOChannelBuffer *iochannel_ram = qio_channel_buffer_new(8000*TARGET_PAGE_SIZE+32*1024*1024);
+    //QEMUFile *file_ram = qemu_fopen_channel_output(QIO_CHANNEL(iochannel_ram));
+    //object_unref(OBJECT(iochannel_ram));
+
+
+    global_state_store_running();
+    // This will disable storing of all ram sections
+    // not individual pages but the whole section
+    // it is only checked in migration/savevm.c
+    dev_only_snapshot = true;
+    //ret = qemu_savevm_state(file_quick, &err);
+    ret = periscope_qemu_savevm_state(NULL, file_quick, &err);
+    dev_only_snapshot = false;
+
+    if(ret != 0) {
+      printf("%s: ERR %d\n", __FUNCTION__, ret);
+      return NULL;
+    }
+
+    qemu_fflush(file_quick);
+    size_t file_quick_sz = qemu_ftell(file_quick);
+    printf("periscope: dev checkpoint %lu KiB\n", file_quick_sz/1024UL);
+    if (sz) {
+        *sz = file_quick_sz;
+    }
+
+    uint8_t *buf_quick = g_realloc(qio_channel_buffer_close_without_free(iochannel_quick), file_quick_sz);
+    iochannel_quick = NULL;
+    qemu_fclose(file_quick);
+    file_quick = NULL;
+
+    return buf_quick;
+}
+#endif
+
+
+static uint64_t last_chkpt_fixed_sz = 0;
+static uint64_t chkpt_memory_used = 0UL;
+
+static uint64_t compute_memory_cost(periscope_cp_desc *cp)
+{
+    assert(cp != NULL);
+    uint64_t cost_kb = cp->len/1024UL;
+#ifdef PERI_DEDUP
+    cost_kb += cp->snapshot.dev_sz/1024UL;
+    cost_kb += compute_prb_cost(cp->snapshot.peri_rb, cp->snapshot.n_peri_rb)/1024UL;
+#else /* PERI_DEDUP */
+    cost_kb += cp->snapshot.quick_sz/1024UL;
+    cost_kb += cp->snapshot.ram_sz/1024UL;
+#ifdef DBG_RAM_STORED // set in periscope.h
+    cost_kb += (cp->snapshot.rambkp_size / 1024UL);
+#endif
+#endif
+    return cost_kb;
+}
+
+#ifdef DBG_RAM_STORED // set in periscope.h
+static unsigned long copy_rambkp(void **rambkp) {
+   rcu_read_lock();
+   RAMBlock *rb = qemu_ram_block_by_name("pc.ram");
+   assert(rb);
+   unsigned long rambkp_size = rb->max_length;
+   if(*rambkp == NULL) {
+      *rambkp = g_malloc(rambkp_size);
+   }
+   assert(*rambkp);
+   memcpy(*rambkp, rb->host, rambkp_size);
+   rcu_read_unlock();
+   return rambkp_size;
+}
+
+static bool compare_ram_pages(void* ram0, void *ram1,
+      unsigned long mem_size,
+      unsigned long* dirty,
+      bool dirty_only) {
+    //bool no_diff = true;
+    unsigned long n_diff = 0;
+    rcu_read_lock();
+    if(ram1 == NULL || ram0 == NULL) {
+       RAMBlock *rb = qemu_ram_block_by_name("pc.ram");
+       assert(rb);
+       if(ram1 == NULL) ram1 = rb->host;
+       else if(ram0 == NULL) ram0 = rb->host;
+       assert(mem_size == rb->max_length);
+    }
+    assert(ram1);
+    assert(ram0);
+
+    for(unsigned long addr=0; addr < mem_size; addr+=TARGET_PAGE_SIZE) {
+       bool is_dirty = dirty != NULL && test_bit(addr >> TARGET_PAGE_BITS, dirty) != 0;
+       if(dirty_only && !is_dirty) continue;
+       if(memcmp(ram0 + addr, ram1 + addr, TARGET_PAGE_SIZE) != 0) {
+          printf("DIFF %d %lx\n", is_dirty, addr);
+          //no_diff = false;
+          n_diff++;
+       }
+    }
+    rcu_read_unlock();
+    //return no_diff;
+    printf("#diff pages %ld\n", n_diff);
+    // There are always changes due to wall clock
+    return n_diff < 4;
+}
+#endif
+
+int periscope_checkpoint(uint64_t id) {
+    Error *err = NULL;
+    int ret;
+
+    char pt_mark_buf[256];
+    snprintf(pt_mark_buf, 256, "## %s\n", __FUNCTION__);
+    pt_mark_all(pt_mark_buf);
+
+    if (id >= MAX_SNAPSHOT_ID) {
+        printf("periscope: too many snapshots > %d\n", MAX_SNAPSHOT_ID);
+        return -1;
+    }
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+#ifdef DBG_RAM_STORED // set in periscope.h
+    if(s->cur_cp->parent) {
+       unsigned long *dirtytmp;
+       unsigned long npagestmp = get_current_delta_bm(&dirtytmp);
+       unsigned long *inv_dirty = bitmap_new(npagestmp);
+       bitmap_complement(inv_dirty, dirtytmp, npagestmp);
+       printf("---------- comparing all non dirty pages (%ld) pc.ram to last restored %d\n",
+             bitmap_count_one(inv_dirty, npagestmp), s->cur_cp->parent->snapshot.id);
+       assert(compare_ram_pages(s->cur_cp->parent->snapshot.rambkp, NULL,
+                s->cur_cp->parent->snapshot.rambkp_size, inv_dirty, true));
+       g_free(inv_dirty);
+       g_free(dirtytmp);
+    }
+#endif
+
+    char name[50];
+    char qname[50];
+    char ramname[50];
+    switch (s->mode) {
+    case PERISCOPE_MODE_AFL:
+        sprintf(name, "periscope-%ld", id);
+        sprintf(qname, "periscope-q-%ld", id);
+        sprintf(ramname, "periscope-r-%ld", id);
+        break;
+    case PERISCOPE_MODE_COVERAGE:
+        sprintf(name, "periscope-cov");
+        sprintf(qname, "periscope-cov-q");
+        sprintf(ramname, "periscope-cov-r");
+        break;
+    case PERISCOPE_MODE_SYZKALLER_USBFUZZER:
+        sprintf(name, "periscope-syz-%ld", id);
+        sprintf(qname, "periscope-syz-q-%ld", id);
+        sprintf(ramname, "periscope-syz-r-%ld", id);
+        break;
+    default:
+        printf("periscope: unknown mode\n");
+        sprintf(name, "periscope-unknown");
+        break;
+    }
+
+    qemu_timeval chkpt_begin, chkpt_end;
+    qemu_gettimeofday(&chkpt_begin);
+
+#ifdef ENABLE_LW_CHKPT
+    unsigned long *dirty = NULL;
+    unsigned long npages = 0;
+#endif
+
+    if (id == SNAPSHOT_ROOT_ID) {
+        BlockDriverState *bs;
+        ret = bdrv_all_find_snapshot(name, &bs);
+
+        if (ret == 0) {
+            bdrv_all_delete_snapshot(name, &bs, &err);
+        }
+
+        //if (ret < 0) {
+            printf("periscope: checkpointing %s (bdrv)...\n", name);
+
+            // qemu_timeval tv1, tv2;
+            // qemu_gettimeofday(&tv1);
+
+            ret = save_snapshot(name, &err);
+            if (ret < 0) {
+                printf("periscope: save snapshot failed\n");
+            }
+
+            // qemu_gettimeofday(&tv2);
+            // tv2.tv_sec -= tv1.tv_sec;
+            // tv2.tv_usec -= tv1.tv_usec;
+        //}
+
+#ifdef ENABLE_LW_CHKPT
+#ifndef PERI_DEDUP
+        MachineState *machine = MACHINE(qdev_get_machine());
+        assert(machine != NULL);
+        npages = machine->ram_size / TARGET_PAGE_SIZE;
+        dirty = bitmap_new(npages);
+        bitmap_fill(dirty, npages); // root snapshot has to be reset completely
+        update_and_clear_delta_snap_bm(NULL);
+    } else {
+        //npages = get_current_delta_bm(&dirty);
+        npages = update_and_clear_delta_snap_bm(&dirty);
+#endif /* PERI_DEDUP */
+#endif /* ENABLE_LW_CHKPT */
+    }
+
+#define FULL_CHKPT
+#undef FULL_CHKPT
+#ifdef FULL_CHKPT
+    MachineState *machine = MACHINE(qdev_get_machine());
+    assert(machine != NULL);
+    npages = machine->ram_size / TARGET_PAGE_SIZE;
+    bitmap_fill(dirty, npages);
+#endif
+
+#ifndef ENABLE_LW_CHKPT
+    int memfd = memfd_create(name, 0);
+    int dupfd = dup(memfd);
+
+    printf("periscope: checkpointing %s (memfd=%d, dupfd=%d)...\n",
+        name,
+        memfd,
+        dupfd
+    );
+
+    QIOChannelFile *iochannel = qio_channel_file_new_fd(dupfd);
+    QEMUFile *file = qemu_fopen_channel_output(QIO_CHANNEL(iochannel));
+    object_unref(OBJECT(iochannel));
+#endif
+
+#ifndef ENABLE_LW_CHKPT
+    peri_timer *pt = NULL;
+    pt = start_interval("periscope_checkpoint.timer");
+    ret = qemu_savevm_state(file, &err);
+    stop_interval(pt);
+    //ret = qemu_savevm_state_live(file, &err);
+    qemu_fflush(file);
+    qemu_fclose(file);
+    file = NULL;
+
+#else /* ENABLE_LW_CHKPT */
+#ifdef PERI_DEDUP
+    int memfd_ram = -1;
+    int memfd_quick = -1;
+    unsigned long num_dirty_pages = 0;
+    size_t dev_sz = 0;
+    //s->cur_cp->snapshot.peri_rb = NULL;
+    //s->cur_cp->snapshot.n_peri_rb = 0;
+    if (id != SNAPSHOT_ROOT_ID) {
+       assert(s->cur_cp->snapshot.peri_rb == NULL);
+       assert(s->cur_cp->snapshot.n_peri_rb == 0);
+       int n_peri_rb = create_prb_and_clear_delta_bm(&s->cur_cp->snapshot.peri_rb, &num_dirty_pages, id);
+       while(n_peri_rb < 0) {
+          printf("create_prb_and_clear_delta_bm failed, purging an retrying\n");
+          int ret = __periscope_purge_and_checkpoint_request(false);
+          assert(ret == 0);
+          n_peri_rb = create_prb_and_clear_delta_bm(&s->cur_cp->snapshot.peri_rb, &num_dirty_pages, id);
+       }
+       s->cur_cp->snapshot.n_peri_rb = n_peri_rb;
+    } else {
+       s->cur_cp->snapshot.n_peri_rb = create_prb_and_fill(&s->cur_cp->snapshot.peri_rb, &num_dirty_pages, id, true);
+    }
+    uint8_t *buf_dev = periscope_quick_checkpoint(qname, &dev_sz);
+    assert(buf_dev);
+    assert(dev_sz > 0);
+    s->cur_cp->snapshot.buf_dev = buf_dev;
+    s->cur_cp->snapshot.dev_sz = dev_sz;
+
+
+#else /* !PERI_DEDUP */
+    unsigned long num_dirty_pages = bitmap_count_one(dirty, npages);
+    update_delta_snap_bm(dirty, npages);
+
+#ifdef DBG_RAM_STORED // set in periscope.h
+    printf("---------- copy ram backup for chkpt %d\n", s->cur_cp->snapshot.id);
+    s->cur_cp->snapshot.rambkp_size = copy_rambkp(&s->cur_cp->snapshot.rambkp);
+#endif
+
+    int memfd_ram = -1;
+    QIOChannelBuffer *iochannel_ram = qio_channel_buffer_new(num_dirty_pages*TARGET_PAGE_SIZE+32*1024*1024);
+    QEMUFile *file_ram = qemu_fopen_channel_output(QIO_CHANNEL(iochannel_ram));
+    object_unref(OBJECT(iochannel_ram));
+
+    int memfd_quick = -1;
+    QIOChannelBuffer *iochannel_quick = qio_channel_buffer_new(32*1024*1024);
+    QEMUFile *file_quick = qemu_fopen_channel_output(QIO_CHANNEL(iochannel_quick));
+    object_unref(OBJECT(iochannel_quick));
+
+    ret = periscope_qemu_savevm_state(file_ram, file_quick, &err);
+
+    if (ret != 0) {
+      printf("%s: ERR %d\n", __FUNCTION__, ret);
+      return -1;
+    }
+
+    qemu_fflush(file_ram);
+    size_t file_ram_sz = qemu_ftell(file_ram);
+    printf("periscope: iterable checkpoint %lu KiB\n", file_ram_sz/1024UL);
+
+    qemu_fflush(file_quick);
+    size_t file_quick_sz = qemu_ftell(file_quick);
+    printf("periscope: non-iterable checkpoint %lu KiB\n", file_quick_sz/1024UL);
+
+    unsigned long *dirty_new;
+    //update_and_clear_delta_snap_bm(&dirty_new);
+    get_current_delta_bm(&dirty_new);
+    unsigned long n_dirty_new = bitmap_count_one(dirty_new, npages);
+    unsigned long *bm_and = bitmap_new(npages);
+    bitmap_and(bm_and, dirty, dirty_new, npages);
+    unsigned long n_and = bitmap_count_one(bm_and, npages);
+    printf("periscope: %d new bits during checkpoint creation, (%d) part of old bitmap\n", n_dirty_new, n_and);
+    g_free(dirty_new);
+    g_free(bm_and);
+
+    assert(n_dirty_new == 0 || n_and == n_dirty_new);
+#endif /* PERI_DEDUP */
+#endif /* ENABLE_LW_CHKPT */
+
+    qemu_gettimeofday(&chkpt_end);
+
+    qemu_timeval chkpt_time;
+    timersub(&chkpt_end, &chkpt_begin, &chkpt_time);
+    if (id != SNAPSHOT_ROOT_ID) {
+       last_chkpt_time.tv_sec = chkpt_time.tv_sec;
+       last_chkpt_time.tv_usec = chkpt_time.tv_usec;
+    }
+    // stat
+    timeradd(&chkpt_time, &total_chkpt_time, &total_chkpt_time);
+    if (id != SNAPSHOT_ROOT_ID && timercmp(&chkpt_time, &max_chkpt_time, >)) {
+        printf("periscope: new max chkpt time %lu ms\n",
+               chkpt_time.tv_sec * 1000L + chkpt_time.tv_usec / 1000L);
+        max_chkpt_time.tv_sec = chkpt_time.tv_sec;
+        max_chkpt_time.tv_usec = chkpt_time.tv_usec;
+    }
+
+    total_chkpts += 1;
+
+    if (ret < 0) {
+        printf("periscope: save vm state failed ret=%d\n", ret);
+        return ret;
+    }
+
+    if (id == SNAPSHOT_ROOT_ID) {
+        snapshot_inited = true;
+    }
+
+#ifdef ENABLE_LW_CHKPT
+    if (close_cp_desc(s->cur_cp, id, memfd_ram, memfd_quick, dirty, npages) != 0) {
+#else
+    if (close_cp_desc(s->cur_cp, id, memfd, memfd_quick) != 0) {
+#endif
+        printf("periscope: failed to close checkpoint\n");
+        return -1;
+    }
+
+#ifndef PERI_DEDUP
+    s->cur_cp->snapshot.ram_sz = file_ram_sz;
+    s->cur_cp->snapshot.quick_sz = file_quick_sz;
+
+    uint8_t *buf_ram = qio_channel_buffer_close_without_free(iochannel_ram);
+    s->cur_cp->snapshot.buf_ram = g_realloc(buf_ram, file_ram_sz);
+    //s->cur_cp->snapshot.buf_ram = g_malloc(file_ram_sz);
+    //memcpy(s->cur_cp->snapshot.buf_ram, iochannel_ram->data, file_ram_sz);
+    iochannel_ram = NULL;
+    qemu_fclose(file_ram);
+    file_ram = NULL;
+
+    uint8_t *buf_quick = qio_channel_buffer_close_without_free(iochannel_quick);
+    s->cur_cp->snapshot.buf_quick = g_realloc(buf_quick, file_quick_sz);
+    //s->cur_cp->snapshot.buf_quick = g_malloc(file_quick_sz);
+    //memcpy(s->cur_cp->snapshot.buf_quick, iochannel_quick->data, file_quick_sz);
+    iochannel_quick = NULL;
+    qemu_fclose(file_quick);
+    file_quick = NULL;
+
+#ifdef ENABLE_LW_CHKPT
+    if (dirty)
+        g_free(dirty);
+#endif
+#endif /* !PERI_DEDUP */
+
+    // update checkpoint memory usage
+    chkpt_memory_used += compute_memory_cost(s->cur_cp);
+
+    // approx. size of fixed memory usage
+    last_chkpt_fixed_sz = 0;
+#ifndef PERI_DEDUP
+    if (file_ram_sz > (num_dirty_pages * TARGET_PAGE_SIZE)) {
+        last_chkpt_fixed_sz += file_ram_sz - num_dirty_pages * TARGET_PAGE_SIZE;
+    }
+    last_chkpt_fixed_sz += file_quick_sz;
+#else /* PERI_DEDUP */
+    unsigned long prb_cost = compute_prb_cost(s->cur_cp->snapshot.peri_rb, s->cur_cp->snapshot.n_peri_rb);
+    uint64_t dirty_cost = compute_dirty_cost(num_dirty_pages);
+    if (prb_cost > dirty_cost) {
+        last_chkpt_fixed_sz += prb_cost - dirty_cost;
+    }
+    last_chkpt_fixed_sz += dev_sz;
+#endif
+
+    // logging
+    printf("periscope: checkpoint created (%lu ms): ",
+           chkpt_time.tv_sec * 1000L + chkpt_time.tv_usec / 1000L);
+
+    periscope_cp_desc *cp = s->cur_cp;
+    while (cp != NULL) {
+        printf("[#%u, %u B, %lu MiB, %lu ms, %u chld] ",
+               cp->snapshot.id, cp->len, compute_memory_cost(cp) / 1024UL,
+               cp->exec_time.tv_sec * 1000L + cp->exec_time.tv_usec / 1000L,
+               cp->n_children);
+        if (cp != &cp_root)
+            printf("<- ");
+        cp = cp->parent;
+    }
+    printf("\n");
+
+    print_time_consumption_statistics();
+
+#if 0 // savevm sometimes changes pc.ram
+#ifdef DBG_RAM_STORED // set in periscope.h
+    printf("---------- comparing new chktp %d to pc.ram\n", s->cur_cp->snapshot.id);
+    assert(compare_ram_pages(s->cur_cp->snapshot.rambkp, NULL, s->cur_cp->snapshot.rambkp_size, NULL, false));
+#endif
+#endif
+
+#ifdef DBG_RAM_STORED // set in periscope.h
+    if(s->cur_cp->parent) {
+       unsigned long *inv_dirty = bitmap_new(npages);
+       bitmap_complement(inv_dirty, s->cur_cp->snapshot.dirty, npages);
+       printf("---------- comparing all non dirty pages (%ld) of new chktp %d to parent %d\n",
+             bitmap_count_one(inv_dirty, npages), s->cur_cp->snapshot.id, s->cur_cp->parent->snapshot.id);
+       assert(compare_ram_pages(s->cur_cp->snapshot.rambkp, s->cur_cp->parent->snapshot.rambkp,
+                s->cur_cp->snapshot.rambkp_size, inv_dirty, true));
+       g_free(inv_dirty);
+    }
+#endif
+
+    s->cur_input->base_cp = s->cur_cp;
+    s->cur_cp = create_cp_desc(s->cur_cp);
+
+    if (!periscope_restore_requested())
+        vm_start();
+
+    return 0;
+}
+
+static int checkpoint_request = 0;
+
+#define CHKPT_TESTING
+#undef CHKPT_TESTING
+
+static uint64_t calc_total_time_saved(periscope_cp_desc *cpd) {
+    uint64_t exec_time_ms = 0;
+
+    periscope_cp_desc *cp = cpd;
+    while (cp != NULL) {
+        exec_time_ms +=
+            cp->exec_time.tv_sec * 1000L + cp->exec_time.tv_usec / 1000L;
+        cp = NULL;
+        // cp = cp->parent;
+    }
+
+    return cpd->num_restored * exec_time_ms;
+}
+
+static uint64_t get_exec_time_ms(periscope_cp_desc *cpd) {
+    uint64_t exec_time_ms = 0;
+
+    while (cpd != NULL) {
+        exec_time_ms +=
+            cpd->exec_time.tv_sec * 1000L + cpd->exec_time.tv_usec / 1000L;
+        cpd = cpd->parent;
+    }
+
+    return exec_time_ms;
+}
+
+#define MAX_CANDIDATES 1024
+
+typedef struct periscope_cp_candidates {
+    periscope_cp_desc *cps[MAX_CANDIDATES];
+    int num_cps;
+} periscope_cp_candidates;
+
+typedef struct periscope_cp_policy {
+    const char *name;
+    int (*find_replacement_candidates)(periscope_cp_candidates *);
+} periscope_cp_policy;
+
+#if 0
+static int cp_compare_always_replace(periscope_cp_desc *old_cp,
+                                     periscope_cp_desc *new_cp)
+{
+    return -1;
+}
+
+static periscope_cp_desc *cp_find_lowest_time_saver(periscope_cp_desc *cpd) {
+    assert(cpd != NULL);
+
+    if (cpd->n_children == 0) {
+        return cpd;
+    }
+
+    uint64_t lowest_time_saved = UINT64_MAX;
+    periscope_cp_desc *lowest_time_saver = NULL;
+
+    // Lowest among children, which recursively return the lowest of their children
+    for (int i=0; i<cpd->n_children; ++i) {
+        periscope_cp_desc *child = cpd->children[i];
+        child = cp_find_lowest_time_saver(child);
+        uint64_t time_saved = calc_total_time_saved(child);
+        if (time_saved <= lowest_time_saved) {
+            lowest_time_saved = time_saved;
+            lowest_time_saver = child;
+        }
+    }
+
+    return lowest_time_saver;
+}
+#endif
+
+static int cp_find_non_active_nodes(periscope_cp_candidates *candidates)
+{
+    assert(candidates);
+    assert(candidates->num_cps > 0);
+
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+    assert(fs->cur_input);
+
+    periscope_cp_desc *active = fs->cur_input->base_cp;
+    assert(active);
+
+    for (int i=0; i<candidates->num_cps; i++) {
+        const periscope_cp_desc *cur = candidates->cps[i];
+        assert(cur != NULL);
+
+        if (cur == active) {
+            candidates->cps[i] = candidates->cps[candidates->num_cps-1];
+            candidates->num_cps--;
+            candidates->cps[candidates->num_cps] = NULL;
+            break;
+        }
+    }
+
+    return candidates->num_cps;
+}
+
+static int cp_level(const periscope_cp_desc *cpd)
+{
+    int level = 0;
+    while (cpd != &cp_root) {
+        level++;
+        cpd = cpd->parent;
+    }
+    return level;
+}
+
+static int cp_cmp_level(const void *a, const void *b)
+{
+    const periscope_cp_desc *const *cp_a = a;
+    const periscope_cp_desc *const *cp_b = b;
+
+    return cp_level(*cp_b) - cp_level(*cp_a);
+}
+
+static int cp_find_last_level_leafs(periscope_cp_candidates *candidates)
+{
+    if (candidates->num_cps > 1)
+        qsort(candidates->cps, candidates->num_cps, sizeof(candidates->cps[0]),
+              cp_cmp_level);
+
+    for (int i=0; i<candidates->num_cps - 1; i++) {
+        const periscope_cp_desc *cur = candidates->cps[i];
+        assert(cur != NULL);
+        const periscope_cp_desc *next = candidates->cps[i+1];
+        assert(next != NULL);
+
+        if (cp_level(cur) == cp_level(next)) {
+            continue;
+        }
+
+        candidates->num_cps = i + 1;
+    }
+
+    return candidates->num_cps;
+}
+
+#ifdef EVICT_LRU_LAST_RESTORED
+static int cp_cmp_last_restored(const void *a, const void *b)
+{
+    const periscope_cp_desc *const *cp_a = a;
+    const periscope_cp_desc *const *cp_b = b;
+
+    if (timercmp(&(*cp_a)->last_restored, &(*cp_b)->last_restored, <)) {
+        return -1;
+    }
+    else if (timercmp(&(*cp_a)->last_restored, &(*cp_b)->last_restored, >)) {
+        return 1;
+    }
+    return 0;
+}
+#else
+static int cp_cmp_last_used(const void *a, const void *b)
+{
+    const periscope_cp_desc *const *cp_a = a;
+    const periscope_cp_desc *const *cp_b = b;
+
+    const qemu_timeval *last_used_a = &(*cp_a)->closed_time;
+    if ( (*cp_a)->num_restored > 0 ) {
+        last_used_a = &(*cp_a)->last_restored;
+    }
+    const qemu_timeval *last_used_b = &(*cp_b)->closed_time;
+    if ( (*cp_a)->num_restored > 0 ) {
+        last_used_b = &(*cp_b)->last_restored;
+    }
+
+    if (timercmp(last_used_a, last_used_b, <)) {
+        return -1;
+    }
+    else if (timercmp(last_used_a, last_used_b, >)) {
+        return 1;
+    }
+    return 0;
+}
+#endif
+
+static int cp_find_least_recently_used(periscope_cp_candidates *candidates)
+{
+    assert(candidates);
+    assert(candidates->num_cps > 0);
+
+    if (candidates->num_cps > 1)
+        qsort(candidates->cps, candidates->num_cps, sizeof(candidates->cps[0]),
+#ifdef EVICT_LRU_LAST_RESTORED
+              cp_cmp_last_restored
+#else
+              cp_cmp_last_used
+#endif
+        );
+
+#if 0
+    printf("periscope: LRU [#%d]", candidates->cps[0]->snapshot.id);
+    for (int i=0; i<candidates->num_cps - 1; i++) {
+        const periscope_cp_desc *cur = candidates->cps[i];
+        assert(cur != NULL);
+        const periscope_cp_desc *next = candidates->cps[i+1];
+        assert(next != NULL);
+
+        qemu_timeval sub;
+        timersub(&next->last_restored, &cur->last_restored, &sub);
+        printf(" [#%d] (%lu ms)", next->snapshot.id,
+               sub.tv_sec * 1000UL + sub.tv_usec / 1000UL);
+
+    }
+    printf("\n");
+#endif
+
+    for (int i=0; i<candidates->num_cps - 1; i++) {
+        const periscope_cp_desc *cur = candidates->cps[i];
+        assert(cur != NULL);
+        const periscope_cp_desc *next = candidates->cps[i+1];
+        assert(next != NULL);
+
+#ifdef EVICT_LRU_LAST_RESTORED
+        if (timercmp(&cur->last_restored, &next->last_restored, ==)) {
+#else
+        const qemu_timeval *last_used_a = &cur->closed_time;
+        if ( cur->num_restored > 0 ) {
+            last_used_a = &cur->last_restored;
+        }
+        const qemu_timeval *last_used_b = &next->closed_time;
+        if ( next->num_restored > 0 ) {
+            last_used_b = &next->last_restored;
+        }
+        if (timercmp(last_used_a, last_used_b, ==)) {
+#endif
+            continue;
+        }
+
+        candidates->num_cps = i + 1;
+    }
+
+    return candidates->num_cps;
+}
+
+#ifdef EVICT_FIFO
+static int cp_cmp_closed_time(const void *a, const void *b)
+{
+    const periscope_cp_desc *const *cp_a = a;
+    const periscope_cp_desc *const *cp_b = b;
+
+    if (timercmp(&(*cp_a)->closed_time, &(*cp_b)->closed_time, <)) {
+        return -1;
+    }
+    else if (timercmp(&(*cp_a)->closed_time, &(*cp_b)->closed_time, >)) {
+        return 1;
+    }
+    return 0;
+}
+
+static int cp_find_least_recently_created(periscope_cp_candidates *candidates)
+{
+    assert(candidates);
+    assert(candidates->num_cps > 0);
+
+    if (candidates->num_cps > 1)
+        qsort(candidates->cps, candidates->num_cps, sizeof(candidates->cps[0]),
+              cp_cmp_closed_time);
+
+    for (int i=0; i<candidates->num_cps - 1; i++) {
+        const periscope_cp_desc *cur = candidates->cps[i];
+        assert(cur != NULL);
+        const periscope_cp_desc *next = candidates->cps[i+1];
+        assert(next != NULL);
+
+        if (timercmp(&cur->closed_time, &next->closed_time, ==)) {
+            continue;
+        }
+
+        candidates->num_cps = i + 1;
+
+    }
+
+    return candidates->num_cps;
+}
+#endif
+
+#if defined(PERI_DEDUP) && !defined(PERI_DEDUP_NOHASH)
+#define UNIQUENESS_PERC 0.85f
+static int cmp_uniqueness(const void *a, const void *b) {
+    const periscope_cp_desc *const *cp_a = a;
+    const periscope_cp_desc *const *cp_b = b;
+    //unsigned int ua = compute_prb_freed((*cp_a)->snapshot.peri_rb);
+    //unsigned int ub = compute_prb_freed((*cp_b)->snapshot.peri_rb);
+    //return ub - ua;
+    //unsigned int ua = compute_uniqueness((*cp_a)->snapshot.peri_rb, (*cp_a)->snapshot.n_peri_rb);
+    //unsigned int ub = compute_uniqueness((*cp_b)->snapshot.peri_rb, (*cp_b)->snapshot.n_peri_rb);
+    float ua = (*cp_a)->snapshot.uniqueness;
+    float ub = (*cp_b)->snapshot.uniqueness;
+    return ub - ua;
+}
+static int cp_find_most_unique(periscope_cp_candidates *candidates)
+{
+    assert(candidates);
+    assert(candidates->num_cps > 0);
+
+    unsigned int min_c = 4;
+    if(candidates->num_cps < min_c) return candidates->num_cps;
+    //float *u = g_malloc(candidates->num_cps * sizeof(float));
+    float min_u = 10000000.0f;
+    for (int i=0; i<candidates->num_cps; i++) {
+       float u = compute_uniqueness(candidates->cps[i]->snapshot.peri_rb, candidates->cps[i]->snapshot.n_peri_rb);
+       candidates->cps[i]->snapshot.uniqueness = u;
+       if(u < min_u) min_u = u;
+    }
+
+    qsort(candidates->cps, candidates->num_cps, sizeof(candidates->cps[0]),
+          cmp_uniqueness);
+    for (int i=0; i<candidates->num_cps; i++) {
+        const periscope_cp_desc *cur = candidates->cps[i];
+        assert(cur != NULL);
+        if (candidates->cps[i]->snapshot.uniqueness > min_u * UNIQUENESS_PERC) {
+            candidates->cps[i] = candidates->cps[candidates->num_cps-1];
+            candidates->num_cps--;
+            candidates->cps[candidates->num_cps] = NULL;
+            if(candidates->num_cps < min_c) break;
+        }
+    }
+
+    //for (int i=0; i<candidates->num_cps; i++) {
+    //   printf("%s u[%d] = %f\n", __FUNCTION__, i, candidates->cps[i]->snapshot.uniqueness);
+    //}
+    return candidates->num_cps;
+}
+#endif
+
+static periscope_cp_policy cp_policy_nac = {
+    .name = "NAC",
+    .find_replacement_candidates = cp_find_non_active_nodes,
+};
+
+static periscope_cp_policy cp_policy_lll = {
+    .name = "LLL",
+    .find_replacement_candidates = cp_find_last_level_leafs,
+};
+
+static periscope_cp_policy cp_policy_lru = {
+    .name = "LRU",
+    .find_replacement_candidates = cp_find_least_recently_used,
+};
+
+#ifdef EVICT_FIFO
+static periscope_cp_policy cp_policy_fifo = {
+    .name = "FIFO",
+    .find_replacement_candidates = cp_find_least_recently_created,
+};
+#endif
+
+#if defined(PERI_DEDUP) && !defined(PERI_DEDUP_NOHASH)
+static periscope_cp_policy cp_policy_dedup = {
+    .name = "DEDUP",
+    .find_replacement_candidates = cp_find_most_unique,
+};
+#endif
+
+static periscope_cp_policy *cp_policy_chain[] = {
+#if defined(PERI_DEDUP) && !defined(PERI_DEDUP_NOHASH)
+    &cp_policy_dedup,
+#endif
+    &cp_policy_nac,
+    &cp_policy_lll,
+    &cp_policy_lru,
+#ifdef EVICT_FIFO
+    &cp_policy_fifo,
+#endif
+    NULL,
+};
+
+static int num_evicted[sizeof(cp_policy_chain)/sizeof(cp_policy_chain[0])];
+
+static void collect_all_leaf_cps(periscope_cp_desc *cpd,
+                                 periscope_cp_candidates *candidates)
+{
+    assert(cpd != NULL);
+    assert(cpd->closed);
+    assert(candidates != NULL);
+
+    // base case
+    if (cpd->n_children == 0) {
+        if (candidates->num_cps >= MAX_CANDIDATES) {
+            printf("periscope: MAX_CANDIDATES too small\n");
+            return;
+        }
+        candidates->cps[candidates->num_cps++] = cpd;
+        return;
+    }
+
+    for (int i = 0; i < cpd->n_children; ++i) {
+        periscope_cp_desc *child = cpd->children[i];
+        assert(child != NULL);
+        collect_all_leaf_cps(child, candidates);
+    }
+}
+
+static int periscope_maybe_purge_checkpoints(periscope_cp_desc *cp_to_store,
+                                             uint64_t cost)
+{
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+
+    if (chkpt_memory_used + cost < fs->chkpt_pool_size * 1024) {
+        return 0;
+    }
+
+    periscope_cp_candidates candidates;
+    memset(&candidates, 0x0, sizeof(candidates));
+    collect_all_leaf_cps(&cp_root, &candidates);
+    printf("periscope: # of (initial) candidates = %d\n", candidates.num_cps);
+
+    int i = 0;
+    periscope_cp_desc* cp_to_purge = NULL;
+    periscope_cp_policy *cp_policy = cp_policy_chain[i];
+
+    while (candidates.num_cps > 0) {
+        assert(cp_policy->find_replacement_candidates);
+
+        if (cp_policy->find_replacement_candidates(&candidates) == 1) {
+            // we found a single candidate
+            printf("periscope: # of candidates = %d\n", candidates.num_cps);
+            cp_to_purge = candidates.cps[0];
+            num_evicted[i]++;
+            break;
+        }
+
+        printf("periscope: # of candidates = %d\n", candidates.num_cps);
+
+        if (cp_policy_chain[i+1] == NULL) {
+            // no more policy exists.
+            break;
+        }
+
+        i++;
+        cp_policy = cp_policy_chain[i];
+    }
+
+    if (cp_to_purge == NULL) {
+        printf("periscope: no policy finds good replacement candidate.\n");
+        return -1;
+    }
+
+    assert(cp_policy != NULL);
+    printf("periscope: policy-%s decides to replace checkpoint %d\n",
+           cp_policy->name, cp_to_purge->snapshot.id);
+
+    if (&cp_root == cp_to_purge) {
+        printf("periscope: root checkpoint cannot be replaced.\n");
+        return -2;
+    }
+
+    // TODO: probably lift this constraint later
+    if (cp_to_purge->n_children > 0) {
+        printf("periscope: checkpoint having any child cannot be replaced.\n");
+        return -3;
+    }
+
+    // TODO: the following only works in conjunction with children number check
+    // up there; we should later generalize this
+    if (cp_to_store->parent == cp_to_purge) {
+#if 1
+        // let's not specialize the checkpoint, and leave it more general and
+        // potentially more useful.
+        printf("periscope: replacement candidate is new checkpoint's parent.\n");
+        return -4;
+#else
+        printf("periscope: purging the parent of a new checkpoint\n");
+
+        memcpy(cp_to_store->io + cp_to_purge->len, cp_to_store,
+               cp_to_purge->len);
+        memcpy(cp_to_store->io, cp_to_purge->io, cp_to_purge->len);
+        cp_to_store->len += cp_to_purge->len;
+
+        timeradd(&cp_to_purge->exec_time, &cp_to_store->exec_time,
+                 &cp_to_store->exec_time);
+
+        cp_to_store->parent = cp_to_purge->parent;
+#endif
+    }
+
+    qemu_timeval now;
+    qemu_timeval time_since_last_restore;
+    qemu_gettimeofday(&now);
+    qemu_timersub(&now, &cp_to_purge->last_restored, &time_since_last_restore);
+    printf("periscope: purging checkpoint periscope-%u (%lu ms saved for %d "
+           "restores, last restore %ld s ago)\n",
+           cp_to_purge->snapshot.id, calc_total_time_saved(cp_to_purge),
+           cp_to_purge->num_restored, time_since_last_restore.tv_sec);
+
+    // Detach from the parent with lots of checks
+    periscope_cp_desc *parent = cp_to_purge->parent;
+    assert(parent != NULL);
+    assert(parent->n_children > 0);
+    bool found = false;
+    for (int i = 0; i < parent->n_children; i++) {
+        if (parent->children[i] == cp_to_purge) {
+            parent->children[i] = parent->children[parent->n_children - 1];
+            found = true;
+            break;
+        }
+    }
+    assert(found);
+    parent->n_children--;
+    cp_to_purge->parent = NULL;
+
+    chkpt_memory_used -= compute_memory_cost(cp_to_purge);
+
+    // Close all the associated file
+#ifndef ENABLE_LW_CHKPT
+    assert(cp_to_purge->snapshot.memfd > -1);
+    close(cp_to_purge->snapshot.memfd);
+    cp_to_purge->snapshot.memfd = -1;
+#else /* ENABLE_LW_CHKPT */
+#ifndef PERI_DEDUP
+    if (cp_to_purge->snapshot.memfd_quick > -1) {
+        close(cp_to_purge->snapshot.memfd_quick);
+        cp_to_purge->snapshot.memfd_quick = -1;
+    }
+
+    if (cp_to_purge->snapshot.memfd_ram > -1) {
+        close(cp_to_purge->snapshot.memfd_ram);
+        cp_to_purge->snapshot.memfd_ram = -1;
+    }
+
+    if (cp_to_purge->snapshot.buf_quick != NULL) {
+        g_free(cp_to_purge->snapshot.buf_quick);
+        cp_to_purge->snapshot.buf_quick = NULL;
+    }
+
+    if (cp_to_purge->snapshot.buf_ram != NULL) {
+        g_free(cp_to_purge->snapshot.buf_ram);
+        cp_to_purge->snapshot.buf_ram = NULL;
+    }
+
+    if (cp_to_purge->snapshot.dirty) {
+        g_free(cp_to_purge->snapshot.dirty);
+        cp_to_purge->snapshot.dirty = NULL;
+    }
+#ifdef DBG_RAM_STORED
+    if (cp_to_purge->snapshot.rambkp) {
+        g_free(cp_to_purge->snapshot.rambkp);
+        cp_to_purge->snapshot.rambkp = NULL;
+    }
+    cp_to_purge->snapshot.rambkp_size = 0;
+#endif
+#else /*PERI_DEDUP */
+    if(cp_to_purge->snapshot.peri_rb) {
+       delete_peri_rbs(
+             cp_to_purge->snapshot.peri_rb,
+             cp_to_purge->snapshot.n_peri_rb,
+             parent->snapshot.peri_rb);
+       g_free(cp_to_purge->snapshot.peri_rb);
+       cp_to_purge->snapshot.peri_rb = NULL;
+       cp_to_purge->snapshot.n_peri_rb = 0;
+    }
+    if (cp_to_purge->snapshot.buf_dev != NULL) {
+        g_free(cp_to_purge->snapshot.buf_dev);
+        cp_to_purge->snapshot.buf_dev = NULL;
+        cp_to_purge->snapshot.dev_sz = 0;
+    }
+#endif /*PERI_DEDUP */
+#endif /*ENABLE_LW_CHKPT*/
+    cp_to_purge->snapshot.id = SNAPSHOT_INVALID;
+
+    // Delete the descriptor itself
+    free(cp_to_purge);
+    cp_to_purge = NULL;
+
+    return 0;
+}
+
+void periscope_checkpoint_request(void) {
+    vm_stop(RUN_STATE_SAVE_VM);
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    // printf("periscope: checkpoint request\n");
+
+    // timeout for checkpoint
+    timer_mod(s->timer, qemu_clock_get_ms(QEMU_CLOCK_HOST) + 5000000);
+    timeout_reason = TIMEOUT_CHECKPOINT;
+
+    checkpoint_request = next_snapshot_id++;
+}
+
+static qemu_timeval tv_restore_end = {0, 0};
+
+bool periscope_snapshot_inited(void) {
+    return snapshot_inited;
+}
+
+static int __periscope_purge_and_checkpoint_request(bool do_request) {
+    // approx. memory cost in KiB
+    FuzzerState *s = fuzzer_get_current();
+    uint64_t input_cost = (s->cur_input->used_len + 1024U) / 1024U;
+#ifndef PERI_DEDUP
+    unsigned long *dirty = NULL;
+    unsigned long num_pages = get_current_delta_bm(&dirty);
+    assert(dirty != NULL);
+    unsigned long num_dirty_pages = bitmap_count_one(dirty, num_pages);
+    g_free(dirty);
+
+    uint64_t dirty_cost = num_dirty_pages * TARGET_PAGE_SIZE / 1024U;
+    uint64_t fixed_cost = last_chkpt_fixed_sz / 1024U;
+#else /*PERI_DEDUP */
+    unsigned long num_dirty_pages = count_dirty_pages();
+    uint64_t dirty_cost = compute_dirty_cost(num_dirty_pages) / 1024U;
+    uint64_t fixed_cost = last_chkpt_fixed_sz / 1024U;
+#ifndef PERI_DEDUP_NOHASH
+    unsigned long num_unique_pages = get_max_new_pages();
+    fixed_cost += (get_ram_page_pool_size() +
+          get_rpp_hashmap_size()) / 1024U;
+#endif
+#endif
+
+    uint64_t mem_cost = input_cost + dirty_cost + fixed_cost;
+
+    // TODO: needed for profiling!
+    while (chkpt_memory_used + mem_cost > s->chkpt_pool_size * 1024) {
+    int reject_reason = periscope_maybe_purge_checkpoints(s->cur_cp, mem_cost);
+    if (reject_reason != 0) {
+#ifndef CHKPT_TESTING
+       printf("periscope: checkpoint request (%lu+%lu+%lu=%lu KiB) rejected for reason %d.\n",
+             input_cost, dirty_cost, fixed_cost, mem_cost,
+             reject_reason);
+#endif
+       return -1;
+    }
+    }
+
+#if defined(PERI_DEDUP) && !defined(PERI_DEDUP_NOHASH)
+    long freed = 0;
+    while(get_free_pages() < num_unique_pages || !do_request) {
+       long free = ((long)s->chkpt_pool_size * 1024L - ((long)chkpt_memory_used + mem_cost)) * 1024L - freed;
+       if(free > TARGET_PAGE_SIZE * 512) {
+          if(grow_ram_page_pool(free/8) == 0) {
+             freed += free/8;
+          } else {
+             freed = (long)s->chkpt_pool_size * 1024L; // to terminate
+          }
+          if(!do_request) break;
+          continue;
+       }
+       int reject_reason = periscope_maybe_purge_checkpoints(s->cur_cp, s->chkpt_pool_size * 1024);
+       if (reject_reason != 0) {
+          printf("periscope: checkpoint request (%lu+%lu+%lu=%lu KiB) rejected for reason %d.\n",
+                input_cost, dirty_cost, fixed_cost, mem_cost,
+                reject_reason);
+          return -1;
+       }
+       // TODO
+       if(!do_request) break;
+    }
+#endif
+
+
+    if(do_request) {
+       printf("periscope: requesting checkpoint (approx. %lu+%lu+%lu=%lu KiB)...\n",
+             input_cost, dirty_cost, fixed_cost, mem_cost);
+
+       periscope_checkpoint_request();
+    }
+
+    return 0;
+}
+int periscope_purge_and_checkpoint_request(void) {
+   return __periscope_purge_and_checkpoint_request(true);
+}
+
+static int chkpt_disable_after_nth = 0; // zero-indexed
+
+#define CHKPT_TIME_THRESHOLD_MS 50
+#define CHKPT_TIME_THRESHOLD_MULTIPLIER 2
+
+static uint64_t chkpt_time_threshold_ms = CHKPT_TIME_THRESHOLD_MS;
+
+static uint64_t last_chkpt_ms = 0;
+static int chkpt_policy = PERISCOPE_CHKPT_TIME_ONLY; // default policy
+
+int periscope_change_chkpt_policy(int pol, int param1)
+{
+    if (pol < 0 || pol >= PERISCOPE_CHKPT_MAX) {
+        return -1;
+    }
+
+    if (chkpt_policy == PERISCOPE_CHKPT_TIME_ONLY_DISABLED_AFTER_NTH) {
+        if (param1 < 0)
+            return -1;
+        chkpt_disable_after_nth = param1;
+    }
+
+    chkpt_policy = pol;
+
+    return 0;
+}
+
+int periscope_maybe_checkpoint_request(void) {
+    if (unlikely(!snapshot_inited)) {
+        periscope_checkpoint_request();
+        snapshot_inited = true;
+        return 0;
+    }
+    if (next_snapshot_id != SNAPSHOT_ROOT_ID && root_only_chkpt) {
+      //printf("periscope: only root checkpoints allowed\n");
+      return -1;
+    }
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+    assert(s->cur_input != NULL);
+    assert(s->cur_cp != NULL);
+
+    if (s->cur_cp->len == 0) {
+        return -1;
+    }
+
+    uint64_t now = qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL);
+    uint64_t time_since_last_chkpt_ms = now - last_chkpt_ms;
+
+    printf(
+        "periscope: chkpt requested after %ld ms (used=%d, threshold=%ld ms)\n",
+        time_since_last_chkpt_ms, s->cur_input->used_len,
+        chkpt_time_threshold_ms);
+
+    s->cur_cp->exec_time.tv_sec = time_since_last_chkpt_ms / 1000UL;
+    s->cur_cp->exec_time.tv_usec =
+        (time_since_last_chkpt_ms % 1000UL) * 1000UL;
+
+    qemu_timeval elapsed; // in vm time
+    memcpy(&elapsed, &s->cur_cp->exec_time, sizeof(qemu_timeval));
+    timeradd(&elapsed, &total_exec_time, &total_exec_time);
+    if (timercmp(&elapsed, &max_exec_time, >)) {
+        printf("periscope: new max exec time %lu ms (%u/%u bytes, %u irqs, %u io reads)\n",
+               elapsed.tv_sec * 1000L + elapsed.tv_usec / 1000L,
+               s->cur_input->used_len,
+               s->cur_input->len,
+               s->cur_input->num_irqs,
+               s->cur_input->num_io_reads);
+        memcpy(&max_exec_time, &elapsed, sizeof(qemu_timeval));
+
+        print_time_consumption_statistics();
+    }
+
+    bool should_chkpt = true;
+
+    switch (chkpt_policy) {
+    case PERISCOPE_CHKPT_TIME_ONLY:
+        should_chkpt &= (time_since_last_chkpt_ms > chkpt_time_threshold_ms);
+        break;
+    case PERISCOPE_CHKPT_DISABLED:
+        should_chkpt = false;
+        break;
+    case PERISCOPE_CHKPT_TIME_ONLY_DISABLED_AFTER_NTH:
+        if (chkpt_disable_after_nth + 1 >= s->cur_input->used_len) {
+            should_chkpt &= (time_since_last_chkpt_ms > chkpt_time_threshold_ms);
+        } else {
+            printf("periscope: chkpt disabled at %d > %d\n",
+                   s->cur_input->used_len - 1, chkpt_disable_after_nth);
+            should_chkpt = false;
+        }
+        break;
+    default:
+        printf("periscope: unknown checkpoint policy\n");
+        break;
+    }
+
+    if (should_chkpt == true) {
+        printf("periscope: policy %d requests checkpoint\n", chkpt_policy);
+
+        if (periscope_purge_and_checkpoint_request() == 0) {
+#ifndef CHKPT_TESTING
+        printf("periscope: last input (%u/%u B, %u irqs, %u io reads) took too much time (%lu ms).\n",
+                s->cur_input->used_len,
+                s->cur_input->len,
+                s->cur_input->num_irqs,
+                s->cur_input->num_io_reads,
+                elapsed.tv_sec * 1000L + elapsed.tv_usec / 1000L);
+#endif
+
+            // reset chkpt counter
+            last_chkpt_ms = now;
+
+            chkpt_time_threshold_ms *= CHKPT_TIME_THRESHOLD_MULTIPLIER;
+        }
+    }
+    else {
+#ifdef TRACE_CHECKPOINT_POLICY
+        printf("periscope: elapsed.tv_usec %8ld < %8ld\n",
+               elapsed.tv_usec,
+               CHKPT_TIME_THRESHOLD);
+#endif
+    }
+
+    return -1;
+}
+
+static int restore_request = 0;
+
+static periscope_input_desc *periscope_next_input(void);
+
+#define TRACE_LCA
+#undef TRACE_LCA
+static periscope_cp_desc *find_lowest_common_ancestor(periscope_cp_desc *a,
+                                                      periscope_cp_desc *b)
+{
+    assert(a != NULL);
+    assert(b != NULL);
+
+    int depth_a = 0;
+    periscope_cp_desc *tmp = a;
+    while (tmp->parent) {
+        tmp = tmp->parent;
+        depth_a++;
+    }
+
+    int depth_b = 0;
+    tmp = b;
+    while (tmp->parent) {
+        tmp = tmp->parent;
+        depth_b++;
+    }
+
+    while (depth_a > depth_b) {
+        depth_a--;
+        a = a->parent;
+    }
+    while (depth_b > depth_a) {
+        depth_b--;
+        b = b->parent;
+    }
+
+    while (a != b) {
+        b = b->parent;
+        a = a->parent;
+    }
+
+    assert(a != NULL);
+    assert(b != NULL);
+    assert(a == b);
+
+#ifdef TRACE_LCA
+    if (a != &cp_root) {
+        printf("periscope: non-root lowest common ancestor id=%d\n", a->snapshot.id);
+    }
+#endif
+
+    return a;
+}
+
+#ifdef ENABLE_LW_CHKPT
+#define TRACE_DELTA_RESTORE
+//#undef TRACE_DELTA_RESTORE
+
+//static bool first_restore = true;
+
+static bool suspended = false;
+
+int periscope_guest_crashed(void)
+{
+    FuzzerState *fs = fuzzer_get_current();
+    if (fs && fs->guest_crashed) {
+        if (fs->guest_crashed() == PERISCOPE_GUEST_SUSPEND) {
+            atomic_set(&suspended, true);
+            return PERISCOPE_GUEST_SUSPEND;
+        }
+    }
+
+    return 0;
+}
+
+struct DirtyBitmapSnapshot {
+    ram_addr_t start;
+    ram_addr_t end;
+    unsigned long dirty[];
+};
+
+#ifdef PERI_DEDUP
+
+/* Should be holding either ram_list.mutex, or the RCU lock. */
+#define  INTERNAL_RAMBLOCK_FOREACH(block)  \
+    QLIST_FOREACH_RCU(block, &ram_list.blocks, next)
+/* Never use the INTERNAL_ version except for defining other macros */
+#define RAMBLOCK_FOREACH(block) INTERNAL_RAMBLOCK_FOREACH(block)
+
+/* Should be holding either ram_list.mutex, or the RCU lock. */
+#define RAMBLOCK_FOREACH_NOT_IGNORED(block)            \
+    INTERNAL_RAMBLOCK_FOREACH(block)                   \
+        if (ramblock_is_ignored(block)) {} else
+
+#define RAMBLOCK_FOREACH_MIGRATABLE(block)             \
+    INTERNAL_RAMBLOCK_FOREACH(block)                   \
+        if (!qemu_ram_is_migratable(block)) {} else
+
+
+
+#define TRACE_PERI_DEVRAM_RESTORE
+//#undef TRACE_PERI_DEVRAM_RESTORE
+static void get_restore_bitmap(
+      periscope_cp_desc *cp_last,
+      periscope_cp_desc *cp_next,
+      periscope_cp_desc *cp_lca,
+      unsigned long *dirty,
+      //unsigned long *dirty_fine,
+      unsigned long npages_snap,
+      const char *name,
+      unsigned long *src_dirty_cnt,
+      unsigned long *dst_dirty_cnt) {
+    /*
+     * concatenate all the pages that have been dirtied
+     * in between the last checkpoint and the checkpoint to be restored.
+     * we want to go from
+     *       cp_last ---- HERE
+     *     /
+     *  cp_lca
+     *     \
+     *       cp_next - TO HERE
+     * -> Pages dirties by A have to be restored as well
+     */
+    periscope_cp_desc *cp_tmp = cp_last;
+    periscope_snapshot_desc *snap = NULL;
+
+    while (cp_tmp != cp_lca) {
+        snap = &cp_tmp->snapshot;
+        cp_tmp = cp_tmp->parent;
+        assert(cp_tmp != NULL);
+        assert(snap->id != SNAPSHOT_INVALID);
+        periscope_ramblock *prb  = get_ramblock(snap->peri_rb, snap->n_peri_rb, name);
+        assert(prb);
+        if(prb->empty) {
+           printf("%s: prb %s empty -> skip\n", __FUNCTION__, prb->idstr);
+           continue;
+        }
+
+#ifdef FINE_CHUNKS
+        unsigned long* prb_dirty = prb->dirty_fine;
+#else
+        unsigned long* prb_dirty = prb->dirty;
+#endif
+        if (npages_snap != prb->npages * CHUNK_DIV) {
+#ifdef TRACE_PERI_DEVRAM_RESTORE
+           printf("(now)%ld -- %ld(%d)\n", npages_snap, prb->npages, snap->id);
+#endif
+        }
+
+        //assert(npages_snap == prb->npages * CHUNK_DIV);
+
+        bitmap_or(dirty, dirty, prb_dirty, npages_snap);
+#ifdef TRACE_PERI_DEVRAM_RESTORE
+        printf("#pages after adding chkpt %d -> %ld\n", snap->id, bitmap_count_one(dirty, npages_snap));
+#endif
+    }
+    if(src_dirty_cnt) *src_dirty_cnt = bitmap_count_one(dirty, npages_snap) / CHUNK_DIV;
+    cp_tmp = cp_next;
+    while (cp_tmp != cp_lca) {
+        snap = &cp_tmp->snapshot;
+        cp_tmp = cp_tmp->parent;
+        assert(cp_tmp != NULL);
+        assert(snap->id != SNAPSHOT_INVALID);
+        periscope_ramblock *prb  = get_ramblock(snap->peri_rb, snap->n_peri_rb, name);
+        assert(prb);
+        if(prb->empty) {
+           printf("%s: prb %s empty -> skip\n", __FUNCTION__, prb->idstr);
+           continue;
+        }
+#ifdef FINE_CHUNKS
+        unsigned long* prb_dirty = prb->dirty_fine;
+#else
+        unsigned long* prb_dirty = prb->dirty;
+#endif
+#ifdef TRACE_PERI_DEVRAM_RESTORE
+        if (npages_snap != prb->npages * CHUNK_DIV) {
+           printf("(now)%ld -- %ld(%d)\n", npages_snap, prb->npages, snap->id);
+        }
+#endif
+
+        //assert(npages_snap == prb->npages * CHUNK_DIV);
+
+        bitmap_or(dirty, dirty, prb_dirty, npages_snap);
+#ifdef TRACE_PERI_DEVRAM_RESTORE
+        printf("#pages after adding chkpt %d -> %ld\n", snap->id, bitmap_count_one(dirty, npages_snap));
+#endif
+    }
+    if(dst_dirty_cnt) *dst_dirty_cnt = bitmap_count_one(dirty, npages_snap) / CHUNK_DIV;
+}
+
+static void restore_branch(
+      RAMBlock *rb,
+      periscope_cp_desc *cp_last,
+      periscope_cp_desc *cp_dest,
+      unsigned long *dirty,
+      unsigned long npages_snap) {
+    periscope_snapshot_desc *snap = NULL;
+    periscope_cp_desc *cp_next = cp_dest;
+
+    unsigned long* bm_and = bitmap_new(npages_snap);
+    bitmap_zero(bm_and, npages_snap);
+
+    // go through all parents of the snapshot to be restored
+    while (cp_next != NULL) {
+        snap = &cp_next->snapshot;
+        cp_next = cp_next->parent;
+        assert(snap->id != SNAPSHOT_INVALID);
+        periscope_ramblock *prb  = get_ramblock(snap->peri_rb, snap->n_peri_rb, rb->idstr);
+        assert(prb);
+        if(prb->empty) {
+           //printf("%s: prb %s empty -> skip\n", __FUNCTION__, prb->idstr);
+           continue;
+        }
+#ifdef FINE_CHUNKS
+        unsigned long* prb_dirty = prb->dirty_fine;
+#else
+        unsigned long* prb_dirty = prb->dirty;
+#endif
+        if(npages_snap > prb->npages * CHUNK_DIV) {
+           assert(false);
+           printf("Reallocating %s %ld ->  %ld\n", rb->idstr, prb->npages, npages_snap);
+           unsigned long *bm_new = bitmap_new(npages_snap);
+           bitmap_copy(bm_new, prb->dirty, prb->npages);
+           g_free(prb->dirty);
+           prb->dirty = bm_new;
+           prb->npages = npages_snap;
+           printf("%ld %ld\n", npages_snap, prb->npages);
+        }
+        //assert(npages_snap == prb->npages * CHUNK_DIV);
+        // get inersection of pages stored in this specific snapshot and all the
+        // pages currently dirty (which have to be restored)
+        bitmap_and(bm_and, dirty, prb_dirty, npages_snap);
+
+        // unless the intersection is empty ...
+        if (!bitmap_empty(bm_and, npages_snap)) {
+#ifdef TRACE_PERI_DEVRAM_RESTORE
+           printf(
+                 "periscope: restoring %lu/%lu dirty pages from snapshot %d\n",
+                 bitmap_count_one(bm_and, npages_snap),
+                 bitmap_count_one(prb_dirty, npages_snap), snap->id);
+#endif
+           restore_ram_pages(rb, prb, bm_and);
+        } else {
+           //printf("%s 0 overlap -> skip\n", rb->idstr);
+        }
+
+
+        // remove the pages that we have already restored fromt the bitmap
+        // indicating which pages still have to be restored
+        bitmap_andnot(dirty, dirty, bm_and, npages_snap);
+
+        //periscope_no_loadvm_state_setup = true;
+        //if(bitmap_empty(dirty, npages_snap)) break;
+    }
+
+#ifdef DBG_RAM_STORED // set in periscope.h
+    periscope_ramblock *prb  = get_ramblock(cp_dest->snapshot.peri_rb, cp_dest->snapshot.n_peri_rb, rb->idstr);
+    printf("---------- comparing restored chktp %d to %s\n", snap->id, rb->idstr);
+    assert(compare_ram_pages(prb->rambkp, NULL, prb->rambkp_size, prb->dirty, false, rb->idstr));
+#endif
+
+    if (bm_and) {
+        g_free(bm_and);
+        bm_and = NULL;
+    }
+}
+#endif /* PERI_DEDUP */
+
+
+int periscope_restore(void) {
+    vm_stop(RUN_STATE_RESTORE_VM);
+
+    int ret = -1; // will be updated as the return value of loadvm
+    rcu_read_lock();
+
+    periscope_cp_desc *cp_base = NULL; // base snapshot
+    periscope_cp_desc *cp_next = NULL; // to be restored
+    periscope_snapshot_desc *snap = NULL;
+
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+    assert(fs->cur_input);
+
+    if (fs->cur_input == &root) {
+       cp_base = &cp_root;
+    }
+    else {
+       assert(fs->cur_input);
+       cp_base = fs->cur_input->base_cp;
+    }
+
+    periscope_next_input(); // this function changes fs->cur_input
+
+    static qemu_timeval tv_restore_begin;
+    qemu_gettimeofday(&tv_restore_begin);
+
+    if (fs->cur_input == &root) {
+        cp_next = &cp_root;
+    }
+    else {
+        assert(fs->cur_input->base_cp);
+        cp_next = fs->cur_input->base_cp;
+    }
+
+    atomic_set(&restore_request, 0);
+
+#ifndef PERI_DEDUP
+    // get current dirty page bitmap -> all the pages we have to restore
+    // from all the upstream snapshots
+    unsigned long *dirty = NULL;
+    //unsigned long npages_snap = get_current_delta_bm(&dirty);
+    unsigned long npages_snap = update_and_clear_delta_snap_bm(&dirty);
+    assert(dirty != NULL);
+
+    unsigned long current_dirty_cnt = bitmap_count_one(dirty, npages_snap);
+    unsigned long src_dirty_cnt = 0;
+    unsigned long dst_dirty_cnt = 0;
+
+    printf("periscope: #dirty before restore %ld\n", bitmap_count_one(dirty, npages_snap));
+    /*
+     * concatenate all the pages that have been dirtied
+     * in between the last checkpoint and the checkpoint to be restored.
+     * we want to go from
+     *       cp_base ---- HERE
+     *     /
+     *  cp_lca
+     *     \
+     *       cp_next - TO HERE
+     * -> Pages dirties by A have to be restored as well
+     */
+    periscope_cp_desc *cp_lca = find_lowest_common_ancestor(cp_base, cp_next);
+    assert(cp_lca);
+    printf("periscope: base checkpoint %d, lca %d, dest %d\n",
+          cp_base->snapshot.id, cp_lca->snapshot.id, cp_next->snapshot.id);
+
+    struct periscope_cp_desc *cp_tmp = cp_base;
+    while (cp_tmp != cp_lca) {
+        snap = &cp_tmp->snapshot;
+        assert(snap->id != SNAPSHOT_INVALID);
+
+        if (npages_snap != snap->npages) {
+            printf("(now)%ld -- %ld(%d)\n", npages_snap, snap->npages, snap->id);
+        }
+
+        assert(npages_snap == snap->npages);
+
+        bitmap_or(dirty, dirty, snap->dirty, npages_snap);
+
+        cp_tmp = cp_tmp->parent;
+        assert(cp_tmp != NULL);
+    }
+
+    src_dirty_cnt = bitmap_count_one(dirty, npages_snap) - current_dirty_cnt;
+
+    cp_tmp = cp_next;
+    while (cp_tmp != cp_lca) {
+        snap = &cp_tmp->snapshot;
+        assert(snap->id != SNAPSHOT_INVALID);
+
+        if (npages_snap != snap->npages) {
+            printf("(now)%ld -- %ld(%d)\n", npages_snap, snap->npages, snap->id);
+        }
+
+        assert(npages_snap == snap->npages);
+
+        bitmap_or(dirty, dirty, snap->dirty, npages_snap);
+
+        cp_tmp = cp_tmp->parent;
+        assert(cp_tmp != NULL);
+    }
+
+    dst_dirty_cnt = bitmap_count_one(dirty, npages_snap) - current_dirty_cnt - src_dirty_cnt;
+
+    fs->cur_input->num_pages_restored = current_dirty_cnt + src_dirty_cnt + dst_dirty_cnt;
+
+    snap = &cp_next->snapshot;
+
+    periscope_cp_desc *cp_dest = cp_next;
+
+    unsigned long* bm_and = bitmap_new(npages_snap);
+
+#ifdef FULL_SNAPSHOT_RESTORE
+    ret = load_snapshot("periscope-syz-1", NULL);
+#else
+
+#ifdef FULL_DELTA_RESTORE
+    bitmap_fill(dirty, npages_snap);
+#endif
+
+    // TODO:
+    // sometimes on first restore, we only have 1 or 2 pages in the bitmap
+    // this fixes that problem, but we should really only match on the first restore
+    //if (first_restore)
+    //   bitmap_fill(dirty, npages_snap);
+    //first_restore = false;
+
+    //QIOChannelFile *iochannel;
+    QIOChannelBuffer *iochannel;
+    QEMUFile *file;
+    MigrationIncomingState* mis;
+
+    //qemu_system_reset(SHUTDOWN_CAUSE_NONE); // TODO: can we avoid this?
+
+    periscope_no_loadvm_state_setup = false;
+    periscope_no_loadvm_state_cleanup = true;
+
+    // go through all parents of the snapshot to be restored
+    while (cp_next != NULL) {
+        snap = &cp_next->snapshot;
+        assert(npages_snap == snap->npages);
+
+        // get inersection of pages stored in this specific snapshot and all the
+        // pages currently dirty (which have to be restored)
+        bitmap_and(bm_and, dirty, snap->dirty, npages_snap);
+
+        // unless the intersection is empty ...
+        if (!bitmap_empty(bm_and, npages_snap) || cp_next==cp_dest) {
+#ifdef TRACE_DELTA_RESTORE
+            printf(
+                "periscope: restoring %lu/%lu dirty pages from snapshot %d\n",
+                bitmap_count_one(bm_and, npages_snap),
+                bitmap_count_one(snap->dirty, npages_snap), snap->id);
+#endif
+
+            // copy intersection bitmap to ramblock
+            // this bitmap will determine which pages are skipped in ram_load
+            RAMBlock *rb;
+            INTERNAL_RAMBLOCK_FOREACH(rb)
+            { // TODO: get_system_ram returns mr->ram_block empty??
+                if (rb->bmap_delta_restore == NULL) {
+                    // if there is none yet, create one (hope that npages is
+                    // fixed)
+                    unsigned long npages = rb->max_length >> TARGET_PAGE_BITS;
+                    rb->bmap_delta_restore = bitmap_new(npages);
+                }
+                assert(rb->bmap_delta_restore != NULL);
+                if (strcmp(rb->idstr, "pc.ram") != 0) {
+                    if (periscope_no_loadvm_state_setup == false) {
+                        bitmap_set(rb->bmap_delta_restore, 0, rb->max_length >> TARGET_PAGE_BITS);
+                    }
+                    else {
+                        bitmap_clear(rb->bmap_delta_restore, 0, rb->max_length >> TARGET_PAGE_BITS);
+                    }
+                }
+                else {
+                    assert(rb->max_length>>TARGET_PAGE_BITS == npages_snap);
+                    bitmap_copy(rb->bmap_delta_restore, bm_and, npages_snap);
+                }
+            }
+
+            // setup the restore
+            //lseek(snap->memfd_ram, 0, SEEK_SET);
+            //iochannel = qio_channel_file_new_fd(dup(snap->memfd_ram));
+            iochannel = qio_channel_buffer_new_with_existing_data(snap->buf_ram, snap->ram_sz);
+            file = qemu_fopen_channel_input(QIO_CHANNEL(iochannel));
+            mis = migration_incoming_get_current();
+            mis->from_src_file = file;
+            ret = qemu_loadvm_state(file);
+            mis->from_src_file = NULL;
+            //migration_incoming_state_destroy();
+            qio_channel_buffer_close_without_free(iochannel);
+            object_unref(OBJECT(iochannel));
+            qemu_fclose(file);
+            file = NULL;
+        }
+
+        // remove the pages that we have already restored fromt the bitmap
+        // indicating which pages still have to be restored
+        bitmap_andnot(dirty, dirty, bm_and, npages_snap);
+
+        periscope_no_loadvm_state_setup = true;
+        cp_next = cp_next->parent;
+    }
+
+    periscope_no_loadvm_state_cleanup = false;
+#ifdef TRACE_DELTA_RESTORE
+    printf("periscope: restoring device state\n");
+#endif
+    snap = &cp_dest->snapshot;
+    iochannel = qio_channel_buffer_new_with_existing_data(snap->buf_quick, snap->quick_sz);
+    file = qemu_fopen_channel_input(QIO_CHANNEL(iochannel));
+    mis = migration_incoming_get_current();
+    mis->from_src_file = file;
+    ret = qemu_loadvm_state(file);
+    mis->from_src_file = NULL;
+    migration_incoming_state_destroy();
+    qio_channel_buffer_close_without_free(iochannel);
+    object_unref(OBJECT(iochannel));
+    qemu_fclose(file);
+    file = NULL;
+#endif /*FULL_DELTA_RESTORE*/
+
+#ifdef ENABLE_LW_CHKPT
+    if (bm_and) {
+        g_free(bm_and);
+        bm_and = NULL;
+    }
+    if (dirty) {
+        g_free(dirty);
+        dirty = NULL;
+    }
+#endif
+#else /*PERI_DEDUP*/
+    periscope_cp_desc *cp_dest = cp_next;
+    periscope_cp_desc *cp_lca = find_lowest_common_ancestor(cp_base, cp_next);
+    assert(cp_lca);
+#ifdef TRACE_DELTA_RESTORE
+    printf("last snap %d, lca snap %d\n", cp_base->snapshot.id, cp_lca->snapshot.id);
+#endif
+    unsigned long total_dirty_cnt = 0;
+    unsigned long current_dirty_cnt = 0;
+    unsigned long src_dirty_cnt = 0;
+    unsigned long dst_dirty_cnt = 0;
+    unsigned long npages_snap = 0;
+
+    //qemu_system_reset(SHUTDOWN_CAUSE_NONE); // TODO: can we avoid this?
+    RAMBlock *rb;
+    qemu_mutex_lock_ramlist();
+    rcu_read_lock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+    RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+       struct DirtyBitmapSnapshot *db_snap = memory_region_snapshot_and_clear_dirty(
+             rb->mr,
+             0, rb->max_length,
+             DIRTY_MEMORY_DELTA // TODO: do we need a custom flag?
+             );
+#ifdef TRACE_DELTA_DEDUP_RESTORE
+       printf("%s: update %s %lx - %lx\n", __FUNCTION__, rb->idstr, db_snap->start, db_snap->end);
+#endif
+       npages_snap = (db_snap->end - db_snap->start) >> TARGET_PAGE_BITS;
+       assert(db_snap->dirty != NULL);
+#ifdef FINE_CHUNKS
+       unsigned long *dirty_fine = copy_fine_bitmap(db_snap->dirty, npages_snap);
+       unsigned long *dirty = dirty_fine;
+       npages_snap *= CHUNK_DIV;
+#else
+       unsigned long *dirty = db_snap->dirty;
+#endif
+       //unsigned long *dirty = bitmap_new(npages_snap);
+       //bitmap_copy(dirty, db_snap->dirty, npages_snap);
+       //assert(dirty != NULL);
+       unsigned long rb_current_dirty_cnt = 0;
+       unsigned long rb_src_dirty_cnt = 0;
+       unsigned long rb_dst_dirty_cnt = 0;
+       rb_current_dirty_cnt = bitmap_count_one(dirty, npages_snap) / CHUNK_DIV;
+       current_dirty_cnt += rb_current_dirty_cnt;
+#ifdef TRACE_DELTA_DEDUP_RESTORE
+       printf("%s #dirty pages %ld\n", rb->idstr, rb_current_dirty_cnt);
+#endif
+       // go through all parents of last restored snapshot to collect dirty bits
+       get_restore_bitmap(cp_base, cp_next, cp_lca, dirty, npages_snap, rb->idstr,
+             &rb_src_dirty_cnt, &rb_dst_dirty_cnt);
+       src_dirty_cnt += (rb_src_dirty_cnt - rb_current_dirty_cnt);
+       dst_dirty_cnt += (rb_dst_dirty_cnt - rb_src_dirty_cnt - rb_current_dirty_cnt);
+       total_dirty_cnt += bitmap_count_one(dirty, npages_snap) / CHUNK_DIV;
+       // restore all dirty memory pages along the branch stating from the destination checkpoint
+       restore_branch(rb, cp_base, cp_next, dirty, npages_snap);
+       g_free(db_snap);
+#ifdef FINE_CHUNKS
+       g_free(dirty_fine);
+#endif
+    }
+    fs->cur_input->num_pages_restored = total_dirty_cnt; //current_dirty_cnt + src_dirty_cnt + dst_dirty_cnt;
+    rcu_read_unlock();
+    qemu_mutex_unlock_ramlist();
+
+    QIOChannelBuffer *iochannel;
+    QEMUFile *file;
+    MigrationIncomingState* mis;
+
+
+    periscope_no_loadvm_state_cleanup = true;
+    periscope_no_loadvm_state_setup = true;
+    snap = &cp_dest->snapshot;
+    iochannel = qio_channel_buffer_new_with_existing_data(snap->buf_dev, snap->dev_sz);
+    file = qemu_fopen_channel_input(QIO_CHANNEL(iochannel));
+    mis = migration_incoming_get_current();
+    mis->from_src_file = file;
+    //quick_reset_devs = true;
+    ret = qemu_loadvm_state(file);
+    mis->from_src_file = NULL;
+    migration_incoming_state_destroy();
+    qio_channel_buffer_close_without_free(iochannel);
+    object_unref(OBJECT(iochannel));
+    qemu_fclose(file);
+    file = NULL;
+
+//    //quick_reset_devs = true;
+//    qemu_timeval tt0, tt1, tte, ttx0, ttx1, ttxe;
+//    qemu_gettimeofday(&tt0);
+//    //periscope_no_loadvm_state_cleanup = false;
+//    //periscope_no_loadvm_state_setup = false;
+//    periscope_no_loadvm_state_cleanup = false;
+//    periscope_no_loadvm_state_setup = true;
+//    snap = &cp_dest->snapshot;
+//    assert(snap->buf_dev != NULL);
+//    assert(snap->dev_sz != 0);
+//    assert(snap != NULL);
+//    iochannel = qio_channel_buffer_new_with_existing_data(snap->buf_dev, snap->dev_sz);
+//    file = qemu_fopen_channel_input(QIO_CHANNEL(iochannel));
+//    mis = migration_incoming_get_current();
+//    mis->from_src_file = file;
+//    ret = qemu_loadvm_state(file);
+//    mis->from_src_file = NULL;
+//    migration_incoming_state_destroy();
+//    qio_channel_buffer_close_without_free(iochannel);
+//    object_unref(OBJECT(iochannel));
+//    qemu_fclose(file);
+//    file = NULL;
+//    qemu_gettimeofday(&tt1);
+//    timersub(&tt1, &tt0, &tte);
+//    unsigned long ttt = tte.tv_sec * 1000L *1000L + tte.tv_usec;
+//    //quick_reset_devs = false;
+//    printf("periscope: dev restore %ld\n", ttt/1000L);
+#endif /*PERI_DEDUP */
+
+    if (ret < 0) {
+        printf("periscope: restoring periscope-%u failed\n", snap->id);
+        return -1;
+    }
+
+    qemu_gettimeofday(&tv_restore_end);
+
+    qemu_timeval restore_elapsed;
+    timersub(&tv_restore_end, &tv_restore_begin, &restore_elapsed);
+
+    last_restore_time.tv_sec =  restore_elapsed.tv_sec;
+    last_restore_time.tv_usec = restore_elapsed.tv_usec;
+#ifdef TRACE_DELTA_RESTORE
+    printf("periscope: restored snapshot %d (%lu ms) %u times (%ld+%ld+%ld=%ld/%ld dirty pages)\n",
+           snap->id, restore_elapsed.tv_usec / 1000L, cp_dest->num_restored,
+           current_dirty_cnt, src_dirty_cnt, dst_dirty_cnt,
+           current_dirty_cnt+src_dirty_cnt+dst_dirty_cnt, npages_snap);
+#endif
+
+    last_chkpt_ms = qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL);
+
+    int level = 0;
+    periscope_cp_desc *cp = fs->cur_input->restored_cp;
+    while (cp != NULL) {
+        level++;
+        cp = cp->parent;
+    }
+
+    chkpt_time_threshold_ms = CHKPT_TIME_THRESHOLD_MS;
+    level--;
+    while (level > 0) {
+        chkpt_time_threshold_ms *= CHKPT_TIME_THRESHOLD_MULTIPLIER;
+        level--;
+    }
+
+    if (fs->restored) {
+        fs->restored();
+
+        memset(num_evicted, 0, sizeof(num_evicted));
+    }
+    atomic_set(&suspended, false);
+
+    assert(fs->cur_cp);
+
+    if (!fs->cur_cp->closed) {
+        delete_cp_desc(fs->cur_cp);
+        fs->cur_cp = NULL;
+    }
+
+    // base a new cp on the base snapshot of the new input.
+    fs->cur_cp = create_cp_desc(cp_dest);
+
+    if (snap->id != SNAPSHOT_ROOT_ID) {
+        total_non_root_restores += 1;
+    }
+
+#if 0 // loadvm will change pc.ram, so we can not clear the bitmap here
+    // clear the bitmap
+    unsigned long *dirty_new;
+    update_and_clear_delta_snap_bm(&dirty_new);
+    unsigned int n_dirty_new = bitmap_count_one(dirty_new, npages_snap);
+    printf("%d new bits after restore\n", n_dirty_new);
+    g_free(dirty_new);
+    assert(n_dirty_new == 0);
+#endif
+
+    rcu_read_unlock();
+
+    cpu_synchronize_all_post_init();
+
+#ifdef DBG_RAM_STORED // set in periscope.h
+    printf("---------- comparing restored chktp %d to pc.ram\n", cp_dest->snapshot.id);
+    assert(compare_ram_pages(cp_dest->snapshot.rambkp, NULL,
+          cp_dest->snapshot.rambkp_size, NULL, false));
+#endif
+
+    vm_start();
+
+    return 0;
+}
+#else  /* !ENABLE_LWPCHKPT */
+int periscope_restore(void) {
+    int ret;
+    int last_id = -1;
+    int id = 0;
+
+    char pt_mark_buf[256];
+    snprintf(pt_mark_buf, 256, "## %s\n", __FUNCTION__);
+    pt_mark_all(pt_mark_buf);
+
+    FuzzerState *fs = fuzzer_get_current();
+    assert(fs);
+    assert(fs->cur_input);
+
+    if (fs->cur_input != &root) {
+        assert(fs->cur_input->base_cp);
+        last_id = fs->cur_input->base_cp->snapshot.id;
+    }
+
+    if (fs->fetch_next) {
+        periscope_next_input(); // this function changes fs->cur_input
+    }
+
+#if 1
+    periscope_cp_desc *cp;
+    periscope_snapshot_desc *s;
+
+    if (fs->cur_input == &root) {
+        cp = &cp_root;
+    }
+    else {
+        assert(fs->cur_input->base_cp);
+        cp = fs->cur_input->base_cp;
+    }
+    s = &cp->snapshot;
+    id = s->id;
+
+    //printf("periscope: restore %d (old %d)\n", id, last_id);
+    // stat
+    timeradd(&cp->exec_time, &total_chkpt_saving_time,
+             &total_chkpt_saving_time);
+
+    restore_request = 0;
+#else
+    assert(s->cur_input->parent);
+
+    // FIXME: parent is always root only for now.
+    assert(s->cur_input->parent == &root);
+
+    restore_request = &s->cur_input->parent->snapshot;
+
+#if 0
+    printf("as=0x%p as->root=0x%p as->root->ram_block=0x%p\n",
+            as, as->root, as->root->ram_block);
+#endif
+#endif
+
+    // printf("periscope: sync dirty log start\n");
+    // memory_global_dirty_log_sync();
+    // printf("perscope: sync dirty log end\n");
+
+#ifdef ENABLE_DELTA_CHECKPOINT
+    check_memory_regions();
+#endif
+
+#if 0
+    // snapshot dirty log
+    MemoryRegion *mr = get_system_memory();
+    DirtyBitmapSnapshot *snap = memory_region_snapshot_and_clear_dirty(
+        mr,
+        mr->addr,
+        mr->size,
+        DIRTY_CLIENTS_ALL
+    );
+
+    // TODO
+    (void)snap;
+#endif
+
+#if 0
+    if (restore_request == NULL) {
+        printf("periscope: restore not requested\n");
+        return -1;
+    }
+
+    periscope_snapshot_desc *s = restore_request;
+    restore_request = NULL;
+
+    rcu_read_lock();
+    // TODO
+    rcu_read_unlock();
+#endif
+
+    static qemu_timeval tv_restore_begin;
+    qemu_gettimeofday(&tv_restore_begin);
+
+    vm_stop(RUN_STATE_RESTORE_VM);
+
+#if 1
+
+    qemu_gettimeofday(&tv_restore_end);
+
+    qemu_timeval reset_elapsed;
+    timersub(&tv_restore_end, &tv_restore_begin, &reset_elapsed);
+    // printf("periscope: system reset time %lu ms\n",
+    //        reset_elapsed.tv_usec / 1000L);
+
+    //lseek(s->memfd, 0, SEEK_SET);
+    QIOChannelFile *iochannel;// = qio_channel_file_new_fd(dup(s->memfd));
+    QEMUFile *file;// = qemu_fopen_channel_input(QIO_CHANNEL(iochannel));
+    MigrationIncomingState* mis;// = migration_incoming_get_current();
+    //mis->from_src_file = file;
+
+    peri_timer *pt = NULL;
+    if(last_id != id || last_id < 0) {
+      pt = start_interval("periscope_restore.timer");
+      lseek(s->memfd, 0, SEEK_SET);
+      iochannel = qio_channel_file_new_fd(dup(s->memfd));
+      file = qemu_fopen_channel_input(QIO_CHANNEL(iochannel));
+      mis = migration_incoming_get_current();
+      mis->from_src_file = file;
+      qemu_system_reset(SHUTDOWN_CAUSE_NONE); // TODO: can we avoid this?
+      ret = qemu_loadvm_state(file);
+      stop_interval(pt);
+    } else {
+      pt = start_interval("periscope_quick_restore.timer");
+      lseek(s->memfd_quick, 0, SEEK_SET);
+      iochannel = qio_channel_file_new_fd(dup(s->memfd_quick));
+      file = qemu_fopen_channel_input(QIO_CHANNEL(iochannel));
+      mis = migration_incoming_get_current();
+      mis->from_src_file = file;
+
+      set_quick_reset_devs();
+      qemu_system_reset(SHUTDOWN_CAUSE_NONE); // TODO: can we avoid this?
+
+      set_quick_reset_ram();
+      ret = qemu_loadvm_state(file);
+      unset_quick_reset_ram();
+
+      unset_quick_reset_devs();
+      stop_interval(pt);
+    }
+
+    mis->from_src_file = NULL;
+    migration_incoming_state_destroy();
+    object_unref(OBJECT(iochannel));
+    qemu_fclose(file);
+    file = NULL;
+#else
+    Error *err = NULL;
+    if (load_snapshot_via_rollback(name, &err) == 0 && saved_vm_running) {
+        vm_start();
+    }
+    vm_start();
+#endif
+
+    qemu_gettimeofday(&tv_restore_end);
+
+    qemu_timeval elapsed;
+    timersub(&tv_restore_end, &tv_restore_begin, &elapsed);
+
+    timeradd(&elapsed, &total_restore_time, &total_restore_time);
+    if (timercmp(&elapsed, &max_restore_time, >)) {
+        printf("periscope: new max restore time %lu ms\n",
+               elapsed.tv_sec * 1000L + elapsed.tv_usec / 1000L);
+        memcpy(&max_restore_time, &elapsed, sizeof(qemu_timeval));
+    }
+    //printf("periscope: restore time %lu ms\n",
+    //      elapsed.tv_sec * 1000L + elapsed.tv_usec / 1000L);
+
+    assert(fs->cur_cp);
+
+    if (!fs->cur_cp->closed) {
+        delete_cp_desc(fs->cur_cp);
+        fs->cur_cp = NULL;
+    }
+
+    // base a new cp on the base snapshot of the new input.
+    fs->cur_cp = create_cp_desc(cp);
+
+    if (ret < 0) {
+        printf("periscope: restoring periscope-%u failed\n",
+               s->id);
+        return -1;
+    }
+
+#define TRACE_CHKPT_RESTORE
+//#undef TRACE_CHKPT_RESTORE
+#ifdef TRACE_CHKPT_RESTORE
+    static int last_restore_id = SNAPSHOT_ROOT_ID;
+    if (s->id != last_restore_id) {
+        printf("periscope: restoring periscope-%d (%u/%u bytes, saved %lu ms %u times) took %lu ms\n",
+                s->id,
+                fs->cur_input->used_len,
+                fs->cur_input->len,
+                calc_total_time_saved(fs->cur_input->base_cp),
+                fs->cur_input->base_cp->num_restored,
+                elapsed.tv_sec * 1000L + elapsed.tv_usec / 1000L);
+        last_restore_id = s->id;
+    }
+#endif
+    if (s->id != SNAPSHOT_ROOT_ID) {
+        total_non_root_restores += 1;
+    }
+
+    vm_start();
+
+    return 0;
+}
+#endif
+
+uint64_t periscope_get_estimated_restore_time_ms(void) {
+    // TODO: take into account the number of dirty pages
+    return 100;//FIXME
+}
+
+#define TRACE_NUM_DIRTY_PAGES
+#undef TRACE_NUM_DIRTY_PAGES
+
+#ifdef TRACE_NUM_DIRTY_PAGES
+static uint64_t get_num_dirty_pages(DirtyBitmapSnapshot *snap) {
+    uint64_t num_dirty_pages = 0;
+    unsigned long page, end;
+
+    ram_addr_t start = snap->start;
+    ram_addr_t length = snap->end;
+
+    end = TARGET_PAGE_ALIGN(start + length - snap->start) >> TARGET_PAGE_BITS;
+    page = (start - snap->start) >> TARGET_PAGE_BITS;
+
+    while (page < end) {
+        if (test_bit(page, snap->dirty)) {
+            num_dirty_pages++;
+        }
+        page++;
+    }
+    return num_dirty_pages;
+}
+#endif
+
+#ifdef ENABLE_DELTA_CHECKPOINT
+static void check_memory_regions(void) {
+#ifdef TRACE_NUM_DIRTY_PAGES
+    uint64_t total_dirty_pages = 0;
+#endif
+
+    //if (mr->ram_block) {
+    RAMBlock *rb;
+    INTERNAL_RAMBLOCK_FOREACH(rb) {
+        if (strcmp(rb->idstr, "pc.ram") != 0) {
+            continue;
+        }
+
+        //printf("ram_block=0x%p, size=0x%lx\n", rb->mr->ram_block, (uint64_t)rb->mr->size);
+
+        struct DirtyBitmapSnapshot *snap = memory_region_snapshot_and_clear_dirty(
+            rb->mr,
+            rb->mr->addr,
+            rb->mr->size,
+            DIRTY_MEMORY_MIGRATION // TODO: do we need a custom flag?
+        );
+
+#ifdef TRACE_NUM_DIRTY_PAGES
+        uint64_t num_dirty_pages = get_num_dirty_pages(snap);
+        if (strcmp(rb->idstr, "pc.ram") == 0) {
+            printf("periscope: pc.ram has %lu dirty pages\n", num_dirty_pages);
+        }
+        else {
+            printf("periscope: %s has %lu dirty pages\n", rb->idstr, num_dirty_pages);
+        }
+        total_dirty_pages += num_dirty_pages;
+#endif
+
+        //printf("snap=0x%p\n", snap);
+
+        //for (unsigned i = 0; i < rb->mr->size / 0x4000; i++) {
+        //    bool dirty = memory_region_snapshot_get_dirty(
+        //        rb->mr,
+        //        snap,
+        //        rb->mr->addr + 0x4000 * i,
+        //        0x4000
+        //    );
+        //    if (dirty) {
+        //        printf("0x%lx: dirty\n", rb->mr->addr + 0x4000 * i);
+        //    }
+        //}
+
+        if (rb->mr->ram_block->bmap2 == NULL) {
+           unsigned long npages = rb->mr->ram_block->max_length >> TARGET_PAGE_BITS;
+           rb->mr->ram_block->bmap2 = bitmap_new(npages);
+           printf("periscope: new dirty page bitmap created\n");
+        }
+
+        unsigned long npages_snap = (snap->end - snap->start) >> TARGET_PAGE_BITS;
+        //printf("%s bmap2 %p\n", rb->mr->ram_block->idstr, rb->mr->ram_block->bmap2);
+        memcpy(rb->mr->ram_block->bmap2, snap->dirty, BITS_TO_LONGS(npages_snap) * sizeof(unsigned long));
+        g_free(snap);
+    }
+
+#ifdef TRACE_NUM_DIRTY_PAGES
+    printf("periscope: %lu total dirty pages found\n", total_dirty_pages);
+#endif
+
+    //MemoryRegion *subregion;
+    //QTAILQ_FOREACH(subregion, &mr->subregions, subregions_link) {
+    //    check_memory_regions(subregion);
+    //}
+}
+#endif
+
+static periscope_input_desc *periscope_create_input_desc(char *input, uint32_t len) {
+    periscope_input_desc *new = malloc(sizeof(periscope_input_desc));
+    memset(new, 0, sizeof(periscope_input_desc));
+    new->input = (char *)malloc(len);
+    memcpy(new->input, input, len);
+    new->len = len;
+
+    return new;
+}
+
+static void periscope_delete_input_desc(periscope_input_desc *input_desc) {
+    if (input_desc->input) {
+        free(input_desc->input);
+        input_desc->input = NULL;
+    }
+    free(input_desc);
+}
+
+#define PRINT_THROUGHPUT
+#undef PRINT_THROUGHPUT
+
+void periscope_fetch_next_input(void) {
+    periscope_next_input();
+    return;
+
+}
+
+static peri_timer *fuzz_iteration_pt = NULL;
+static periscope_input_desc *periscope_next_input(void) {
+    if(fuzz_iteration_pt)
+       stop_interval(fuzz_iteration_pt);
+    fuzz_iteration_pt = start_interval("periscope_fuzz_interation.timer");
+
+    char pt_mark_buf[256];
+    snprintf(pt_mark_buf, 256, "## %s\n", __FUNCTION__);
+    pt_mark_all(pt_mark_buf);
+
+#ifdef PRINT_THROUGHPUT
+    static qemu_timeval tv_prev;
+    static int total_prev = 0;
+
+    if (total_execs % 100 == 0) {
+        if (total_execs > 1) {
+            qemu_timeval tv, sub;
+            qemu_gettimeofday(&tv);
+            timersub(&tv, &tv_prev, &sub);
+
+            printf("periscope: total inputs=%d, throughput=%.2f for the last %d inputs\n",
+                total_execs,
+                (float)(total_execs - total_prev) * 1000
+                / (sub.tv_sec * 1000 + sub.tv_usec / 1000),
+                total_execs - total_prev);
+
+            total_prev = total_execs;
+        }
+        qemu_gettimeofday(&tv_prev);
+    }
+#endif
+
+    trace_periscope_next_input(total_execs);
+    total_execs++;
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    periscope_input_desc *cur = s->cur_input;
+    assert(cur != NULL);
+
+#define AFL_COVERAGE_SUPPORT 1
+#if AFL_COVERAGE_SUPPORT
+    if (cur != &root && s->cur_executed) {
+        uint8_t *kcov_area = kcov_get_area();
+        if (kcov_area == NULL) {
+            printf("periscope: kcov_area not initialized\n");
+        }
+        else {
+            uint64_t now = qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL);
+            s->cur_executed(kcov_area, cur->used_len, now - last_chkpt_ms, timed_out);
+        }
+    }
+#endif
+
+    // update useful stats
+    if (cur->num_irqs > max_irqs) {
+        max_irqs = cur->num_irqs;
+        printf("periscope: new max irqs %u\n", max_irqs);
+    }
+
+    if (cur->num_io_reads > max_io_reads) {
+        max_io_reads = cur->num_io_reads;
+        printf("periscope: new max io reads %u\n", max_io_reads);
+    }
+
+    if (cur->used_len > max_used_len) {
+        max_used_len = cur->used_len;
+        printf("periscope: new max used len %u bytes\n", max_used_len);
+    }
+
+    // reset timeout flag
+    timed_out = 0;
+
+    uint32_t next_len;
+    uint32_t matched_len = 0;
+    char *next = NULL;
+
+    if (s->fetch_next) {
+        next = s->fetch_next(&next_len);
+    }
+
+    if (next == NULL) {
+        // printf("periscope: no next input exists.\n");
+        return NULL;
+    }
+
+    // printf("periscope: input (%u B) fetched \n", next_len);
+
+    periscope_cp_desc *closest = &cp_root;
+    if(!no_restore) {
+       closest =
+          periscope_find_closest_snapshot(next, next_len, cur, &matched_len);
+
+       static int last_restore_id = -1;
+       if (closest->snapshot.id != last_restore_id) {
+          printf("periscope: closest snapshot %d, exec time %lu + (%lu) ms, len %d, match %d\n",
+                closest->snapshot.id,
+                closest->exec_time.tv_sec * 1000L + closest->exec_time.tv_usec / 1000L,
+                get_exec_time_ms(closest->parent),
+                next_len, matched_len);
+          last_restore_id = closest->snapshot.id;
+       }
+    }
+
+    periscope_input_desc *new = periscope_create_input_desc(next, next_len);
+    new->restored_cp = closest;
+    new->num_pages_restored = 0;
+    new->base_cp = closest;
+    new->used_len = matched_len;
+
+    assert(new->len >= new->used_len);
+
+    if (s->cur_input != &root) {
+        periscope_delete_input_desc(s->cur_input);
+    }
+    s->cur_input = new;
+
+    return 0;
+}
+
+void periscope_restore_request(void) {
+    vm_stop(RUN_STATE_RESTORE_VM);
+
+    FuzzerState *s = fuzzer_get_current();
+    assert(s != NULL);
+
+    if(no_restore) return;
+    // printf("periscope: restore request\n");
+
+    // timeout for restore
+    timer_mod(s->timer, qemu_clock_get_ms(QEMU_CLOCK_HOST) + 5000000);
+    timeout_reason = TIMEOUT_RESTORE;
+
+    restore_request = 1;
+}
+
+int periscope_mmio_check(MemoryRegion *mr, uint32_t len, uint8_t is_write) {
+    if (no_restore)
+       return 0;
+
+    if (is_write)
+        return 0;
+
+    if (single_exec)
+        return 0;
+
+    if (!fuzzer_get_current())
+        return 0;
+
+    periscope_input_desc *cur = fuzzer_get_current()->cur_input;
+    if (!cur)
+        return 0;
+
+    if (!mr)
+        return 0;
+
+    if (!mr->name)
+        return 0;
+
+    if (!strstart(mr->name, "periscope-", NULL))
+        return 0;
+
+    if (cur->len - cur->used_len < len) {
+        //printf("input consumed %d\n", cur->used_len);
+        return -1;
+    }
+
+    return 0; // OK
+}
+
+static uint64_t seed = 0xDEAD;
+
+#define TRACE_IRQ_ASSERT
+
+int periscope_maybe_raise_irq(PCIDevice *pci_dev) {
+    FuzzerState *s = fuzzer_get_current();
+
+    if (!s)
+       return 0;
+
+    if (s->irq_pending) {
+#ifdef TRACE_IRQ_ASSERT
+        printf("periscope: pci_irq_assert\n");
+#endif
+        pci_irq_assert(pci_dev);
+        s->irq_pending = false;
+    }
+
+    return 0;
+}
+
+#define PERI_KEY_IRQ_CHECK 1
+#if PERI_KEY_IRQ_CHECK == 1
+
+#define PERISCOPE_IRQ_TOKEN (uint32_t)0xaddeadde
+
+static int lookahead_tokens(periscope_input_desc* cur, uint32_t token) {
+    int num_tokens = 0;
+
+    while (cur->used_len + sizeof(uint32_t) <= cur->len) {
+        if (*((uint32_t*)&cur->input[cur->used_len]) != token) {
+            break;
+        }
+        cur->used_len += sizeof(uint32_t);
+        num_tokens++;
+    }
+
+    return num_tokens;
+}
+#endif
+
+int periscope_mmio_read(void* opaque, unsigned size, uint64_t *out) {
+    int ret = 0;
+
+    FuzzerState *s = fuzzer_get_current();
+    if (!s || !s->cur_input) {
+        // just return some value for the sake of performance profiling
+        *out = seed++;
+        return 0;
+    }
+
+    s->cur_input->num_io_reads++;
+
+    if (s->dev == NULL) {
+        s->dev = opaque;
+    }
+
+    if (s->cur_input->len - s->cur_input->used_len < size) {
+        if (single_exec || no_restore) {
+            *out = 0xbabababababababa;
+            printf("periscope: no input left. returning 0x%lx\n", *out);
+            return 0;
+        }
+
+        printf("periscope: no input left!\n");
+        return -1;
+    }
+
+    if (s->mmio_read) {
+        ret = s->mmio_read(size, out);
+    }
+    else {
+        *out = 0x0;
+        s->cur_input->used_len += size;
+    }
+
+    if(no_restore) {
+      return 0;
+    }
+    if (s->cur_cp->len + size < MAX_INPUT_BYTES) {
+        switch (size) {
+        case 1:
+            *(uint8_t*)&s->cur_cp->io[s->cur_cp->len] = (uint8_t)*out;
+            break;
+        case 2:
+            *(uint16_t*)&s->cur_cp->io[s->cur_cp->len] = (uint16_t)*out;
+            break;
+        case 4:
+            *(uint32_t*)&s->cur_cp->io[s->cur_cp->len] = (uint32_t)*out;
+            break;
+        case 8:
+            *(uint64_t*)&s->cur_cp->io[s->cur_cp->len] = (uint64_t)*out;
+            break;
+        default:
+            printf("periscope: unexpected size!\n");
+        }
+        s->cur_cp->len += size;
+    }
+    else {
+        printf("periscope: input length cannot exceed %ld!\n", MAX_INPUT_BYTES);
+    }
+
+#if PERI_KEY_IRQ_CHECK == 1
+    int num_irq_tokens = lookahead_tokens(s->cur_input, PERISCOPE_IRQ_TOKEN);
+    if (num_irq_tokens > 0) {
+#ifdef TRACE_IRQ_ASSERT
+        printf("periscope: %d irq tokens ahead consumed\n", num_irq_tokens);
+#endif
+        s->cur_input->num_irqs += num_irq_tokens;
+        s->irq_pending = true;
+
+        while (num_irq_tokens > 0) {
+            if (s->cur_cp->len + sizeof(uint32_t) > MAX_INPUT_BYTES) {
+                printf("periscope: not enough chkpt storage\n");
+                break;
+            }
+
+            *(uint32_t*)&s->cur_cp->io[s->cur_cp->len] = PERISCOPE_IRQ_TOKEN;
+            s->cur_cp->len += sizeof(uint32_t);
+            num_irq_tokens--;
+        }
+    }
+#endif
+
+    if (!single_exec) {
+        timer_mod(s->timer, qemu_clock_get_ms(QEMU_CLOCK_HOST) + MMIO_RESPONSE_TIMEOUT);
+        timeout_reason = TIMEOUT_MMIO;
+    }
+
+    return ret;
+}
+
+uint32_t periscope_get_stat(int stat)
+{
+    uint32_t statVal;
+
+    FuzzerState *fs = fuzzer_get_current();
+    if (!fs || !fs->cur_input)
+        return 0;
+
+    if (fs->get_stat && fs->get_stat(stat, &statVal)) {
+        return statVal;
+    }
+
+    if (stat == stat_saved_time || stat == stat_time_saved_total) {
+        periscope_cp_desc *cp = fs->cur_input->restored_cp;
+        uint32_t exec_time_ms = 0;
+        while (cp != &cp_root) {
+            exec_time_ms +=
+                cp->exec_time.tv_sec * 1000L + cp->exec_time.tv_usec / 1000L;
+            cp = cp->parent;
+        }
+        return exec_time_ms;
+    }
+    else if (stat == stat_exec_time || stat == stat_time_exec_total) {
+        periscope_cp_desc *cp = fs->cur_cp;
+        uint32_t exec_time_ms = 0;
+        while (cp != &cp_root) {
+            exec_time_ms +=
+                cp->exec_time.tv_sec * 1000L + cp->exec_time.tv_usec / 1000L;
+            cp = cp->parent;
+        }
+        return exec_time_ms;
+    }
+#ifdef PERI_DEDUP_STAT
+    else if (stat == stat_chkpt_time) {
+       return (uint32_t)(last_chkpt_time.tv_sec * 1000L * 1000L + last_chkpt_time.tv_usec) / 10; // 10us
+    }
+    else if (stat == stat_restore_time) {
+       return (uint32_t)(last_restore_time.tv_sec * 1000L * 1000L + last_restore_time.tv_usec) / 10; // 10us
+    }
+#endif
+    else if (stat == stat_actual_time) {
+        periscope_cp_desc *cp = fs->cur_cp;
+        uint32_t exec_time_ms = 0;
+        while (cp != fs->cur_input->restored_cp) {
+            exec_time_ms +=
+                cp->exec_time.tv_sec * 1000L + cp->exec_time.tv_usec / 1000L;
+            cp = cp->parent;
+        }
+        return exec_time_ms;
+    }
+    else if (stat == stat_non_root_restores) {
+        if (fs->cur_input->restored_cp != &cp_root) {
+            return 1;
+        }
+        return 0;
+    }
+    else if (stat == stat_chkpts_created) {
+        int num_chkpts_created = 0;
+        periscope_cp_desc *cp = fs->cur_input->base_cp;
+        while (cp != fs->cur_input->restored_cp) {
+            num_chkpts_created++;
+            cp = cp->parent;
+        }
+        return num_chkpts_created;
+    }
+    else if (stat >= stat_evict_policy1 && stat <= stat_evict_policy4) {
+        int policy = stat - stat_evict_policy1;
+        if (policy < sizeof(num_evicted)/sizeof(num_evicted[0])) {
+            return num_evicted[policy];
+        }
+        return 0;
+    }
+#ifdef PERI_DEDUP_STAT
+    else if (stat == stat_zero) {
+#if !defined(PERI_DEDUP)  || defined(PERI_DEDUP_NOHASH)
+       return 0;
+#else
+       unsigned long num_zero_pages = 0;
+       periscope_cp_desc *cp = fs->cur_input->base_cp;
+       while (cp != fs->cur_input->restored_cp) {
+          num_zero_pages += count_zero_pages_prbs(cp->snapshot.peri_rb, cp->snapshot.n_peri_rb);
+          cp = cp->parent;
+       }
+       return num_zero_pages;
+#endif
+    }
+    else if (stat == stat_skipped) {
+#if !defined(PERI_DEDUP)  || defined(PERI_DEDUP_NOHASH)
+       return 0;
+#else
+       unsigned long num_skipped_pages = 0;
+       periscope_cp_desc *cp = fs->cur_input->base_cp;
+       while (cp != fs->cur_input->restored_cp) {
+          num_skipped_pages += count_skipped_pages_prbs(cp->snapshot.peri_rb, cp->snapshot.n_peri_rb);
+          cp = cp->parent;
+       }
+       return num_skipped_pages;
+#endif
+    }
+
+
+    else if (stat == stat_dedup) {
+#if !defined(PERI_DEDUP)  || defined(PERI_DEDUP_NOHASH)
+       return 0;
+#else
+       unsigned long num_unique_pages = 0;
+       unsigned long num_stored_pages = 0;
+       periscope_cp_desc *cp = fs->cur_input->base_cp;
+       while (cp != fs->cur_input->restored_cp) {
+          num_unique_pages += count_hashed_pages_prbs(cp->snapshot.peri_rb, cp->snapshot.n_peri_rb);
+          num_stored_pages += count_stored_pages_prbs(cp->snapshot.peri_rb, cp->snapshot.n_peri_rb);
+          cp = cp->parent;
+       }
+       return num_stored_pages - num_unique_pages;
+#endif
+    }
+    else if (stat == stat_hashed) {
+#if !defined(PERI_DEDUP)  || defined(PERI_DEDUP_NOHASH)
+       return 0;
+#else
+       unsigned long num_unique_pages = 0;
+       periscope_cp_desc *cp = fs->cur_input->base_cp;
+       while (cp != fs->cur_input->restored_cp) {
+          num_unique_pages += count_hashed_pages_prbs(cp->snapshot.peri_rb, cp->snapshot.n_peri_rb);
+          cp = cp->parent;
+       }
+       return num_unique_pages;
+#endif
+    }
+#endif /* PERI_DEDUP_STAT */
+    else if (stat == stat_restored) {
+        return fs->cur_input->num_pages_restored;
+    }
+    else if (stat == stat_dirtied) {
+#ifndef PERI_DEDUP
+        unsigned long *dirty = NULL;
+        unsigned long num_pages = get_current_delta_bm(&dirty);
+        assert(dirty != NULL);
+
+        periscope_cp_desc *cp = fs->cur_input->base_cp;
+        while (cp != fs->cur_input->restored_cp) {
+            bitmap_or(dirty, dirty, cp->snapshot.dirty, num_pages);
+            cp = cp->parent;
+        }
+
+        unsigned long num_dirty_pages = bitmap_count_one(dirty, num_pages);
+        g_free(dirty);
+        fs->cur_input->num_pages_dirtied = num_dirty_pages;
+        return fs->cur_input->num_pages_dirtied;
+#else
+        unsigned long num_dirty_pages = 0;
+        RAMBlock *rb = NULL;
+        rcu_read_lock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+        RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+           struct DirtyBitmapSnapshot *db_snap = memory_region_snapshot_and_get_dirty(
+                 rb->mr,
+                 0, rb->max_length,
+                 DIRTY_MEMORY_DELTA // TODO: do we need a custom flag?
+                 );
+           assert(db_snap);
+           assert(db_snap->dirty != NULL);
+           unsigned long npages = (db_snap->end - db_snap->start) >> TARGET_PAGE_BITS;
+           unsigned long *dirty = db_snap->dirty;
+           periscope_cp_desc *cp = fs->cur_input->base_cp;
+           while (cp != fs->cur_input->restored_cp) {
+              periscope_snapshot_desc *snap = &cp->snapshot;
+              cp = cp->parent;
+              periscope_ramblock *prb  = get_ramblock(snap->peri_rb, snap->n_peri_rb, rb->idstr);
+              assert(prb);
+              if(prb->empty) continue;
+              assert(prb != NULL);
+              assert(prb->dirty != NULL);
+              assert(npages == prb->npages);
+              bitmap_or(dirty, dirty, prb->dirty, npages);
+           }
+           num_dirty_pages += bitmap_count_one(dirty, npages);
+           g_free(db_snap);
+        }
+        rcu_read_unlock(); // see comment on INTERNAL_RAMBLOCK_FOREACH
+        fs->cur_input->num_pages_dirtied = num_dirty_pages;
+        return num_dirty_pages;
+#endif
+    }
+    else if (stat >= stat_chkpt_size_0 && stat <= stat_chkpt_size_max) {
+        int idx = 0;
+
+        periscope_cp_desc *cp = fs->cur_input->base_cp;
+        while (cp != fs->cur_input->restored_cp) {
+            if (idx == stat - stat_chkpt_size_0) {
+#if defined(PERI_DEDUP) && !defined(PERI_DEDUP_NOHASH)
+                return compute_memory_cost(cp) +
+                   compute_hash_cost(cp->snapshot.peri_rb, cp->snapshot.n_peri_rb)/1024U;
+#else
+                return compute_memory_cost(cp);
+#endif
+            }
+            idx++;
+            cp = cp->parent;
+        }
+
+        return 0;
+    }
+    // TODO: more stats
+
+    return 0;
+}
+
+#define TRACE_CP_DESC
+#undef TRACE_CP_DESC
+
+#ifdef ENABLE_LW_CHKPT
+static int close_cp_desc(periscope_cp_desc *cpd, uint16_t snapid, int memfd_ram, int memfd_quick, unsigned long *dirty, unsigned long npages) {
+#else
+static int close_cp_desc(periscope_cp_desc *cpd, uint16_t snapid, int memfd, int memfd_quick) {
+#endif
+    if (cpd->closed) {
+        printf("periscope: chkpt already closed!\n");
+        return 0;
+    }
+
+    if (cpd != &cp_root && cpd->len == 0) {
+        printf("periscope: chkpt requested with an empty io history\n");
+        return -1;
+    }
+
+    cpd->snapshot.id = snapid;
+#ifndef ENABLE_LW_CHKPT
+    cpd->snapshot.memfd = memfd;
+#else
+#ifndef PERI_DEDUP
+    cpd->snapshot.memfd_quick = memfd_quick;
+    cpd->snapshot.memfd_ram = memfd_ram;
+    // TODO: maybe copy and free in parent?
+    //cpd->snapshot.dirty = dirty;
+    cpd->snapshot.dirty = bitmap_new(npages);
+    bitmap_copy(cpd->snapshot.dirty, dirty, npages);
+    cpd->snapshot.npages = npages;
+#endif
+#endif
+    cpd->closed = true;
+    qemu_gettimeofday(&cpd->closed_time);
+
+    if (cpd->parent) {
+        cpd->parent->children[cpd->parent->n_children] = cpd;
+        cpd->parent->n_children++;
+    }
+
+#ifdef TRACE_CP_DESC
+    printf("closed new cp desc %p with id %d\n", cpd, snapid);
+#endif
+
+    return 0;
+}
+
+static int delete_cp_desc(periscope_cp_desc *cpd) {
+    if (cpd && cpd != &cp_root) {
+#ifdef ENABLE_LW_CHKPT
+#ifndef PERI_DEDUP
+        if (cpd->snapshot.dirty) {
+            g_free(cpd->snapshot.dirty);
+            cpd->snapshot.dirty = NULL;
+        }
+#else
+        //delete_peri_rbs(cpd->snapshot.peri_rb, cpd->snapshot.n_peri_rb);
+        //cpd->snapshot.peri_rb = NULL;
+        //cpd->snapshot.n_peri_rb = 0;
+#endif
+#endif
+        free(cpd);
+        return 0;
+    }
+    return -1;
+}
+
+static periscope_cp_desc *create_cp_desc(periscope_cp_desc *parent) {
+    assert(parent);
+
+#ifdef TRACE_CP_DESC
+    printf("Adding new cp desc to parent snapshot id %d\n", parent->snapshot.id);
+#endif
+
+    if (parent->n_children > MAX_CP_DESC_CHILDREN - 1) {
+        printf("periscope: too many children!\n");
+        return NULL;
+    }
+
+    periscope_cp_desc *new_cp = (periscope_cp_desc *)malloc(sizeof(periscope_cp_desc));
+    new_cp->len = 0;
+
+    new_cp->n_children = 0;
+    new_cp->parent = parent;
+
+    new_cp->closed = false;
+
+    new_cp->num_restored = 0;
+
+    new_cp->last_restored.tv_sec = 0;
+    new_cp->last_restored.tv_usec = 0;
+
+    new_cp->exec_time.tv_sec = 0;
+    new_cp->exec_time.tv_usec = 0;
+
+    new_cp->closed_time.tv_sec = 0;
+    new_cp->closed_time.tv_usec = 0;
+
+    new_cp->snapshot.id = SNAPSHOT_INVALID;
+#ifndef PERI_DEDUP
+    new_cp->snapshot.memfd = -1;
+    new_cp->snapshot.memfd_quick = -1;
+    new_cp->snapshot.memfd_ram = -1;
+    new_cp->snapshot.buf_quick = NULL;
+    new_cp->snapshot.buf_ram = NULL;
+#ifdef ENABLE_LW_CHKPT
+    new_cp->snapshot.dirty = NULL;
+#ifdef DBG_RAM_STORED // set in periscope.h
+    new_cp->snapshot.rambkp = NULL;
+    new_cp->snapshot.rambkp_size = 0;
+#endif
+#endif
+#else
+    new_cp->snapshot.buf_dev = NULL;
+    new_cp->snapshot.dev_sz = 0;
+    new_cp->snapshot.peri_rb = NULL;
+    new_cp->snapshot.n_peri_rb = 0;
+#endif
+
+    return new_cp;
+}
+
+int periscope_irq_check(void) {
+    static qemu_timeval cur;
+
+    qemu_timeval prev = cur;
+    qemu_gettimeofday(&cur);
+
+    qemu_timeval sub;
+    timersub(&cur, &prev, &sub);
+
+#if 0
+    printf("periscope: irq check - %lu (s) + %lu (us) elapsed since last check\n",
+           sub.tv_sec, sub.tv_usec);
+#endif
+
+    return 0;
+}
+
+uint64_t periscope_checkpoint_requested(void) {
+    int r = checkpoint_request;
+    checkpoint_request = 0;
+    return r;
+}
+
+uint64_t periscope_restore_requested(void) {
+    if (!snapshot_inited)
+        return 0;
+
+    FuzzerState *fs = fuzzer_get_current();
+    if (!restore_request && fs && fs->should_restore) {
+        if (suspended && fs->should_restore())
+            restore_request = 1;
+    }
+
+    if (restore_request) {
+        return 1;
+    }
+    return 0;
+}
+
+static ShutdownCause shutdown_requested;
+
+int periscope_system_shutdown_request(ShutdownCause reason) {
+    if (reason == SHUTDOWN_CAUSE_GUEST_PANIC) {
+        shutdown_requested = reason;
+        return 0;
+    }
+    return -1;
+}
+
+int periscope_shutdown_requested(void) {
+    return shutdown_requested;
+}
+
+#define TRACE_TIMEOUT
+#undef TRACE_TIMEOUT
+
+static void periscope_on_timeout(void *opaque) {
+#ifdef TRACE_TIMEOUT
+    printf("periscope: timeout reason=%s\n",
+        timeout_reason == TIMEOUT_RESTORE ? "RESTORE" :
+        timeout_reason == TIMEOUT_CHECKPOINT ? "CHECKPOINT" :
+        timeout_reason == TIMEOUT_MMIO ? "MMIO" :
+        timeout_reason == TIMEOUT_INTERRUPT ? "INTERRUPT" :
+        "UNKNOWN");
+#endif
+
+    FuzzerState *s = opaque;
+    assert(s);
+
+    // raise a pending irq, if any, and delay the timeout for another interval
+    if (s->irq_pending) {
+        printf("periscope: draining pending irqs...\n");
+        periscope_maybe_raise_irq(&s->dev->parent_obj);
+
+        timer_mod(s->timer, qemu_clock_get_ms(QEMU_CLOCK_HOST) + INTERRUPT_RESPONSE_TIMEOUT);
+        timeout_reason = TIMEOUT_INTERRUPT;
+        return;
+    }
+
+    timed_out = 1;
+
+    //timer_del(s->timer);
+    //timer_mod(s->timer, qemu_clock_get_ms(QEMU_CLOCK_VIRTUAL) + 1);
+
+    // TODO: shutdown guest
+    periscope_restore_request();
+    vm_stop(RUN_STATE_SAVE_VM);
+}
+
+static FuzzerState *current_fuzzer = NULL;
+
+static uint8_t get_queue_cur_info_default(void) {
+    printf("periscope: default cur info\n");
+    return 0;
+}
+
+static void fuzzer_object_init(FuzzerState *fuzzer) {
+    fuzzer->dev = NULL;
+
+    fuzzer->irq_pending = false;
+
+    fuzzer->mmio_read = NULL;
+    fuzzer->fetch_next = NULL;
+    fuzzer->get_cur = NULL;
+    fuzzer->cur_executed = NULL;
+    fuzzer->restored = NULL;
+    fuzzer->should_restore = NULL;
+    fuzzer->guest_crashed = NULL;
+    fuzzer->get_stat = NULL;
+    fuzzer->get_queue_cur_info = get_queue_cur_info_default;
+
+    fuzzer->root = &root;
+    fuzzer->cur_input = &root;
+    fuzzer->cur_cp = &cp_root;
+
+#ifdef ENABLE_LW_CHKPT
+#ifndef PERI_DEDUP
+    MachineState *machine = MACHINE(qdev_get_machine());
+    assert(machine != NULL);
+    cp_root.snapshot.npages = machine->ram_size / TARGET_PAGE_SIZE;
+    cp_root.snapshot.dirty = bitmap_new(cp_root.snapshot.npages);
+    bitmap_fill(cp_root.snapshot.dirty, cp_root.snapshot.npages);
+    //memset(cp_root.snapshot.dirty, 0xff, cp_root.snapshot.npages / 8);
+#endif
+#endif
+
+    fuzzer->timer =
+        timer_new_ms(QEMU_CLOCK_HOST, periscope_on_timeout, fuzzer);
+
+    char *root_only = getenv("__PERISCOPE_ROOT_ONLY_CHKPT");
+    root_only_chkpt = root_only != NULL && strcmp(root_only, "root_only") == 0;
+    char *no_restore_str = getenv("__PERISCOPE_NO_RESTORE");
+    no_restore = no_restore_str != NULL && strcmp(no_restore_str, "no_restore") == 0;
+}
+
+static void fuzzer_object_finalize(void)
+{
+    // TODO: iterate through input and snapshot descriptors to deallocate them.
+    printf("periscope: deleting fuzzer object\n");
+    object_unref(OBJECT(current_fuzzer));
+    current_fuzzer = NULL;
+}
+
+FuzzerState *fuzzer_get_current(void)
+{
+    return current_fuzzer;
+}
+
+// TODO
+void periscope_debug_hypercall(uint64_t a0, uint64_t a1, uint64_t a2) {
+    printf("periscope: debug hypercall 0x%lx 0x%lx 0x%lx\n", a0, a1, a2);
+
+    RAMBlock *block = qemu_ram_block_by_name("pc.ram");
+    if(!block) {
+        printf("periscope: could not find ramblock\n");
+        return;
+    }
+
+    uint64_t *addr = host_from_ram_block_offset(block, a1);
+    switch (a0) {
+    case 3:
+        if (addr) {
+            printf("*inmem=0x%lx\n", *addr);
+        }
+        periscope_syzkaller_send_addr_offset(a1);
+        break;
+    case 4:
+        if (addr) {
+            printf("*outmem=0x%lx\n", *addr);
+        }
+        periscope_syzkaller_send_addr_offset(a1);
+        break;
+    default:
+        printf("periscope: unknown parameters for debug hypercall a0=0x%lx a1=0x%lx\n", a0, a1);
+        break;
+    }
+}
+
+bool should_restore_at_agent_exit(uint64_t code)
+{
+    if (!current_fuzzer) return false;
+
+    if (code == 0) {
+        //printf("periscope: guest agent exited successfully\n");
+    } else
+        printf("periscope: guest agent exited with code %ld\n",
+               (int64_t)code);
+
+    switch (current_fuzzer->mode) {
+    case PERISCOPE_MODE_AFL:
+    case PERISCOPE_MODE_COVERAGE:
+        return true;
+    }
+
+    return false;
+}
+
+bool should_shutdown_at_agent_exit(uint64_t code)
+{
+    if ((code & 0xffff0000) == 0xdead0000) {
+        printf("periscope: guest agent requested shutdown\n");
+        return true;
+    }
+    printf("periscope: guest agent did not request shutdown %lu\n", code);
+    return false;
+}
+
+void periscope_notify_boot(void) {
+    FuzzerState *fs = fuzzer_get_current();
+
+    if (fs && fs->mode == PERISCOPE_MODE_SYZKALLER_USBFUZZER) {
+        periscope_syzkaller_notify_boot();
+    }
+}
+
+static uint32_t agent_id = 0xdeadbeef;
+
+uint32_t periscope_get_agent_id(void) {
+    printf("periscope: returning agent id %d\n", agent_id);
+
+    return agent_id;
+}
+
+static const char *parse_agent_id(const char *arg) {
+    char str[256];
+    char *tok;
+
+    strncpy(str, arg, sizeof(str));
+
+    tok = strtok(str, ",");
+    if (!tok) return NULL;
+
+    agent_id = strtol(tok, NULL, 0);
+
+    printf("periscope: agent id %d\n", agent_id);
+
+    tok = strtok(NULL, ",");
+    if (!tok) return NULL;
+
+    return arg + (tok - str);
+}
+
+// legacy
+void periscope_start_fuzzer(const char *uri, Error **errp)
+{
+    const char *p;
+
+    assert(!current_fuzzer);
+    current_fuzzer = FUZZER_OBJ(object_new(TYPE_FUZZER));
+
+    fuzzer_object_init(current_fuzzer);
+    if (strstart(uri, "syzkaller:", &p)) {
+        p = parse_agent_id(p);
+        start_syzkaller_fuzzer(p, -1, -1, NULL, -1, errp);
+    }
+    else if (strstart(uri, "afl:", &p)) {
+        p = parse_agent_id(p);
+        start_afl_fuzzer(p, -1, -1, -1, errp);
+    }
+    else if (strstart(uri, "kcov:", &p)) {
+        p = parse_agent_id(p);
+        start_coverage_collector(p, errp);
+    }
+    else if (strstart(uri, "exec:", &p)) {
+        single_exec = true;
+        p = parse_agent_id(p);
+        start_input_executor(p, errp);
+    }
+    else if (strstart(uri, "dummy:", &p)) {
+        p = parse_agent_id(p);
+        // TODO
+    }
+    else if (strstart(uri, "none:", &p)) {
+        p = parse_agent_id(p);
+        fuzzer_object_finalize();
+    }
+    else {
+        error_setg(errp, "unknown fuzzer protocol: %s", uri);
+        fuzzer_object_finalize();
+    }
+}
+
+static Property fuzzer_properties[] = {
+    DEFINE_PROP_STRING("uri", FuzzerState, uri), // format: "fuzzer:agent_id"
+    DEFINE_PROP_INT32("st_pipe", FuzzerState, st_pipe, -1),
+    DEFINE_PROP_INT32("ctl_pipe", FuzzerState, ctl_pipe, -1),
+    DEFINE_PROP_STRING("mgr_pipe", FuzzerState, mgr_pipe),
+    DEFINE_PROP_INT32("shm_id", FuzzerState, shm_id, -1),
+    DEFINE_PROP_INT32("chkpt_pool_size", FuzzerState, chkpt_pool_size, 1024), // unit: MB
+    DEFINE_PROP_INT32("fuzzer_id", FuzzerState, fuzzer_id, -1),
+#if 1
+    DEFINE_PROP_LINK("hostmem1", FuzzerState, hostmem[0], TYPE_MEMORY_BACKEND,
+                     HostMemoryBackend *),
+    DEFINE_PROP_LINK("hostmem2", FuzzerState, hostmem[1], TYPE_MEMORY_BACKEND,
+                     HostMemoryBackend *),
+#else
+    DEFINE_PROP_LINK("shmem1", FuzzerState, shmem[0], "ivshmem-plain",
+                     IVShmemState *),
+#endif
+    DEFINE_PROP_END_OF_LIST(),
+};
+
+#define FUZZER_TEST
+#undef FUZZER_TEST
+
+#ifdef FUZZER_TEST
+static void fuzzer_test(FuzzerState *fs)
+{
+    if (fs) {
+        MemoryRegion *mr = fs->mr[0];
+        if (mr) {
+            uint64_t *ptr = memory_region_get_ram_ptr(mr);
+            printf("periscope: ptr=0x%lx *ptr=0x%lx\n", (uint64_t)ptr, *ptr);
+        }
+    }
+}
+#endif
+
+static void fuzzer_realize(DeviceState *dev, Error **errp)
+{
+    FuzzerState *s = FUZZER_OBJ(dev);
+
+    fuzzer_object_init(s);
+
+    const char *p;
+
+    // let the module have convenient access to the fuzzer device by caching it
+    // to a static variable
+    current_fuzzer = s;
+
+    if (strstart(s->uri, "syzkaller:", &p)) {
+        p = parse_agent_id(p);
+        start_syzkaller_fuzzer(NULL, s->st_pipe, s->ctl_pipe,
+                               s->mgr_pipe, s->shm_id, errp);
+    }
+    else if (strstart(s->uri, "profiler:", &p)) {
+        p = parse_agent_id(p);
+        start_profiler(0, errp);
+    }
+    else if (strstart(s->uri, "profiler-baseline:", &p)) {
+        p = parse_agent_id(p);
+        start_profiler(1, errp);
+    }
+    else if (strstart(s->uri, "afl:", &p)) {
+        p = parse_agent_id(p);
+        start_afl_fuzzer(NULL, s->st_pipe, s->ctl_pipe, s->shm_id, errp);
+    }
+    // TODO(dokyungs): add support other fuzzers
+
+#if 1
+    if (s->hostmem[0]) {
+        s->mr[0] = &s->hostmem[0]->mr;
+    }
+    if (s->hostmem[1]) {
+        s->mr[1] = &s->hostmem[1]->mr;
+    }
+#else
+    if (s->shmem[0] && s->shmem[0]->ivshmem_bar2) {
+        s->mr[0] = s->shmem[0]->ivshmem_bar2;
+    }
+#endif
+
+#ifdef PERI_DEDUP
+   delta_snap_init(s->fuzzer_id, s->chkpt_pool_size);
+   cp_root.snapshot.n_peri_rb = create_prb_and_fill(&cp_root.snapshot.peri_rb, NULL, SNAPSHOT_ROOT_ID, false);
+#endif
+
+#ifdef FUZZER_TEST
+    fuzzer_test(s);
+#endif
+}
+
+static void fuzzer_class_init(ObjectClass *klass, void *data)
+{
+    DeviceClass *dc = DEVICE_CLASS(klass);
+
+    dc->props = fuzzer_properties;
+    dc->realize = fuzzer_realize;
+}
+
+static const TypeInfo fuzzer_type = {
+    .name = TYPE_FUZZER,
+    .parent = TYPE_DEVICE,
+    .class_size = sizeof(FuzzerClass),
+    .instance_size = sizeof(FuzzerState),
+    .class_init = fuzzer_class_init,
+};
+
+static void register_fuzzer_types(void)
+{
+    type_register_static(&fuzzer_type);
+}
+
+type_init(register_fuzzer_types);
diff --git migration/periscope.h migration/periscope.h
new file mode 100644
index 0000000000..9f98e745ab
--- /dev/null
+++ migration/periscope.h
@@ -0,0 +1,410 @@
+#ifndef PERISCOPE_H
+#define PERISCOPE_H
+
+#include <stdint.h>
+#include "qemu/thread.h"
+#include "qom/object.h"
+#include "sysemu/sysemu.h"
+#include "sysemu/hostmem.h"
+#include "hw/periscope/pci.h"
+#include "migration/periscope-delta-snap.h"
+
+// afl-2.52b/config.h
+// #define MAX_FILE            (1 * 1024 * 1024)
+
+//#define kMaxInput 1024 * 1024
+
+// syzkaller
+#define kMaxInput (2 << 22)
+
+struct syzkaller_execute_req {
+    uint64_t magic;
+    uint64_t env_flags;
+    uint64_t exec_flags;
+    uint64_t pid;
+    uint64_t fault_call;
+    uint64_t mut_from_nth;//fault_nth;
+    uint64_t prog_size;
+};
+
+#define MAX_INPUT_BYTES (kMaxInput + sizeof(struct syzkaller_execute_req))
+
+uint32_t periscope_get_agent_id(void);
+void periscope_configure_dev(const char *optarg);
+
+bool periscope_snapshot_inited(void);
+int periscope_total_execs(void);
+
+int periscope_mmio_check(MemoryRegion *mr, uint32_t, uint8_t);
+int periscope_mmio_read(void *, unsigned, uint64_t *);
+
+int periscope_irq_check(void);
+int periscope_maybe_raise_irq(PCIDevice *pci_dev);
+
+enum PERISCOPE_CHKPT_POLICY {
+    PERISCOPE_CHKPT_TIME_AND_COV, // conservative default
+    PERISCOPE_CHKPT_TIME_ONLY,
+    PERISCOPE_CHKPT_DISABLED,           // disable checkpoint
+    PERISCOPE_CHKPT_TIME_ONLY_DISABLED_AFTER_NTH, // disable checkpoint after nth op
+    PERISCOPE_CHKPT_MAX,
+};
+
+enum PERISCOPE_RESTORE_POLICY {
+    PERISCOPE_RESTORE_LONGEST,
+    PERISCOPE_RESTORE_ROOT,
+};
+
+int periscope_change_chkpt_policy(int, int);
+
+int periscope_purge_and_checkpoint_request(void);
+int periscope_maybe_checkpoint_request(void);
+void periscope_checkpoint_request(void);
+uint64_t periscope_checkpoint_requested(void);
+int periscope_checkpoint(uint64_t);
+
+void periscope_restore_request(void);
+uint64_t periscope_restore_requested(void);
+int periscope_restore(void);
+
+uint64_t periscope_get_estimated_restore_time_ms(void);
+
+int periscope_system_shutdown_request(ShutdownCause reason);
+int periscope_shutdown_requested(void);
+
+void periscope_benchmark_hypercall(uint64_t);
+void periscope_debug_hypercall(uint64_t, uint64_t, uint64_t);
+
+// profiling
+int periscope_snapshot_and_restore_baseline_requested(void);
+void periscope_snapshot_and_restore_baseline(void);
+
+void periscope_syzkaller_send_addr_offset(uint64_t);
+
+#define DBG_RAM_STORED
+#undef DBG_RAM_STORED
+#define PERI_DEDUP
+//#undef PERI_DEDUP
+#define PERI_DEDUP_NOHASH
+//#undef PERI_DEDUP_NOHASH
+
+#ifdef PERI_DEDUP
+
+#define FINE_CHUNKS
+#undef FINE_CHUNKS
+#ifdef FINE_CHUNKS
+#define CHUNK_SHIFT 2
+#else
+#define CHUNK_SHIFT 0
+#endif
+#define CHUNK_DIV (1<<CHUNK_SHIFT)
+
+#define N_CHECKS_REQ 2
+#define N_R_BUF 32
+// Structure holding information about each stored ramblock
+// i.e. dirty bitmap and data to be restored
+typedef struct periscope_ramblock {
+    // RAMBlock->idstr (for matching)
+    char idstr[256];
+    int id;
+    bool empty;
+    bool store_done;
+    bool dirty_done;
+    // Dirty bitmap at time of checkpoint creation
+    unsigned long *dirty;
+#ifdef FINE_CHUNKS
+    unsigned long *dirty_fine;
+#endif
+    unsigned long npages;
+    unsigned long npages_dirty;
+    // #Dirty pages / #Pages stored in *ram
+    unsigned long npages_stored;
+    unsigned long npages_hashes_added;
+    unsigned long npages_zero;
+    unsigned long npages_skipped;
+    // RAMBlock offsets of stored pages (i.e. rb->host + offset)
+    unsigned int *offsets;
+    //unsigned int *offsets_zero;
+    // zero pages bitmap
+    unsigned long *zero_pages;
+    // Dirty pages stored at checkpoint creation
+    //void **ram_meta;
+#ifdef PERI_DEDUP_NOHASH
+    void *ram;
+#else
+    unsigned int *ram_idx;
+#endif
+#ifdef DBG_RAM_STORED
+    // For debugging
+    void *rambkp;
+    unsigned long rambkp_size;
+#endif
+} periscope_ramblock;
+#endif /* PERI_DEDUP */
+
+typedef struct periscope_snapshot_desc {
+    uint16_t id;
+    int memfd;
+#ifdef ENABLE_LW_CHKPT
+#ifndef PERI_DEDUP
+    int memfd_quick;
+    uint8_t *buf_quick;
+    size_t quick_sz;
+    int memfd_ram;
+    uint8_t *buf_ram;
+    size_t ram_sz;
+    unsigned long *dirty; // bitmap of pages stored in this snapshot
+    unsigned long npages;
+#ifdef DBG_RAM_STORED
+    void *rambkp;
+    unsigned long rambkp_size;
+#endif
+#else /* PERI_DEDUP */
+    uint8_t *buf_dev;
+    size_t dev_sz;
+    unsigned int n_peri_rb;
+    // Structure holding information about each stored ramblock
+    // i.e. dirty bitmap and data to be restored
+    periscope_ramblock *peri_rb;
+    float uniqueness;
+#endif /* PERI_DEDUP */
+#else
+    unsigned long dirty[]; // TODO: delta?
+#endif
+
+} periscope_snapshot_desc;
+
+struct periscope_input_desc;
+struct periscope_cp_desc;
+
+#define MAX_CP_DESC_CHILDREN 1024
+
+struct periscope_cp_desc {
+    char io[MAX_INPUT_BYTES];
+    uint32_t len;
+    uint32_t n_children;
+    bool closed;
+    uint32_t num_restored;
+
+    qemu_timeval last_restored;
+    qemu_timeval exec_time; // since parent restore
+    qemu_timeval closed_time;
+
+    struct periscope_cp_desc *parent;
+    // TODO: could be a dynamic structure (e.g., hash table of queues)
+    struct periscope_cp_desc *children[MAX_CP_DESC_CHILDREN];
+
+    periscope_snapshot_desc snapshot; // TODO: multiple snapshots?
+};
+
+struct periscope_input_desc {
+    char *input;
+    uint32_t len;
+    uint32_t used_len; // 0 <= used_len <= len
+
+    uint32_t num_irqs;
+    uint32_t num_io_reads;
+
+    struct periscope_cp_desc *restored_cp; // cp this input was initially based on
+    struct periscope_cp_desc *base_cp; // cp this input is currently based on
+
+    uint32_t num_pages_restored;
+    uint32_t num_pages_dirtied;
+};
+
+typedef struct periscope_input_desc periscope_input_desc;
+typedef struct periscope_cp_desc periscope_cp_desc;
+
+void periscope_notify_boot(void);
+void periscope_syzkaller_notify_boot(void);
+
+// stats
+uint32_t periscope_get_stat(int);
+
+/*
+ * Syzkaller
+ */
+struct syzkaller_handshake_req {
+    uint64_t magic;
+    uint64_t flags; // env flags
+    uint64_t pid;
+};
+
+struct syzkaller_handshake_reply {
+    uint32_t magic;
+};
+
+enum {
+    /* aggregate stats */
+    stat_time_saved_total = 0,
+    stat_time_exec_total,
+    stat_non_root_restores,
+    stat_chkpts_created,
+    stat_killed,
+    stat_evict_policy1,
+    stat_evict_policy2,
+    stat_evict_policy3,
+    stat_evict_policy4,
+#ifdef PERI_DEDUP_STAT
+    stat_evict_policy5,
+#endif
+
+    /* time stats */
+    stat_exec_time,
+    stat_saved_time,
+    stat_actual_time,
+#ifdef PERI_DEDUP_STAT
+    stat_chkpt_time,
+    stat_restore_time,
+#endif
+
+    /* dirty page stats */
+    stat_restored,
+    stat_dirtied,
+#ifdef PERI_DEDUP_STAT
+    stat_dedup,
+    stat_hashed,
+    stat_zero,
+    stat_skipped,
+#endif
+
+    /* chkpt stats */
+    stat_chkpt_size_0,
+    stat_chkpt_size_1,
+    stat_chkpt_size_2,
+    stat_chkpt_size_3,
+    stat_chkpt_size_4,
+    stat_chkpt_size_5,
+    stat_chkpt_size_6,
+    stat_chkpt_size_7,
+    stat_chkpt_size_8,
+    stat_chkpt_size_9,
+    stat_chkpt_size_max = stat_chkpt_size_9,
+
+    /* add stats before this line */
+    stat_count,
+};
+
+struct syzkaller_execute_reply {
+    uint32_t magic;
+    uint32_t done;
+    uint32_t status;
+    uint32_t stats[stat_count];
+};
+
+enum {
+    SYZKALLER_HC_ROOT_CHKPT          = 5,
+    SYZKALLER_HC_RECV_EXEC,         // 6
+    SYZKALLER_HC_REPLY_EXEC,        // 7
+    SYZKALLER_HC_RECV_HANDSHAKE,    // 8
+    SYZKALLER_HC_REPLY_HANDSHAKE,   // 9
+    SYZKALLER_HC_MAYBE_CHKPT,       // 10
+    SYZKALLER_HC_FORKSRV_CTX,       // 11
+    PERISCOPE_DEBUG_HC_BENCHMARK,   // 12
+    PERISCOPE_DEBUG_HC_NEXT,        // 13
+    SYZKALLER_HC_MAX,               // unused
+};
+
+void syzkaller_reply_handshake(void);
+void syzkaller_reply_execute_crash(void);
+void syzkaller_reply_execute(uint32_t);
+void syzkaller_receive_handshake(CPUState *, uint64_t);
+void syzkaller_receive_execute(CPUState *, uint64_t);
+
+uint64_t syzkaller_maybe_checkpoint(uint64_t, uint64_t);
+
+void syzkaller_submit_forkserver_context(uint64_t);
+
+#define PERISCOPE_INPUT_FOREACH(list, var)          \
+        for ((var) = (list);                        \
+            (var);                                  \
+            (var) = ((var)->next))
+
+#define TYPE_FUZZER "fuzzer"
+
+#define FUZZER_CLASS(klass) \
+    OBJECT_CLASS_CHECK(FuzzerClass, (klass), TYPE_FUZZER)
+#define FUZZER_OBJ(obj) \
+    OBJECT_CHECK(FuzzerState, (obj), TYPE_FUZZER)
+#define FUZZER_GET_CLASS(obj) \
+    OBJECT_GET_CLASS(FuzzerClass, (obj), TYPE_FUZZER)
+
+typedef struct FuzzerClass {
+    /*< private >*/
+    DeviceClass parent_class;
+    /*< public >*/
+} FuzzerClass;
+
+enum {
+    PERISCOPE_MODE_EXEC = 0,
+    PERISCOPE_MODE_COVERAGE,
+    PERISCOPE_MODE_AFL,
+    PERISCOPE_MODE_SYZKALLER_USBFUZZER,
+    PERISCOPE_MODE_PROFILER,
+};
+
+typedef struct FuzzerState {
+    /*< private >*/
+    DeviceState parent_obj;
+    /*< public >*/
+    char *uri;
+    int st_pipe, ctl_pipe, shm_id;
+    char *mgr_pipe;
+    int chkpt_pool_size;
+    int fuzzer_id;
+#if 1
+    HostMemoryBackend *hostmem[2];
+#else
+    IVShmemState *shmem[2];
+#endif
+    MemoryRegion *mr[2];
+
+    QEMUTimer *timer;
+    QemuThread thread;
+
+    periscope_input_desc *root;
+    periscope_input_desc *input_queue;
+
+    QCAState *dev;
+
+    // candidate
+    periscope_input_desc *cur_input;
+    periscope_cp_desc *cur_cp;
+    bool irq_pending;
+
+    int mode;
+
+    // fuzzer backend must initialize the following fptrs
+    int (*mmio_read)(unsigned, uint64_t *);
+    char *(*fetch_next)(uint32_t *);
+    char *(*get_cur)(uint32_t *);
+    void (*cur_executed)(uint8_t *, uint32_t, uint64_t, bool);
+    void (*restored)(void);
+    bool (*should_restore)(void);
+    int (*guest_crashed)(void);
+    bool (*get_stat)(int, uint32_t *);
+
+    uint8_t (*get_queue_cur_info)(void);
+} FuzzerState;
+
+FuzzerState *fuzzer_get_current(void);
+bool should_restore_at_agent_exit(uint64_t);
+bool should_shutdown_at_agent_exit(uint64_t);
+bool periscope_should_suspend_on_shutdown(void);
+
+#define PERISCOPE_GUEST_SUSPEND -1
+int periscope_guest_crashed(void);
+
+void periscope_start_fuzzer(const char *uri, Error **errp);
+
+void start_syzkaller_fuzzer(const char *, int, int, const char *, int, Error **);
+
+void start_profiler(int, Error **);
+
+void start_afl_fuzzer(const char *pipes, int, int, int, Error **errp);
+
+void start_input_executor(const char *uri, Error **errp);
+
+void start_coverage_collector(const char *args, Error **errp);
+
+void periscope_fetch_next_input(void);
+#endif
diff --git migration/periscope_dma.c migration/periscope_dma.c
new file mode 100644
index 0000000000..12eca43f16
--- /dev/null
+++ migration/periscope_dma.c
@@ -0,0 +1,192 @@
+#include "migration/periscope_dma.h"
+#include "sysemu/kvm.h"
+#include "qemu/bitops.h"
+#include <unistd.h>
+
+static bool is_init = false;
+static QLIST_HEAD( ,periscope_dmar) dma_regions =
+    QLIST_HEAD_INITIALIZER(dma_regions);
+
+int periscope_dma_init(void)
+{
+   if(is_init) return -1;
+   return 0;
+}
+
+//static periscope_dmar* find_dma_region_exact(uint64_t gpa, unsigned long size)
+//{
+//   periscope_dmar *dmar;
+//   QLIST_FOREACH(dmar, &dma_regions, list) {
+//      if (dmar->gpa == gpa && dmar->size == size) {
+//         return dmar;
+//      }
+//   }
+//   return NULL;
+//}
+
+static periscope_dmar* find_dma_region(uint64_t gpa, unsigned long size)
+{
+   periscope_dmar *dmar;
+   QLIST_FOREACH(dmar, &dma_regions, list) {
+      if (dmar->gpa <= gpa && dmar->gpa + dmar->size > gpa) {
+         return dmar;
+      }
+   }
+   return NULL;
+}
+
+int periscope_dma_add(uint64_t gpa, unsigned long size, MemoryRegion* mr)
+{
+   int pagesize = getpagesize();
+   periscope_dmar *dmar = find_dma_region(gpa, size);
+
+   //printf("%s: addr %lx, size %lx\n", __FUNCTION__, gpa, size);
+   // TODO what to do with partial overlaps?
+   if(dmar != NULL) {
+      // reset all tracking data fields
+      dmar->is_mapped = true;
+      memset(dmar->accessed_bm, 0, sizeof(dmar->accessed_bm) * sizeof(char));
+      //printf("Warning: dma region at %lx already registered\n", gpa);
+      return 0;
+   }
+
+   for(unsigned long addr = gpa; addr < gpa + size; addr += pagesize) {
+      if(kvm_enable_dma_trace(addr) != 0) {
+         printf("Error: could not enable dma trace for %lx\n", addr);
+         return -1;
+      }
+   }
+
+   dmar = g_malloc(sizeof(periscope_dmar));
+   dmar->gpa = gpa;
+   dmar->size = size;
+   dmar->mr = mr;
+   dmar->is_mapped = true;
+   dmar->n_accessed = 0;
+   QLIST_INSERT_HEAD(&dma_regions, dmar, list);
+   //printf("%s: success\n", __FUNCTION__);
+   return 0;
+}
+
+int periscope_dma_remove(uint64_t gpa, unsigned long size)
+{
+   int pagesize = getpagesize();
+   //periscope_dmar *dmar = find_dma_region_exact(gpa, size);
+   periscope_dmar *dmar = find_dma_region(gpa, size);
+   //printf("%s: Enter gpa %lx (+%lx)\n", __FUNCTION__, gpa, size);
+   // TODO what to do with partial overlaps?
+   if(dmar == NULL) {
+      printf("Warning: dma region at %lx (+%lx) not registered\n", gpa, size);
+      return -1;
+   }
+
+   for(unsigned long addr = dmar->gpa; addr < dmar->gpa + dmar->size; addr += pagesize) {
+      if(kvm_disable_dma_trace(addr) != 0) {
+         printf("Error: could not disable dma trace for %lx\n", addr);
+         // remove anyway, if there are future pfs they will be handled by kvm
+         // removing the entry just avoids the detour through this module
+         // when the guest is reset the page tables will be reset anyway
+         //return -1;
+      }
+   }
+
+   QLIST_REMOVE(dmar, list);
+   g_free(dmar);
+   //printf("%s: success\n", __FUNCTION__);
+   return 0;
+}
+
+int periscope_dma_write_access(periscope_dmar *dmar, uint64_t gpa, uint8_t *val, unsigned size)
+{
+   unsigned long offset;
+   int pagesize = getpagesize();
+   if(!dmar) return -1;
+   if(dmar->is_mapped) return 0; // if the dma region is still under device control -> do nothing
+   offset = gpa - dmar->gpa;
+   if(offset > pagesize) return -1; // should not happen
+   //printf("%s: Enter\n", __FUNCTION__);
+   // mark bytes as overwritten (no matter if they were set already)
+   for(int i=0; i<size; ++i) {
+      if(!test_and_set_bit(offset + i, (unsigned long*)dmar->accessed_bm)) {
+         dmar->n_accessed++;
+      }
+   }
+   //printf("#Accessed dmas %d\n", dmar->n_accessed);
+   return 0;
+}
+
+int periscope_dma_read_access(periscope_dmar *dmar, uint64_t gpa, uint8_t *val)
+{
+   unsigned long offset;
+   int pagesize = getpagesize();
+   if(!dmar) return -1;
+   if(dmar->is_mapped) return 0; // if the dma region is still under device control -> do nothing
+   //printf("%s: Enter\n", __FUNCTION__);
+   offset = gpa - dmar->gpa;
+   if(offset > pagesize) return -1; // should not happen
+   // mark bytes as overwritten (no matter if they were set already)
+   if(test_and_set_bit(offset, (unsigned long*)dmar->accessed_bm)) {
+      // read data from actual guest ram
+      dma_memory_read(&address_space_memory, gpa, val, 1);
+      //printf("read value at %lx -> %x\n", offset, *val);
+      return 1;
+   }
+   return 0;
+}
+
+int periscope_dma_unmap(uint64_t gpa, unsigned long size)
+{
+   //periscope_dmar *dmar = find_dma_region_exact(gpa, size);
+   periscope_dmar *dmar = find_dma_region(gpa, size);
+   //printf("%s: Enter gpa %lx (+%lx)\n", __FUNCTION__, gpa, size);
+   // TODO what to do with partial overlaps?
+   if(dmar == NULL) {
+      //printf("Warning: dma region at %lx (+%lx) not registered\n", gpa, size);
+      return -1;
+   }
+
+   // mark as not mapped
+   dmar->is_mapped = false;
+   // reset accessed bitmap (from now on writes to this area have to be buffered)
+   memset(dmar->accessed_bm, 0, sizeof(dmar->accessed_bm) * sizeof(char));
+   return 0;
+}
+
+void periscope_dma_remove_all(void)
+{
+   periscope_dmar *dmar;
+   int pagesize = getpagesize();
+   QLIST_FOREACH(dmar, &dma_regions, list) {
+      for(unsigned long addr = dmar->gpa; addr < dmar->gpa + dmar->size; addr += pagesize) {
+         if(kvm_disable_dma_trace(addr) != 0) {
+            printf("Error: could not disable dma trace for %lx\n", addr);
+         }
+      }
+      //printf("Removed dmar %lx\n", dmar->gpa);
+      QLIST_REMOVE(dmar, list);
+      g_free(dmar);
+   }
+}
+
+int periscop_dma_maybe_remove(periscope_dmar *dmar, uint64_t gpa)
+{
+   if(dmar == NULL) return 0;
+   if(!dmar->is_mapped && dmar->n_accessed >= 0x1000 - 8) {
+      periscope_dma_remove(gpa, 1);
+      return 1;
+   }
+   return 0;
+}
+
+periscope_dmar *periscope_dma_get(uint64_t gpa, unsigned long size)
+{
+   periscope_dmar *dmar = find_dma_region(gpa, size);
+   //printf("%s %lx (+%lx)\n", __FUNCTION__, gpa, size);
+   if(dmar == NULL) {
+      printf("Warning: dma region at %lx (+%lx) not registered\n", gpa, size);
+      return NULL;
+   }
+   return dmar;
+}
+
+
diff --git migration/periscope_dma.h migration/periscope_dma.h
new file mode 100644
index 0000000000..0eaa0c9d07
--- /dev/null
+++ migration/periscope_dma.h
@@ -0,0 +1,52 @@
+#ifndef PERISCOPE_DMA_H
+#define PERISCOPE_DMA_H
+
+#include "qemu/osdep.h"
+#include "qapi/error.h"
+
+#include <sys/shm.h>
+
+#include "periscope.h"
+
+
+//#include <stdint.h>
+//#include "exec/memory.h"
+
+struct periscope_dmar;
+struct periscope_dmar {
+   uint64_t gpa;
+   unsigned long size;
+   MemoryRegion *mr;
+   bool is_mapped;
+   unsigned n_accessed;
+   char accessed_bm[512]; // -> 0x1000 bits (one for each byte)
+   // ram should have the values -> we prob. dont need this
+   QLIST_ENTRY(periscope_dmar) list;
+};
+typedef struct periscope_dmar periscope_dmar;
+
+
+
+// initialize dma tracing
+int periscope_dma_init(void);
+
+// add a dma region to be traced and start tracing
+// the memory region is pretty arbitrary,
+// but determines which io callbacks will be invoked
+int periscope_dma_add(uint64_t gpa, unsigned long size, MemoryRegion* mr);
+// stop tracing and remove the dma region
+int periscope_dma_remove(uint64_t gpa, unsigned long size);
+// mark dma region as unmapped, accesses are still intercepted
+int periscope_dma_unmap(uint64_t gpa, unsigned long size);
+
+// return the memory region associated with the dma region for the given address
+// the memory region determines which io callbacks will be invoked
+periscope_dmar *periscope_dma_get(uint64_t gpa, unsigned long size);
+
+int periscope_dma_read_access(periscope_dmar *dmar, uint64_t gpa, uint8_t *val);
+int periscope_dma_write_access(periscope_dmar *dmar, uint64_t gpa, uint8_t *val, unsigned size);
+
+// remove all remaining dma traces
+void periscope_dma_remove_all(void);
+int periscop_dma_maybe_remove(periscope_dmar *dmar, uint64_t gpa);
+#endif
diff --git migration/periscope_perf_switches.h migration/periscope_perf_switches.h
new file mode 100644
index 0000000000..54ac7f2425
--- /dev/null
+++ migration/periscope_perf_switches.h
@@ -0,0 +1,46 @@
+#ifndef PERISCOPE_PERF_SWITCHES
+#define PERISCOPE_PERF_SWITCHES
+
+//#define PERI_ENABLE_RESTORE_OPTS_RESET_DEVS
+//#define PERI_ENABLE_RESTORE_OPTS_RESET_RAM
+
+extern bool periscope_no_loadvm_state_setup;
+extern bool periscope_no_loadvm_state_cleanup;
+
+// if set:
+// * skips addition of ram pages to snapshot file -> empty snapshot
+extern bool quick_snapshot;
+static inline void set_quick_snapshot(void) {
+#ifdef PERI_ENABLE_RESTORE_OPTS_RESET_RAM
+   quick_snapshot = true;
+#endif
+}
+static inline void unset_quick_snapshot(void) {
+   quick_snapshot = false;
+}
+
+// if set:
+// * skips device->reset and device->post_load
+extern bool quick_reset_devs;
+// * resets MAP_PRIVATE ram mappings instead of doing a full snapshot restore
+extern bool quick_reset_ram;
+
+static inline void set_quick_reset_devs(void) {
+#ifdef PERI_ENABLE_RESTORE_OPTS_RESET_DEVS
+   quick_reset_devs = true;
+#endif
+}
+static inline void unset_quick_reset_devs(void) {
+   quick_reset_devs = false;
+}
+
+static inline void set_quick_reset_ram(void) {
+#ifdef PERI_ENABLE_RESTORE_OPTS_RESET_RAM
+   quick_reset_ram = true;
+#endif
+}
+static inline void unset_quick_reset_ram(void) {
+   quick_reset_ram = false;
+}
+
+#endif
diff --git migration/qemu-file.c migration/qemu-file.c
index 977b9ae07c..5ee816c7c6 100644
--- migration/qemu-file.c
+++ migration/qemu-file.c
@@ -504,6 +504,31 @@ size_t qemu_get_buffer(QEMUFile *f, uint8_t *buf, size_t size)
     }
     return done;
 }
+size_t skip_qemu_get_buffer(QEMUFile *f, uint8_t *buf, size_t size)
+{
+    //size_t pending = size;
+    //size_t done = 0;
+    //size_t res;
+    uint8_t *src;
+
+    qemu_peek_buffer(f, &src, size, 0);
+    qemu_file_skip(f, size);
+    return size;
+    //while (pending > 0) {
+
+    //    res = qemu_peek_buffer(f, &src, MIN(pending, IO_BUF_SIZE), 0);
+    //    if (res == 0) {
+    //        return done;
+    //    }
+    //    //memcpy(buf, src, res);
+    //    qemu_file_skip(f, res);
+    //    buf += res;
+    //    pending -= res;
+    //    done += res;
+    //}
+    //return done;
+}
+
 
 /*
  * Read 'size' bytes of data from the file.
diff --git migration/ram.c migration/ram.c
index 1ca9ba77b6..2341c1e727 100644
--- migration/ram.c
+++ migration/ram.c
@@ -55,8 +55,12 @@
 #include "block.h"
 #include "sysemu/sysemu.h"
 #include "qemu/uuid.h"
+#include "qemu/mmap-alloc.h"
 #include "savevm.h"
 #include "qemu/iov.h"
+#include "migration/periscope_perf_switches.h"
+#include "migration/periscope.h"
+#include "migration/periscope-delta-snap.h"
 
 /***********************************************************/
 /* ram save/restore */
@@ -2521,12 +2525,35 @@ static int ram_save_host_page(RAMState *rs, PageSearchStatus *pss,
     }
 
     do {
+        bool should_save_target_page = true;
+#if 0
+        should_save_target_page &=
+            !quick_snapshot || strcmp(pss->block->idstr, "pc.ram") != 0;
+        should_save_target_page &= !periscope_save_ram_only || strcmp(pss->block->idstr, "pc.ram") == 0;
+#endif
+        if (strcmp(pss->block->idstr, "pc.ram") == 0 && periscope_delta_snapshot && pss->block->bmap_delta_snap) {
+            bool ret = test_and_clear_bit(pss->page, pss->block->bmap_delta_snap);
+            if (ret) {
+                // disregard migration bitmap management, force setting the bitmap.
+                // this allows us to get past default migration bitmap check below.
+                set_bit(pss->page, pss->block->bmap);
+            }
+            else {
+                should_save_target_page = false;
+            }
+        }
+
         /* Check the pages is dirty and if it is send it */
         if (!migration_bitmap_clear_dirty(rs, pss->block, pss->page)) {
             pss->page++;
             continue;
         }
 
+        if (!should_save_target_page) {
+            pss->page++;
+            continue;
+        }
+
         tmppages = ram_save_target_page(rs, pss, last_stage);
         if (tmppages < 0) {
             return tmppages;
@@ -2688,6 +2715,14 @@ static void ram_save_cleanup(void *opaque)
     RAMBLOCK_FOREACH_NOT_IGNORED(block) {
         g_free(block->bmap);
         block->bmap = NULL;
+        if (block->bmap_delta_restore) {
+            g_free(block->bmap_delta_restore);
+            block->bmap_delta_restore = NULL;
+        }
+        if (block->bmap_delta_snap) {
+            g_free(block->bmap_delta_snap);
+            block->bmap_delta_snap = NULL;
+        }
         g_free(block->unsentmap);
         block->unsentmap = NULL;
     }
@@ -3389,6 +3424,101 @@ static int ram_save_setup(QEMUFile *f, void *opaque)
     return 0;
 }
 
+void compare_ram(unsigned long long *p1, unsigned long long *p2, int len);
+void compare_ram(unsigned long long *p1, unsigned long long *p2, int len)
+{
+   for(int i=0x100fa0/sizeof(unsigned long long); i<len/sizeof(unsigned long long); ++i) {
+      if(p1[i] != p2[i]) {
+         printf("------------------> %lx: %llx != %llx\n", i*sizeof(unsigned long long), p1[i], p2[i]);
+         break;
+      }
+   }
+}
+
+void cram(void);
+void cram(void)
+{
+    RAMBlock *block;
+    printf("------------- %s ------------------\n", __FUNCTION__);
+    RAMBLOCK_FOREACH_MIGRATABLE(block) {
+       if(strcmp(block->idstr, "pc.ram") != 0) continue;
+       compare_ram((unsigned long long*)block->host, (unsigned long long*)block->host_restore, block->used_length);
+    }
+}
+
+int kvm_update_user_memory_region(void* old, void* new, size_t len);
+// this is only called on the quick reset path
+// meaning that we can just discard any changes since the last snapshot
+// the reset is done by mmaping the host ram ptr again with MAP_PRIVATE
+int ram_reset_mappings_cow(void)
+{
+    RAMBlock *block;
+    void *old;
+
+    RAMBLOCK_FOREACH_MIGRATABLE(block) {
+       if(strcmp(block->idstr, "pc.ram") != 0) continue; // TODO, also apply to acpi and bios ram blocks?
+       if(!block->host_restore) {
+          printf("can not restore %s\n", block->idstr);
+          return -1;
+       }
+       old = block->host;
+       //munmap(old, block->max_length); // TODO: needed?
+       uint8_t *area = mmap(block->host, block->max_length, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_FIXED, block->fd, 0);
+       if (area == MAP_FAILED) {
+          printf("ERROR MAP FAILED %s\n", block->idstr);
+          perror("mmap");
+          return -1;
+       }
+       block->host = area;
+       kvm_update_user_memory_region(old, block->host, block->max_length);
+    }
+    return 0;
+}
+
+// ram duplicate mappings recreates a shared mapping to the filed backed ram
+// so that when we are doing a full snapshot restore (not quick reset)
+// the changes actually reach the file backend
+int ram_duplicate_mappings(void)
+{
+    RAMBlock *block;
+
+    RAMBLOCK_FOREACH_MIGRATABLE(block) {
+       if(strcmp(block->idstr, "pc.ram") != 0) continue;
+
+       uint8_t *area = mmap(block->host, block->max_length, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_FIXED, block->fd, 0);
+       if (area == MAP_FAILED) {
+          printf("ERROR MAP FAILED %s\n", block->idstr);
+          perror("mmap");
+          return -1;
+       }
+       block->host_restore = block->host;
+       block->host = area;
+    }
+
+    return 0;
+}
+
+// after the full snapshot restore is done restoring data in the file backend
+// we can now cow protect the file backed memory area
+// so any changes from now on can be easily reset by mmaping the area again (see ram_reset_mappings)
+int ram_duplicate_mappings_cow(void)
+{
+    RAMBlock *block;
+    RAMBLOCK_FOREACH_MIGRATABLE(block) {
+       if(strcmp(block->idstr, "pc.ram") != 0) continue;
+       // make sure all the changes are synced?
+       fsync(block->fd);
+       uint8_t *area = mmap(block->host, block->max_length, PROT_READ | PROT_WRITE, MAP_FIXED | MAP_PRIVATE, block->fd, 0);
+       if (area == MAP_FAILED) {
+          printf("ERROR MAP FAILED %s\n", block->idstr);
+          perror("mmap");
+          return -1;
+       }
+       kvm_update_user_memory_region(block->host_restore, block->host, block->max_length);
+    }
+    return 0;
+}
+
 /**
  * ram_save_iterate: iterative stage for migration
  *
@@ -3641,7 +3771,7 @@ static inline RAMBlock *ram_block_from_stream(QEMUFile *f, int flags)
     return block;
 }
 
-static inline void *host_from_ram_block_offset(RAMBlock *block,
+void *host_from_ram_block_offset(RAMBlock *block,
                                                ram_addr_t offset)
 {
     if (!offset_in_ramblock(block, offset)) {
@@ -4222,6 +4352,41 @@ static void colo_flush_ram_cache(void)
     trace_colo_flush_ram_cache_end();
 }
 
+#define SELECT_RESTORE 1
+//#define DBG_SELECT_RESTORE 1
+#define DBG_SELECT_RESTORE 0
+//#define DBG_SELECT_RESTORE_NAME "0000:00:05.0/mb2"
+//#undef DBG_SELECT_RESTORE_NAME
+#define COUNT_SR_SKIPS 0
+
+#if COUNT_SR_SKIPS == 1
+static void init_ramblock_skipped(void)
+{
+    RAMBlock *rb;
+    RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+       rb->skipped = 0;
+       rb->restored = 0;
+    }
+}
+static void print_ramblock_skipped(void)
+{
+    RAMBlock *rb;
+    RAMBLOCK_FOREACH_MIGRATABLE(rb) {
+        //if (strcmp(rb->idstr, "pc.ram") == 0)
+        if (rb->restored)
+            printf("periscope: %s SKIP: %ld, RES: %ld\n", rb->idstr, rb->skipped, rb->restored);
+    }
+}
+static void inc_ramblock_restored(RAMBlock *rb)
+{
+   rb->restored++;
+}
+static void inc_ramblock_skipped(RAMBlock *rb)
+{
+   rb->skipped++;
+}
+#endif
+
 static int ram_load(QEMUFile *f, void *opaque, int version_id)
 {
     int flags = 0, ret = 0, invalid_flags = 0;
@@ -4255,10 +4420,20 @@ static int ram_load(QEMUFile *f, void *opaque, int version_id)
         ret = ram_load_postcopy(f);
     }
 
+#if COUNT_SR_SKIPS == 1
+    init_ramblock_skipped();
+#endif
     while (!postcopy_running && !ret && !(flags & RAM_SAVE_FLAG_EOS)) {
         ram_addr_t addr, total_ram_bytes;
         void *host = NULL;
         uint8_t ch;
+        unsigned long *bm = NULL;
+#ifdef DBG_SELECT_RESTORE_NAME
+        char* name = NULL;
+#endif
+#if COUNT_SR_SKIPS == 1
+        RAMBlock *rb_tmp = NULL;
+#endif
 
         addr = qemu_get_be64(f);
         flags = addr & ~TARGET_PAGE_MASK;
@@ -4276,7 +4451,9 @@ static int ram_load(QEMUFile *f, void *opaque, int version_id)
         if (flags & (RAM_SAVE_FLAG_ZERO | RAM_SAVE_FLAG_PAGE |
                      RAM_SAVE_FLAG_COMPRESS_PAGE | RAM_SAVE_FLAG_XBZRLE)) {
             RAMBlock *block = ram_block_from_stream(f, flags);
-
+#if COUNT_SR_SKIPS == 1
+            rb_tmp = block;
+#endif
             /*
              * After going into COLO, we should load the Page into colo_cache.
              */
@@ -4291,6 +4468,20 @@ static int ram_load(QEMUFile *f, void *opaque, int version_id)
                 break;
             }
 
+#if SELECT_RESTORE == 1
+            bm = block->bmap_delta_restore;
+#ifdef DBG_SELECT_RESTORE_NAME
+            name = block->idstr;
+#endif
+#endif
+            //if(block->bmap_delta_restore) {
+            //   //if(test_bit(ramblock_recv_bitmap_offset(host, block), block->bmap_delta_restore)) {
+            //   if(test_bit(addr >> TARGET_PAGE_BITS, block->bmap_delta_restore)) {
+            //      printf("addr %lx, offset %lx, shift %lx\n", addr,
+            //            ramblock_recv_bitmap_offset(host, block), addr >> TARGET_PAGE_BITS);
+            //      skip = true;
+            //   }
+            //}
             if (!migration_incoming_in_colo_state()) {
                 ramblock_recv_bitmap_set(block, host);
             }
@@ -4369,24 +4560,85 @@ static int ram_load(QEMUFile *f, void *opaque, int version_id)
 
         case RAM_SAVE_FLAG_ZERO:
             ch = qemu_get_byte(f);
-            ram_handle_compressed(host, ch, TARGET_PAGE_SIZE);
+            if (!bm || (bm && test_bit(addr >> TARGET_PAGE_BITS, bm))) {
+                ram_handle_compressed(host, ch, TARGET_PAGE_SIZE);
+#if COUNT_SR_SKIPS == 1
+                if (rb_tmp) {
+                    inc_ramblock_restored(rb_tmp);
+                }
+#endif
+            } else {
+#if COUNT_SR_SKIPS == 1
+                if (rb_tmp) {
+                    inc_ramblock_skipped(rb_tmp);
+                }
+#endif
+            }
+#if DBG_SELECT_RESTORE == 1
+#ifdef DBG_SELECT_RESTORE_NAME
+            if(name && strcmp(name, DBG_SELECT_RESTORE_NAME) == 0)
+#endif
+                printf("ram_save_flag_zero addr %lx, shift %lx\n", addr, addr >> TARGET_PAGE_BITS);
+#endif
             break;
 
         case RAM_SAVE_FLAG_PAGE:
-            qemu_get_buffer(f, host, TARGET_PAGE_SIZE);
+            if (!bm || (bm && test_bit(addr >> TARGET_PAGE_BITS, bm))) {
+                qemu_get_buffer(f, host, TARGET_PAGE_SIZE);
+#if COUNT_SR_SKIPS == 1
+                if (rb_tmp) {
+                    inc_ramblock_restored(rb_tmp);
+                }
+#endif
+            } else {
+                skip_qemu_get_buffer(f, host, TARGET_PAGE_SIZE);
+#if COUNT_SR_SKIPS == 1
+                if (rb_tmp) {
+                    inc_ramblock_skipped(rb_tmp);
+                }
+#endif
+            }
+#if DBG_SELECT_RESTORE == 1
+#ifdef DBG_SELECT_RESTORE_NAME
+            if(name && strcmp(name, DBG_SELECT_RESTORE_NAME) == 0)
+#endif
+                printf("ram_save_flag_page addr %lx, shift %lx\n", addr, addr >> TARGET_PAGE_BITS);
+#endif
             break;
 
         case RAM_SAVE_FLAG_COMPRESS_PAGE:
+#if COUNT_SR_SKIPS == 1
+            if (rb_tmp) {
+                inc_ramblock_restored(rb_tmp);
+            }
+#endif
             len = qemu_get_be32(f);
             if (len < 0 || len > compressBound(TARGET_PAGE_SIZE)) {
                 error_report("Invalid compressed data length: %d", len);
                 ret = -EINVAL;
                 break;
             }
+#if DBG_SELECT_RESTORE == 1
+#ifdef DBG_SELECT_RESTORE_NAME
+            if(name && strcmp(name, DBG_SELECT_RESTORE_NAME) == 0)
+#endif
+                printf("ram_save_flag_compress_page addr %lx, shift %lx\n", addr, addr >> TARGET_PAGE_BITS);
+#endif
             decompress_data_with_multi_threads(f, host, len);
             break;
 
         case RAM_SAVE_FLAG_XBZRLE:
+#if COUNT_SR_SKIPS == 1
+            if (rb_tmp) {
+                inc_ramblock_restored(rb_tmp);
+            }
+#endif
+#if DBG_SELECT_RESTORE == 1
+#ifdef DBG_SELECT_RESTORE_NAME
+            if(name && strcmp(name, DBG_SELECT_RESTORE_NAME) == 0)
+#endif
+                printf("ram_save_flag_xbzrle addr %lx, shift %lx\n", addr, addr >> TARGET_PAGE_BITS);
+#endif
             if (load_xbzrle(f, addr, host) < 0) {
                 error_report("Failed to decompress XBZRLE page at "
                              RAM_ADDR_FMT, addr);
@@ -4419,6 +4671,10 @@ static int ram_load(QEMUFile *f, void *opaque, int version_id)
     if (!ret  && migration_incoming_in_colo_state()) {
         colo_flush_ram_cache();
     }
+
+#if COUNT_SR_SKIPS == 1
+   print_ramblock_skipped();
+#endif
     return ret;
 }
 
diff --git migration/ram.h migration/ram.h
index 936177b3e9..f637c0ad0c 100644
--- migration/ram.h
+++ migration/ram.h
@@ -75,4 +75,5 @@ int ram_dirty_bitmap_reload(MigrationState *s, RAMBlock *rb);
 int colo_init_ram_cache(void);
 void colo_release_ram_cache(void);
 
+void *host_from_ram_block_offset(RAMBlock *block, ram_addr_t offset);
 #endif
diff --git migration/savevm.c migration/savevm.c
index 34bcad3807..644f35da34 100644
--- migration/savevm.c
+++ migration/savevm.c
@@ -59,7 +59,11 @@
 #include "migration/colo.h"
 #include "qemu/bitmap.h"
 #include "net/announce.h"
+#include "migration/periscope_perf_switches.h"
+#include "migration/periscope-delta-snap.h"
+#include "migration/periscope.h"
 
+extern bool dev_only_snapshot;
 const unsigned int postcopy_ram_discard_version = 0;
 
 /* Subcommands for QEMU_VM_COMMAND */
@@ -1093,6 +1097,7 @@ void qemu_savevm_state_setup(QEMUFile *f)
 
     trace_savevm_state_setup();
     QTAILQ_FOREACH(se, &savevm_state.handlers, entry) {
+        if(dev_only_snapshot && se->is_ram) continue;
         if (!se->ops || !se->ops->save_setup) {
             continue;
         }
@@ -1124,6 +1129,7 @@ int qemu_savevm_state_resume_prepare(MigrationState *s)
     trace_savevm_state_resume_prepare();
 
     QTAILQ_FOREACH(se, &savevm_state.handlers, entry) {
+        if(dev_only_snapshot && se->is_ram) continue;
         if (!se->ops || !se->ops->resume_prepare) {
             continue;
         }
@@ -1154,6 +1160,7 @@ int qemu_savevm_state_iterate(QEMUFile *f, bool postcopy)
 
     trace_savevm_state_iterate();
     QTAILQ_FOREACH(se, &savevm_state.handlers, entry) {
+        if(dev_only_snapshot && se->is_ram) continue;
         if (!se->ops || !se->ops->save_live_iterate) {
             continue;
         }
@@ -1222,6 +1229,7 @@ void qemu_savevm_state_complete_postcopy(QEMUFile *f)
     int ret;
 
     QTAILQ_FOREACH(se, &savevm_state.handlers, entry) {
+        if(dev_only_snapshot && se->is_ram) continue;
         if (!se->ops || !se->ops->save_live_complete_postcopy) {
             continue;
         }
@@ -1267,6 +1275,7 @@ int qemu_savevm_state_complete_precopy(QEMUFile *f, bool iterable_only,
     cpu_synchronize_all_states();
 
     QTAILQ_FOREACH(se, &savevm_state.handlers, entry) {
+        if(dev_only_snapshot && se->is_ram) continue;
         if (!se->ops ||
             (in_postcopy && se->ops->has_postcopy &&
              se->ops->has_postcopy(se->opaque)) ||
@@ -1301,6 +1310,7 @@ int qemu_savevm_state_complete_precopy(QEMUFile *f, bool iterable_only,
     json_prop_int(vmdesc, "page_size", qemu_target_page_size());
     json_start_array(vmdesc, "devices");
     QTAILQ_FOREACH(se, &savevm_state.handlers, entry) {
+        if(dev_only_snapshot && se->is_ram) continue;
 
         if ((!se->ops || !se->ops->save_state) && !se->vmsd) {
             continue;
@@ -1309,7 +1319,6 @@ int qemu_savevm_state_complete_precopy(QEMUFile *f, bool iterable_only,
             trace_savevm_section_skip(se->idstr, se->section_id);
             continue;
         }
-
         trace_savevm_section_start(se->idstr, se->section_id);
 
         json_start_object(vmdesc, NULL);
@@ -1376,6 +1385,7 @@ void qemu_savevm_state_pending(QEMUFile *f, uint64_t threshold_size,
 
 
     QTAILQ_FOREACH(se, &savevm_state.handlers, entry) {
+        if(dev_only_snapshot && se->is_ram) continue;
         if (!se->ops || !se->ops->save_live_pending) {
             continue;
         }
@@ -1401,13 +1411,14 @@ void qemu_savevm_state_cleanup(void)
 
     trace_savevm_state_cleanup();
     QTAILQ_FOREACH(se, &savevm_state.handlers, entry) {
+        if(dev_only_snapshot && se->is_ram) continue;
         if (se->ops && se->ops->save_cleanup) {
             se->ops->save_cleanup(se->opaque);
         }
     }
 }
 
-static int qemu_savevm_state(QEMUFile *f, Error **errp)
+int qemu_savevm_state(QEMUFile *f, Error **errp)
 {
     int ret;
     MigrationState *ms = migrate_get_current();
@@ -1420,9 +1431,9 @@ static int qemu_savevm_state(QEMUFile *f, Error **errp)
         return -EINVAL;
     }
 
-    if (migration_is_blocked(errp)) {
-        return -EINVAL;
-    }
+//    if (migration_is_blocked(errp)) {
+//        return -EINVAL;
+//    }
 
     if (migrate_use_block()) {
         error_setg(errp, "Block migration and snapshots are incompatible");
@@ -1467,6 +1478,79 @@ static int qemu_savevm_state(QEMUFile *f, Error **errp)
     return ret;
 }
 
+int periscope_qemu_savevm_state(QEMUFile *f_iterable, QEMUFile *f_others, Error **errp)
+{
+    int ret;
+    MigrationState *ms = migrate_get_current();
+    MigrationStatus status;
+
+    if (migration_is_setup_or_active(ms->state) ||
+        ms->state == MIGRATION_STATUS_CANCELLING ||
+        ms->state == MIGRATION_STATUS_COLO) {
+        error_setg(errp, QERR_MIGRATION_ACTIVE);
+        return -EINVAL;
+    }
+
+//    if (migration_is_blocked(errp)) {
+//        return -EINVAL;
+//    }
+
+    if (migrate_use_block()) {
+        error_setg(errp, "Block migration and snapshots are incompatible");
+        return -EINVAL;
+    }
+
+    ret = 0;
+    migrate_init(ms);
+    QEMUFile *f = NULL;
+
+    if(f_iterable != NULL) {
+       f = f_iterable;
+       ms->to_dst_file = f;
+
+       qemu_mutex_unlock_iothread();
+       qemu_savevm_state_header(f);
+       qemu_savevm_state_setup(f);
+       qemu_mutex_lock_iothread();
+
+       while (qemu_file_get_error(f) == 0) {
+          if (qemu_savevm_state_iterate(f, false) > 0) {
+             break;
+          }
+       }
+
+       ret = qemu_file_get_error(f);
+    }
+    if (ret == 0) {
+        f = f_others;
+        ms->to_dst_file = f;
+
+        qemu_mutex_unlock_iothread();
+        qemu_savevm_state_header(f);
+        qemu_mutex_lock_iothread();
+
+        qemu_savevm_state_complete_precopy(f, false, false);
+        ret = qemu_file_get_error(f);
+    }
+    qemu_savevm_state_cleanup();
+    if (ret != 0) {
+        error_setg_errno(errp, -ret, "Error while writing VM state");
+    }
+
+    if (ret != 0) {
+        status = MIGRATION_STATUS_FAILED;
+    } else {
+        status = MIGRATION_STATUS_COMPLETED;
+    }
+    migrate_set_state(&ms->state, MIGRATION_STATUS_SETUP, status);
+
+    /* f is outer parameter, it should not stay in global migration state after
+     * this function finished */
+    ms->to_dst_file = NULL;
+
+    return ret;
+}
+
 void qemu_savevm_live_state(QEMUFile *f)
 {
     /* save QEMU_VM_SECTION_END section */
@@ -2415,14 +2499,20 @@ out:
 int qemu_loadvm_state(QEMUFile *f)
 {
     MigrationIncomingState *mis = migration_incoming_get_current();
-    Error *local_err = NULL;
+//    Error *local_err = NULL;
     unsigned int v;
     int ret;
 
-    if (qemu_savevm_state_blocked(&local_err)) {
-        error_report_err(local_err);
-        return -EINVAL;
-    }
+//#ifdef PERI_ENABLE_RESTORE_OPTS_RESET_RAM
+//    if(!quick_reset_ram) {
+//       ret = ram_duplicate_mappings();
+//    }
+//#endif
+
+//    if (qemu_savevm_state_blocked(&local_err)) {
+//        error_report_err(local_err);
+//        return -EINVAL;
+//    }
 
     v = qemu_get_be32(f);
     if (v != QEMU_VM_FILE_MAGIC) {
@@ -2440,7 +2530,7 @@ int qemu_loadvm_state(QEMUFile *f)
         return -ENOTSUP;
     }
 
-    if (qemu_loadvm_state_setup(f) != 0) {
+    if (!periscope_no_loadvm_state_setup && qemu_loadvm_state_setup(f) != 0) {
         return -EINVAL;
     }
 
@@ -2509,12 +2599,23 @@ int qemu_loadvm_state(QEMUFile *f)
         }
     }
 
+    if (!periscope_no_loadvm_state_cleanup)
     qemu_loadvm_state_cleanup();
+
     cpu_synchronize_all_post_init();
+#ifdef PERI_ENABLE_RESTORE_OPTS_RESET_RAM
+    if(!quick_reset_ram) {
+       ret = ram_duplicate_mappings_cow();
+    } else {
+       ret = ram_reset_mappings_cow();
+    }
+#endif
+
 
     return ret;
 }
 
+
 int qemu_load_device_state(QEMUFile *f)
 {
     MigrationIncomingState *mis = migration_incoming_get_current();
@@ -2543,9 +2644,9 @@ int save_snapshot(const char *name, Error **errp)
     struct tm tm;
     AioContext *aio_context;
 
-    if (migration_is_blocked(errp)) {
-        return false;
-    }
+//    if (migration_is_blocked(errp)) {
+//        return false;
+//    }
 
     if (!replay_can_snapshot()) {
         error_setg(errp, "Record/replay does not allow making snapshot "
@@ -2576,7 +2677,7 @@ int save_snapshot(const char *name, Error **errp)
     }
     aio_context = bdrv_get_aio_context(bs);
 
-    saved_vm_running = runstate_is_running();
+    saved_vm_running = false;
 
     ret = global_state_store();
     if (ret) {
@@ -2823,6 +2924,94 @@ err_drain:
     return ret;
 }
 
+int load_snapshot_via_rollback(const char *name, Error **errp)
+{
+    BlockDriverState *bs, *bs_vm_state;
+    QEMUSnapshotInfo sn;
+    QEMUFile *f;
+    int ret;
+    AioContext *aio_context;
+    MigrationIncomingState *mis = migration_incoming_get_current();
+
+    if (!replay_can_snapshot()) {
+        error_setg(errp, "Record/replay does not allow loading snapshot "
+                   "right now. Try once more later.");
+        return -EINVAL;
+    }
+
+    if (!bdrv_all_can_snapshot(&bs)) {
+        error_setg(errp,
+                   "Device '%s' is writable but does not support snapshots",
+                   bdrv_get_device_name(bs));
+        return -ENOTSUP;
+    }
+    ret = bdrv_all_find_snapshot(name, &bs);
+    if (ret < 0) {
+        error_setg(errp,
+                   "Device '%s' does not have the requested snapshot '%s'",
+                   bdrv_get_device_name(bs), name);
+        return ret;
+    }
+
+    bs_vm_state = bdrv_all_find_vmstate_bs();
+    if (!bs_vm_state) {
+        error_setg(errp, "No block device supports snapshots");
+        return -ENOTSUP;
+    }
+    aio_context = bdrv_get_aio_context(bs_vm_state);
+
+    /* Don't even try to load empty VM states */
+    aio_context_acquire(aio_context);
+    ret = bdrv_snapshot_find(bs_vm_state, &sn, name);
+    aio_context_release(aio_context);
+    if (ret < 0) {
+        return ret;
+    } else if (sn.vm_state_size == 0) {
+        error_setg(errp, "This is a disk-only snapshot. Revert to it "
+                   " offline using qemu-img");
+        return -EINVAL;
+    }
+
+    /* Flush all IO requests so they don't interfere with the new state.  */
+    bdrv_drain_all_begin();
+
+    ret = bdrv_all_goto_snapshot(name, &bs, errp);
+    if (ret < 0) {
+        error_prepend(errp, "Could not load snapshot '%s' on '%s': ",
+                      name, bdrv_get_device_name(bs));
+        goto err_drain;
+    }
+
+    /* restore the VM state */
+    f = qemu_fopen_bdrv(bs_vm_state, 0);
+    if (!f) {
+        error_setg(errp, "Could not open VM state file");
+        ret = -EINVAL;
+        goto err_drain;
+    }
+
+    qemu_system_reset(SHUTDOWN_CAUSE_NONE);
+    mis->from_src_file = f;
+
+    aio_context_acquire(aio_context);
+    ret = qemu_loadvm_state(f);
+    migration_incoming_state_destroy();
+    aio_context_release(aio_context);
+
+    bdrv_drain_all_end();
+
+    if (ret < 0) {
+        error_setg(errp, "Error %d while loading VM state", ret);
+        return ret;
+    }
+
+    return 0;
+
+err_drain:
+    bdrv_drain_all_end();
+    return ret;
+}
+
 void vmstate_register_ram(MemoryRegion *mr, DeviceState *dev)
 {
     qemu_ram_set_idstr(mr->ram_block,
diff --git migration/savevm.h migration/savevm.h
index 51a4b9caa8..3a4cfbc0cf 100644
--- migration/savevm.h
+++ migration/savevm.h
@@ -35,6 +35,8 @@ int qemu_savevm_state_resume_prepare(MigrationState *s);
 void qemu_savevm_state_header(QEMUFile *f);
 int qemu_savevm_state_iterate(QEMUFile *f, bool postcopy);
 void qemu_savevm_state_cleanup(void);
+int qemu_savevm_state(QEMUFile *f, Error **errp);
+int periscope_qemu_savevm_state(QEMUFile *, QEMUFile *, Error **);
 void qemu_savevm_state_complete_postcopy(QEMUFile *f);
 int qemu_savevm_state_complete_precopy(QEMUFile *f, bool iterable_only,
                                        bool inactivate_disks);
@@ -60,6 +62,8 @@ void qemu_savevm_live_state(QEMUFile *f);
 int qemu_save_device_state(QEMUFile *f);
 
 int qemu_loadvm_state(QEMUFile *f);
+int qemu_loadvm_state_live(QEMUFile *f);
+int qemu_loadvm_state_normal(QEMUFile *f);
 void qemu_loadvm_state_cleanup(void);
 int qemu_loadvm_state_main(QEMUFile *f, MigrationIncomingState *mis);
 int qemu_load_device_state(QEMUFile *f);
diff --git migration/trace-events migration/trace-events
index de2e136e57..8b26476887 100644
--- migration/trace-events
+++ migration/trace-events
@@ -1,5 +1,8 @@
 # See docs/devel/tracing.txt for syntax documentation.
 
+# periscope.c
+periscope_next_input(int total) "%d"
+
 # savevm.c
 qemu_loadvm_state_section(unsigned int section_type) "%d"
 qemu_loadvm_state_section_command(int ret) "%d"
diff --git migration/vmstate.c migration/vmstate.c
index e2bbb7b5f7..5165e46fe3 100644
--- migration/vmstate.c
+++ migration/vmstate.c
@@ -20,6 +20,8 @@
 #include "qemu/error-report.h"
 #include "trace.h"
 #include "qjson.h"
+#include "migration/periscope_perf_switches.h"
+#include "migration/periscope-delta-snap.h"
 
 static int vmstate_subsection_save(QEMUFile *f, const VMStateDescription *vmsd,
                                    void *opaque, QJSON *vmdesc);
@@ -165,7 +167,7 @@ int vmstate_load_state(QEMUFile *f, const VMStateDescription *vmsd,
     if (ret != 0) {
         return ret;
     }
-    if (vmsd->post_load) {
+    if (vmsd->post_load && !quick_reset_devs) {
         ret = vmsd->post_load(opaque, version_id);
     }
     trace_vmstate_load_state_end(vmsd->name, "end", ret);
diff --git monitor.c monitor.c
index 4807bbe811..a1d5c44cee 100644
--- monitor.c
+++ monitor.c
@@ -3972,6 +3972,17 @@ void loadvm_completion(ReadLineState *rs, int nb_args, const char *str)
     }
 }
 
+void loadvm_minimal_completion(ReadLineState *rs, int nb_args, const char *str)
+{
+    printf("TODO: loadvm_minimal_completion\n");
+
+#if 0
+    if (nb_args == 2) {
+        vm_completion(rs, str);
+    }
+#endif
+}
+
 static void monitor_find_completion_by_table(Monitor *mon,
                                              const mon_cmd_t *cmd_table,
                                              char **args,
diff --git qapi/Makefile.objs qapi/Makefile.objs
index 729e5185c5..91aada4cd6 100644
--- qapi/Makefile.objs
+++ qapi/Makefile.objs
@@ -8,6 +8,7 @@ util-obj-y += qapi-util.o
 QAPI_COMMON_MODULES = audio authz block-core block char common crypto
 QAPI_COMMON_MODULES += introspect job migration misc net rdma rocker
 QAPI_COMMON_MODULES += run-state sockets tpm trace transaction ui
+QAPI_COMMON_MODULES += kcov
 QAPI_TARGET_MODULES = target
 QAPI_MODULES = $(QAPI_COMMON_MODULES) $(QAPI_TARGET_MODULES)
 
diff --git qapi/kcov.json qapi/kcov.json
new file mode 100644
index 0000000000..6f27546770
--- /dev/null
+++ qapi/kcov.json
@@ -0,0 +1,83 @@
+# -*- Mode: Python -*-
+#
+
+##
+# = Kcov
+##
+
+{ 'include': 'common.json' }
+
+##
+# @KcovArea:
+#
+# todo
+#
+# @size: the size
+#
+# @offset: the offset
+#
+# Since: 0.14.0
+##
+{ 'struct': 'KcovArea', 'data': {'size': 'int',
+                                  'offset': 'int'}}
+
+
+##
+# @kcov_get_area_offset:
+#
+# todo
+#
+# Returns: offset.
+#
+# Example:
+#
+# -> { "execute": "kcov_get_area_offset",
+#      "arguments": {} }
+# <- { "return": {"offset": 0} }
+#
+# Since: 1.0
+#
+##
+{'command': 'kcov_get_area_offset', 'returns': 'KcovArea'}
+
+##
+# @kcov_print_coverage:
+#
+# todo
+#
+# Returns: Nothing on success
+#
+# Example:
+#
+# -> { "execute": "kcov_print_coverage",
+#      "arguments": {} }
+# <- { "return": {} }
+#
+# Since: 1.0
+#
+##
+{ 'command': 'kcov_print_coverage'}
+
+
+##
+# @kcov_ioctl:
+#
+# todo
+#
+# @cmd: the ioctl command id
+# @arg: the ioctl command arg
+#
+# Returns: Nothing on success
+#
+# Example:
+#
+# -> { "execute": "kcov_ioctl",
+#      "arguments": { "cmd": "1", "arg": "2" } }
+# <- { "return": {} }
+#
+# Since: 1.0
+#
+##
+{ 'command': 'kcov_ioctl', 'data': {'cmd': 'int', 'arg': 'int'}}
+
+
diff --git qapi/qapi-schema.json qapi/qapi-schema.json
index 4bd1223637..bc1a8d8066 100644
--- qapi/qapi-schema.json
+++ qapi/qapi-schema.json
@@ -97,6 +97,7 @@
 { 'include': 'transaction.json' }
 { 'include': 'trace.json' }
 { 'include': 'introspect.json' }
+{ 'include': 'kcov.json' }
 { 'include': 'misc.json' }
 { 'include': 'target.json' }
 { 'include': 'audio.json' }
diff --git qemu-options.hx qemu-options.hx
index 08749a3391..77b03e76bf 100644
--- qemu-options.hx
+++ qemu-options.hx
@@ -3877,6 +3877,23 @@ STEXI
 Set TB size.
 ETEXI
 
+DEF("fuzzer", HAS_ARG, QEMU_OPTION_fuzzer, \
+    "-fuzzer afl:st_pipe,ctl_pipe\n" \
+    "                accept fuzzer io channel for AFL\n",
+    QEMU_ARCH_ALL)
+STEXI
+@item -fuzzer afl:[@var{st_pipe}],@var{ctl_pipe}
+Accept fuzzer io channels for AFL.
+ETEXI
+
+DEF("periscope", HAS_ARG, QEMU_OPTION_periscope, \
+    "-periscope agent=id,vendor=id,device=id,revision=id,[mm]io=size,...\n" \
+    "",
+    QEMU_ARCH_ALL)
+STEXI
+@item -periscope agent=[@var{agent_id}],vendor=[@var{vendor_id}],device=[@var{device_id}],revision=[@var{revision_id}],io=[@var{size}],mmio=[@var{size}],...]
+ETEXI
+
 DEF("incoming", HAS_ARG, QEMU_OPTION_incoming, \
     "-incoming tcp:[host]:port[,to=maxport][,ipv4][,ipv6]\n" \
     "-incoming rdma:host:port[,ipv4][,ipv6]\n" \
diff --git qmp.c qmp.c
index b92d62cd5f..6e6387931f 100644
--- qmp.c
+++ qmp.c
@@ -34,6 +34,7 @@
 #include "qapi/qapi-commands-block-core.h"
 #include "qapi/qapi-commands-misc.h"
 #include "qapi/qapi-commands-ui.h"
+#include "qapi/qapi-commands-kcov.h"
 #include "qapi/qmp/qdict.h"
 #include "qapi/qmp/qerror.h"
 #include "qapi/qobject-input-visitor.h"
@@ -41,6 +42,8 @@
 #include "qom/object_interfaces.h"
 #include "hw/mem/memory-device.h"
 #include "hw/acpi/acpi_dev_interface.h"
+#include "hw/pci/pci.h"
+#include "hw/periscope/kcov_vdev.h"
 
 NameInfo *qmp_query_name(Error **errp)
 {
@@ -717,3 +720,28 @@ MemoryInfo *qmp_query_memory_size_summary(Error **errp)
 
     return mem_info;
 }
+
+KcovArea* qmp_kcov_get_area_offset(Error **errp)
+{
+   PCIDevice *p = get_pcidev_by_name("kcov_vdev");
+   if(p)
+      kcov_get_area_offset(p);
+   else
+      printf("Error no device kcov_vdev\n");
+   return NULL;
+}
+
+void qmp_kcov_print_coverage(Error **errp)
+{
+   kcov_print_coverage();
+}
+
+void qmp_kcov_ioctl(int64_t cmd, int64_t arg, Error **errp)
+{
+   printf("%s: %lx, %lx\n", __FUNCTION__, cmd, arg);
+   PCIDevice *p = get_pcidev_by_name("kcov_vdev");
+   if(p)
+      kcov_ioctl(p, cmd, arg);
+   else
+      printf("Error no device kcov_vdev\n");
+}
diff --git target/i386/kvm.c target/i386/kvm.c
index 3b29ce5c0d..fda5ebdf59 100644
--- target/i386/kvm.c
+++ target/i386/kvm.c
@@ -1717,6 +1717,24 @@ static void kvm_getput_reg(__u64 *kvm_reg, target_ulong *qemu_reg, int set)
     }
 }
 
+target_ulong kvm_arch_get_kvm_rip(CPUState *cs)
+{
+    X86CPU *cpu = X86_CPU(cs);
+    //CPUX86State *env = &cpu->env;
+    struct kvm_regs regs;
+    int ret;
+
+    ret = kvm_vcpu_ioctl(CPU(cpu), KVM_GET_REGS, &regs);
+    if(ret < 0) {
+       printf("Error KVM_GET_REGS %d\n", ret);
+       return 0;
+    }
+    // FIXME: make sure kvm_getput_regs is called before
+    //return env->eip;
+    return regs.rip;
+}
+
+
 static int kvm_getput_regs(X86CPU *cpu, int set)
 {
     CPUX86State *env = &cpu->env;
diff --git util/bitmap.c util/bitmap.c
index cb618c65a5..1ba49cc3c1 100644
--- util/bitmap.c
+++ util/bitmap.c
@@ -287,6 +287,18 @@ bool bitmap_test_and_clear_atomic(unsigned long *map, long start, long nr)
     return dirty != 0;
 }
 
+void bitmap_copy_atomic(unsigned long *dst, unsigned long *src,
+                                  long nr)
+{
+    while (nr > 0) {
+        *dst = atomic_read(src);
+        dst++;
+        src++;
+        nr -= BITS_PER_LONG;
+    }
+}
+
+
 void bitmap_copy_and_clear_atomic(unsigned long *dst, unsigned long *src,
                                   long nr)
 {
diff --git vl.c vl.c
index c696ad2a13..9ef40a7008 100644
--- vl.c
+++ vl.c
@@ -30,6 +30,7 @@
 #include "qemu/help_option.h"
 #include "qemu/uuid.h"
 #include "sysemu/seccomp.h"
+#include "migration/periscope.h"
 
 #ifdef CONFIG_SDL
 #if defined(__APPLE__) || defined(main)
@@ -128,6 +129,8 @@ int main(int argc, char **argv)
 #include "qapi/qapi-commands-ui.h"
 #include "qapi/qmp/qerror.h"
 #include "sysemu/iothread.h"
+#include "migration/periscope_perf_switches.h"
+#include "migration/periscope-timers.h"
 
 #define MAX_VIRTIO_CONSOLES 1
 
@@ -1719,7 +1722,7 @@ void qemu_system_reset(ShutdownCause reason)
     if (mc && mc->reset) {
         mc->reset();
     } else {
-        qemu_devices_reset();
+       if(!quick_reset_devs) qemu_devices_reset();
     }
     if (reason != SHUTDOWN_CAUSE_SUBSYSTEM_RESET) {
         qapi_event_send_reset(shutdown_caused_by_guest(reason), reason);
@@ -1766,6 +1769,12 @@ void qemu_system_guest_panicked(GuestPanicInformation *info)
 
 void qemu_system_reset_request(ShutdownCause reason)
 {
+    if (reason == SHUTDOWN_CAUSE_GUEST_RESET) {
+        if (periscope_guest_crashed() == PERISCOPE_GUEST_SUSPEND) {
+            qemu_system_suspend_request();
+            return;
+        }
+    }
     if (no_reboot && reason != SHUTDOWN_CAUSE_SUBSYSTEM_RESET) {
         shutdown_requested = reason;
     } else {
@@ -1863,6 +1872,11 @@ void qemu_system_killed(int signal, pid_t pid)
 void qemu_system_shutdown_request(ShutdownCause reason)
 {
     trace_qemu_system_shutdown_request(reason);
+
+    if (periscope_system_shutdown_request(reason) == 0) {
+        return;
+    }
+
     replay_shutdown_request(reason);
     shutdown_requested = reason;
     qemu_notify_event();
@@ -1907,6 +1921,7 @@ static bool main_loop_should_exit(void)
 {
     RunState r;
     ShutdownCause request;
+    uint64_t periscope_request;
 
     if (preconfig_exit_requested) {
         if (runstate_check(RUN_STATE_PRECONFIG)) {
@@ -1941,6 +1956,36 @@ static bool main_loop_should_exit(void)
             runstate_set(RUN_STATE_PRELAUNCH);
         }
     }
+    periscope_request = periscope_checkpoint_requested();
+    if (periscope_request) {
+        pause_all_vcpus();
+
+        uint64_t id = periscope_request;
+        periscope_checkpoint(id);
+
+        if (!periscope_restore_requested()) {
+            // restart logging after checkpointing
+            memory_global_dirty_log_start();
+
+            resume_all_vcpus();
+        }
+    }
+    periscope_request = periscope_restore_requested();
+    if (periscope_request) {
+        pause_all_vcpus();
+
+        periscope_restore();
+
+        // restart logging again after restoring
+        memory_global_dirty_log_start();
+
+        resume_all_vcpus();
+    }
+    if (periscope_snapshot_and_restore_baseline_requested()) {
+        pause_all_vcpus();
+        periscope_snapshot_and_restore_baseline();
+        resume_all_vcpus();
+    }
     if (qemu_wakeup_requested()) {
         pause_all_vcpus();
         qemu_system_reset(SHUTDOWN_CAUSE_NONE);
@@ -3006,6 +3051,7 @@ int main(int argc, char **argv, char **envp)
     const char *vga_model = NULL;
     const char *qtest_chrdev = NULL;
     const char *qtest_log = NULL;
+    const char *fuzzer = NULL;
     const char *incoming = NULL;
     bool userconfig = true;
     bool nographic = false;
@@ -3794,6 +3840,12 @@ int main(int argc, char **argv, char **envp)
                     exit(1);
                 }
                 break;
+            case QEMU_OPTION_periscope:
+                periscope_configure_dev(optarg);
+                break;
+            case QEMU_OPTION_fuzzer:
+                fuzzer = optarg;
+                break;
             case QEMU_OPTION_incoming:
                 if (!incoming) {
                     runstate_set(RUN_STATE_INMIGRATE);
@@ -4587,6 +4639,24 @@ int main(int argc, char **argv, char **envp)
         return 0;
     }
 
+    if (fuzzer) { // FIXME: legacy
+        Error *local_err = NULL;
+        periscope_start_fuzzer(fuzzer, &local_err);
+        if (local_err) {
+            error_reportf_err(local_err, "-fuzzer %s: ", incoming);
+            exit(1);
+        }
+    }
+#ifdef PERISCOPE_TIMERS
+    add_timer("periscope_afl.timer");
+    add_timer("periscope_kvm_run.timer");
+    add_timer("periscope_checkpoint.timer");
+    add_timer("periscope_quick_checkpoint.timer");
+    add_timer("periscope_restore.timer");
+    add_timer("periscope_quick_restore.timer");
+    add_timer("periscope_fuzz_interation.timer");
+#endif
+
     if (incoming) {
         Error *local_err = NULL;
         qemu_start_incoming_migration(incoming, &local_err);
